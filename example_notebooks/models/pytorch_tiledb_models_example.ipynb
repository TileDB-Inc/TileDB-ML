{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example notebook shows how we can train an [image/digit classification](https://pytorch.org/tutorials/beginner/nn_tutorial.html?highlight=mnist)\n",
    "model based on MNIST dataset, and store it as TileDB array. Firstly, let's import what we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import tiledb\n",
    "import glob\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "from tiledb.ml.models.pytorch import PyTorchTileDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's define the parameters/hyperparameters we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10e0cc270>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 1\n",
    "batch_size_train = 128\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "# Set random seeds for anything using random number generation\n",
    "random_seed = 1\n",
    "\n",
    "# Disable nondeterministic algorithms\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We  will also need the DataLoaders API for the dataset. We will also employ TorchVision which let's as load the MNIST\n",
    "dataset in a handy way. We'll use a batch_size of 64 for training while the values 0.1307 and 0.3081 used for\n",
    "the Normalize() transformation below are the global mean and standard deviation of the MNIST dataset,\n",
    "we'll take them as a given here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Moving on, we build our network. We'll use two 2-D convolutional layers followed by two fully-connected\n",
    "layers. As activation function we'll choose ReLUs and as a means of regularization we'll use two dropout layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now initialise our Neural Network and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We continue with the training loop and we iterate over all training data once per epoch. Loading the individual batches\n",
    "is handled by the DataLoader. We need to set the gradients to zero using optimizer.zero_grad() since PyTorch by default\n",
    "accumulates gradients. We then produce the output of the network (forward pass) and compute a negative log-likelihodd\n",
    "loss between the output and the ground truth label. The backward() call we now collect a new set of gradients which we\n",
    "propagate back into each of the network's parameters using optimizer.step()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.316989\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.310947\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.287661\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.261894\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.287373\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.252142\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.202135\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 2.180613\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 2.127905\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 2.048942\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.947829\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 1.886966\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 1.879172\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 1.631594\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 1.653769\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.471534\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 1.364005\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 1.362187\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 1.254044\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 1.181683\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.133363\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 1.117735\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 1.025067\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 1.022916\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.868980\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.979115\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.929074\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.927253\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.836439\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.957468\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.923594\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.731101\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.708485\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.868229\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.633356\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.687116\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.729152\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.782490\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.734664\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.607371\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.744582\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.708631\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.628832\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.576485\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.651480\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.600559\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.530525\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "\n",
    "def train(epoch):\n",
    "  network.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append(\n",
    "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "  train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now save the trained model as a TileDB array. In case we want to train  the model further in a later time, we can save\n",
    "optimizer's state_dict in our TileDB array. In case we will use our model only for inference, we don't have to save optimizer's\n",
    "state_dict and we only keep model's state_dict. We first declare a PytTorchTileDB object (with the corresponding uri) and then\n",
    "save the model as a TileDB array. Finally, we can save any kind of meta data (in any structure, i.e., list, tuple or dictionary)\n",
    "by passing a dictionary to the meta attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tiledb_model_1 = PyTorchTileDB(uri='tiledb-pytorch-mnist-1')\n",
    "\n",
    "tiledb_model_1.save(update=False, model_info={\n",
    "    'model_state_dict': network.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    },\n",
    "                    meta={'epochs': epochs,\n",
    "                          'train_loss': train_losses})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above step will create a TileDB array in your working directory. For information about the structure of a dense\n",
    "TileDB array in terms of files on disk please take a look [here](https://docs.tiledb.com/main/basic-concepts/data-format).\n",
    "Let's open our TileDB array model and check metadata. Metadata that are of type list, dict or tuple have been JSON\n",
    "serialized while saving, i.e., we need json.loads to deserialize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tiledb-pytorch-mnist-1/__meta',\n",
      " 'tiledb-pytorch-mnist-1/__lock.tdb',\n",
      " 'tiledb-pytorch-mnist-1/__array_schema.tdb',\n",
      " 'tiledb-pytorch-mnist-1/__1617026164071_1617026164071_66e47eea64e44eb9bc296acb9955988a_8',\n",
      " 'tiledb-pytorch-mnist-1/__1617026164071_1617026164071_66e47eea64e44eb9bc296acb9955988a_8.ok']\n",
      "\n",
      "\n",
      "Key: epochs, Value: 1\n",
      "Key: python_version, Value: 3.7.3\n",
      "Key: pytorch_version, Value: 1.8.1\n",
      "Key: train_loss, Value: [2.3169891834259033, 2.3109469413757324, 2.287660837173462, 2.2618942260742188, 2.2873728275299072, 2.2521421909332275, 2.202134609222412, 2.180612802505493, 2.1279051303863525, 2.0489416122436523, 1.9478294849395752, 1.8869657516479492, 1.8791720867156982, 1.6315940618515015, 1.65376877784729, 1.4715337753295898, 1.3640053272247314, 1.3621865510940552, 1.2540440559387207, 1.1816833019256592, 1.1333627700805664, 1.1177345514297485, 1.0250669717788696, 1.0229164361953735, 0.8689796328544617, 0.9791150093078613, 0.9290736317634583, 0.9272529482841492, 0.8364390134811401, 0.9574681520462036, 0.9235935211181641, 0.7311012148857117, 0.7084848880767822, 0.868228554725647, 0.6333558559417725, 0.6871156096458435, 0.7291515469551086, 0.7824904918670654, 0.7346636652946472, 0.6073712110519409, 0.74458247423172, 0.708631157875061, 0.6288322806358337, 0.5764852166175842, 0.651480495929718, 0.6005592942237854, 0.5305253863334656]\n"
     ]
    }
   ],
   "source": [
    "# Check array directory\n",
    "pprint(glob.glob('tiledb-pytorch-mnist-1/*'))\n",
    "\n",
    "# Open in write mode in order to add metadata\n",
    "print()\n",
    "model_array_1 = tiledb.open('tiledb-pytorch-mnist-1')\n",
    "for key, value in model_array_1.meta.items():\n",
    "    if isinstance(value, bytes):\n",
    "        value = json.loads(value)\n",
    "    print(\"Key: {}, Value: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, in array's metadata we have by default information about the backend we used for training (pytorch),\n",
    "pytorch version, python version and the extra metadata about epochs and training loss that we added.\n",
    "We can load and check any of the aforementioned without having to load the entire model in memory.\n",
    "Moreover, we can add any kind of extra information in model's metadata also by opening the TileDB array and adding new keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: epochs, Value: 1\n",
      "Key: new_meta, Value: [\"Any kind of info\"]\n",
      "Key: python_version, Value: 3.7.3\n",
      "Key: pytorch_version, Value: 1.8.1\n",
      "Key: train_loss, Value: [2.3169891834259033, 2.3109469413757324, 2.287660837173462, 2.2618942260742188, 2.2873728275299072, 2.2521421909332275, 2.202134609222412, 2.180612802505493, 2.1279051303863525, 2.0489416122436523, 1.9478294849395752, 1.8869657516479492, 1.8791720867156982, 1.6315940618515015, 1.65376877784729, 1.4715337753295898, 1.3640053272247314, 1.3621865510940552, 1.2540440559387207, 1.1816833019256592, 1.1333627700805664, 1.1177345514297485, 1.0250669717788696, 1.0229164361953735, 0.8689796328544617, 0.9791150093078613, 0.9290736317634583, 0.9272529482841492, 0.8364390134811401, 0.9574681520462036, 0.9235935211181641, 0.7311012148857117, 0.7084848880767822, 0.868228554725647, 0.6333558559417725, 0.6871156096458435, 0.7291515469551086, 0.7824904918670654, 0.7346636652946472, 0.6073712110519409, 0.74458247423172, 0.708631157875061, 0.6288322806358337, 0.5764852166175842, 0.651480495929718, 0.6005592942237854, 0.5305253863334656]\n"
     ]
    }
   ],
   "source": [
    "# Open the array in write mode\n",
    "with tiledb.Array('tiledb-pytorch-mnist-1', \"w\") as A:\n",
    "    # Keep all history\n",
    "    A.meta['new_meta'] = json.dumps(['Any kind of info'])\n",
    "\n",
    "# Check that everything is there\n",
    "model_array_1 = tiledb.open('tiledb-pytorch-mnist-1')\n",
    "for key, value in model_array_1.meta.items():\n",
    "    if isinstance(value, bytes):\n",
    "        value = json.loads(value)\n",
    "    print(\"Key: {}, Value: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the case of PyTorch models, as mentioned above, we save model's state_dict and optimizer's state_dict,\n",
    "as [variable sized attributes)](https://docs.tiledb.com/main/solutions/tiledb-embedded/api-usage/writing-arrays/var-length-attributes)\n",
    "(pickled), i.e., we can open the TileDB and get only the state_dict of the model or optimizer,\n",
    "without bringing the whole model in memory. For example, we can load model's and optimizer's state_dict\n",
    "for model tiledb-pytorch-mnist-1 as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('conv1.weight', tensor([[[[ 0.1196, -0.0909, -0.0716,  0.0518, -0.2079],\n",
      "          [ 0.1540, -0.0288,  0.0913,  0.0247, -0.0133],\n",
      "          [ 0.1030,  0.0503,  0.1028, -0.0420,  0.0180],\n",
      "          [ 0.0134,  0.0608,  0.0284,  0.2031,  0.0921],\n",
      "          [-0.0730, -0.1239, -0.0435, -0.0908, -0.0517]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0473,  0.1834,  0.1117, -0.2845,  0.0098],\n",
      "          [ 0.1284,  0.2763,  0.1337, -0.2607, -0.2752],\n",
      "          [ 0.0143,  0.2913, -0.0139,  0.0315, -0.1523],\n",
      "          [ 0.3000,  0.0248,  0.1901, -0.0017, -0.1102],\n",
      "          [ 0.1880, -0.0187,  0.1166, -0.0169,  0.0175]]],\n",
      "\n",
      "\n",
      "        [[[-0.2377, -0.1176,  0.1562,  0.0474,  0.2775],\n",
      "          [ 0.1391,  0.0210, -0.0236,  0.2540,  0.1335],\n",
      "          [-0.1081,  0.2079,  0.2517,  0.2953, -0.0805],\n",
      "          [ 0.0130,  0.0836,  0.1333, -0.0921, -0.1461],\n",
      "          [ 0.1425,  0.0148,  0.1544,  0.0294,  0.0532]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0704,  0.1073,  0.1291, -0.1668,  0.1078],\n",
      "          [-0.1428, -0.1451,  0.0154, -0.0328,  0.1165],\n",
      "          [-0.1222, -0.1823,  0.1315, -0.0428,  0.1010],\n",
      "          [ 0.0564, -0.1566,  0.0206,  0.0245, -0.1562],\n",
      "          [-0.1004,  0.0584,  0.0095, -0.1173, -0.0909]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2855,  0.0935,  0.2417,  0.1554, -0.1186],\n",
      "          [-0.0265,  0.4201,  0.2200,  0.2478,  0.0868],\n",
      "          [ 0.2481,  0.4221,  0.4155, -0.0293,  0.0878],\n",
      "          [ 0.3047,  0.3577,  0.2821, -0.0725, -0.0815],\n",
      "          [-0.0447,  0.1343,  0.2848, -0.0726,  0.1829]]],\n",
      "\n",
      "\n",
      "        [[[-0.1100, -0.1947, -0.0033,  0.2381,  0.3270],\n",
      "          [-0.0873,  0.0929,  0.2855,  0.3036,  0.2695],\n",
      "          [ 0.1907,  0.1847,  0.1553, -0.0031, -0.0820],\n",
      "          [-0.0833, -0.0029, -0.0594,  0.1627,  0.1163],\n",
      "          [-0.0713,  0.0696,  0.1028,  0.1800,  0.1651]]],\n",
      "\n",
      "\n",
      "        [[[-0.0858,  0.1820, -0.0097,  0.0293, -0.1652],\n",
      "          [-0.1486, -0.1238, -0.0611,  0.1827, -0.0508],\n",
      "          [-0.1577,  0.0948,  0.1113,  0.1734, -0.0937],\n",
      "          [ 0.0561, -0.0331,  0.0224, -0.1093, -0.0694],\n",
      "          [-0.0375,  0.1301,  0.0996,  0.1001,  0.2302]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1897,  0.1433,  0.0163, -0.1312,  0.1514],\n",
      "          [-0.0653, -0.0259, -0.1770, -0.0511, -0.1426],\n",
      "          [ 0.1697, -0.1842, -0.1650, -0.0186, -0.1125],\n",
      "          [ 0.0758, -0.0616, -0.0709,  0.0366,  0.1697],\n",
      "          [-0.1161,  0.1434,  0.1974,  0.2533, -0.1011]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0550, -0.1436,  0.1920, -0.0162,  0.2101],\n",
      "          [ 0.0199, -0.0018,  0.0313,  0.1209,  0.2043],\n",
      "          [ 0.0408,  0.0671, -0.1493,  0.2195,  0.2768],\n",
      "          [ 0.1503,  0.1281, -0.1433, -0.0315,  0.2505],\n",
      "          [-0.2068,  0.1346, -0.1719, -0.1188,  0.1421]]],\n",
      "\n",
      "\n",
      "        [[[-0.1403, -0.0235,  0.2151,  0.2503,  0.2664],\n",
      "          [-0.0470, -0.1449,  0.2608,  0.0422, -0.0120],\n",
      "          [ 0.0357, -0.1348,  0.1749,  0.1802, -0.1208],\n",
      "          [-0.1766, -0.0121,  0.1091,  0.0206, -0.0914],\n",
      "          [-0.0081, -0.1861, -0.1277, -0.1288,  0.1486]]]])), ('conv1.bias', tensor([ 0.1877, -0.0474,  0.0478,  0.0981,  0.1131, -0.0415,  0.1208,  0.1372,\n",
      "         0.0159,  0.0059])), ('conv2.weight', tensor([[[[ 5.2476e-02,  4.4376e-02, -4.7886e-02,  5.6827e-02,  2.0328e-02],\n",
      "          [-4.3289e-02,  3.0660e-02, -5.2730e-02,  7.0837e-02, -1.3815e-02],\n",
      "          [ 2.2514e-02,  2.0528e-02,  1.7594e-02,  6.3093e-02, -1.2187e-02],\n",
      "          [-3.6201e-02, -6.1779e-02, -3.1378e-03, -2.7690e-02, -7.0485e-04],\n",
      "          [-1.5414e-02,  2.5271e-02,  6.3774e-02,  2.6533e-02, -1.5878e-02]],\n",
      "\n",
      "         [[-3.4347e-02, -7.5316e-02,  2.7694e-02, -1.5484e-03,  5.1359e-02],\n",
      "          [-6.1752e-03, -6.0949e-02,  1.9683e-02,  5.2388e-02,  2.5743e-02],\n",
      "          [-4.7007e-02, -4.2337e-02,  1.0202e-02, -2.3503e-02, -4.6005e-02],\n",
      "          [-1.1034e-02, -1.0299e-02,  3.5242e-02, -2.8608e-02, -4.1720e-02],\n",
      "          [-1.3275e-02, -4.4560e-02,  5.4995e-02, -1.2000e-02,  3.2100e-02]],\n",
      "\n",
      "         [[-2.1036e-02, -4.0875e-02, -6.3030e-02,  1.2076e-03,  5.4573e-02],\n",
      "          [-8.4280e-02, -2.8564e-02,  7.7992e-02,  7.7751e-02,  3.9671e-02],\n",
      "          [-3.3199e-03,  3.7616e-02,  4.3771e-02, -5.8515e-03,  2.5385e-02],\n",
      "          [-3.1339e-03, -1.5202e-02,  4.5870e-03, -7.7008e-02, -3.0767e-02],\n",
      "          [ 2.5800e-02,  3.6096e-03,  1.8968e-02, -6.0333e-02, -2.1570e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.6836e-02,  4.0913e-02,  1.7149e-02,  4.3585e-02,  5.8566e-02],\n",
      "          [-3.7319e-02,  8.4018e-02, -6.2519e-02,  2.4507e-02,  1.3321e-02],\n",
      "          [ 2.4931e-02, -3.9152e-02,  2.4712e-02, -2.0874e-02, -3.9236e-02],\n",
      "          [ 2.1330e-02,  3.9858e-02,  8.5311e-02,  2.7869e-02,  8.1332e-02],\n",
      "          [ 3.9961e-02, -2.5733e-02, -3.6557e-02,  4.0187e-02, -3.5669e-02]],\n",
      "\n",
      "         [[ 2.6463e-03, -5.6958e-02,  5.2292e-02,  2.2459e-02, -1.0567e-02],\n",
      "          [ 8.3306e-03, -3.9387e-02,  1.4818e-03,  2.8202e-02, -1.4619e-02],\n",
      "          [-7.4644e-03, -2.3473e-03,  7.3225e-02,  6.5778e-02,  6.6685e-02],\n",
      "          [ 5.3629e-02, -5.7125e-02,  1.9968e-03,  1.3467e-03, -5.4786e-02],\n",
      "          [ 1.7610e-02, -3.9936e-02, -3.1345e-04,  1.2480e-02,  5.1301e-02]],\n",
      "\n",
      "         [[-3.5130e-02, -5.5650e-02,  6.1810e-02,  3.4697e-02,  2.7129e-02],\n",
      "          [ 8.8786e-03, -4.6070e-02,  4.3467e-02, -4.2509e-02,  9.3953e-03],\n",
      "          [ 2.0385e-02,  5.8948e-02,  4.9828e-03, -2.2807e-02,  3.9391e-02],\n",
      "          [-3.8993e-02, -2.5879e-02, -4.0719e-02, -3.2530e-02, -1.0729e-02],\n",
      "          [-4.3411e-02, -2.9503e-02, -6.3787e-02,  3.2018e-02, -1.9360e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.2080e-02,  1.7869e-02, -4.7539e-02,  3.8644e-02,  3.0114e-02],\n",
      "          [-7.0580e-02, -5.5830e-02, -4.5211e-02, -3.3746e-02,  8.4963e-03],\n",
      "          [-7.0425e-02, -5.2131e-02,  2.9813e-02, -9.6134e-03, -1.3388e-02],\n",
      "          [-5.8806e-02,  1.6067e-02, -1.1423e-05, -2.7191e-02, -3.6047e-02],\n",
      "          [ 1.5615e-02,  1.2993e-02,  1.7772e-02,  2.5132e-03, -2.0983e-02]],\n",
      "\n",
      "         [[-5.0467e-02,  3.9508e-02, -7.1469e-03, -6.2752e-02,  5.4058e-02],\n",
      "          [ 1.8370e-02, -6.5683e-02, -3.6436e-02, -1.4777e-02, -1.1679e-02],\n",
      "          [ 1.0657e-02, -5.5562e-02,  5.3944e-02, -2.8124e-02,  5.4779e-02],\n",
      "          [-1.2033e-02, -2.9199e-02,  2.5464e-02, -7.6226e-02, -4.7485e-02],\n",
      "          [ 1.2696e-03,  4.3582e-02, -5.3744e-02, -6.8578e-02, -5.6257e-02]],\n",
      "\n",
      "         [[-3.0682e-02, -3.6916e-02, -3.1949e-02, -1.9151e-02,  6.1648e-02],\n",
      "          [-1.2700e-02, -3.5298e-02, -1.1275e-02,  5.0964e-02,  2.9021e-02],\n",
      "          [ 4.6481e-02,  1.5733e-02, -3.6257e-02, -3.5901e-02, -1.9801e-02],\n",
      "          [ 5.3551e-03,  1.4452e-02, -2.7870e-02,  1.5721e-02, -2.7684e-02],\n",
      "          [ 3.5524e-02, -8.2028e-04, -3.9920e-02,  4.5056e-02, -7.3725e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.4527e-02,  2.4525e-02, -1.3519e-02, -2.0544e-02, -6.5946e-02],\n",
      "          [ 3.1446e-02, -3.6623e-02, -5.7570e-02, -2.3838e-02, -2.5969e-02],\n",
      "          [-5.9985e-02,  1.1960e-02, -2.9563e-02,  4.0074e-02,  5.2544e-02],\n",
      "          [-4.5864e-02, -3.7378e-02, -1.5624e-02,  2.9975e-02, -7.4997e-03],\n",
      "          [-2.5896e-02,  4.2694e-02,  6.6594e-02,  4.4298e-02, -4.9270e-02]],\n",
      "\n",
      "         [[-1.1039e-02, -2.1375e-02,  4.7002e-02, -2.6087e-02, -2.3977e-02],\n",
      "          [-4.8809e-03, -1.4243e-02,  4.1008e-02,  2.3877e-02, -3.5008e-02],\n",
      "          [ 4.2448e-02,  4.2553e-02,  3.6353e-02, -4.1701e-02,  2.7986e-02],\n",
      "          [ 3.9713e-02,  4.6722e-03, -2.5288e-02,  4.9749e-03, -2.5265e-02],\n",
      "          [ 4.9450e-02,  3.4532e-02, -2.4844e-02, -5.7749e-02,  2.0236e-02]],\n",
      "\n",
      "         [[ 3.6291e-02,  2.8941e-02, -6.7092e-02,  3.8361e-03, -1.8115e-02],\n",
      "          [-6.1238e-02, -4.5665e-02,  2.4782e-02,  3.7704e-02, -4.7009e-02],\n",
      "          [ 2.5511e-02,  5.7642e-02,  6.3311e-02,  5.0521e-02, -9.8331e-03],\n",
      "          [ 4.8156e-02,  5.4632e-02,  3.8213e-02, -3.5883e-02, -1.3512e-02],\n",
      "          [ 5.2214e-02,  4.0174e-02,  2.5950e-02, -2.8263e-02, -2.0162e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.7532e-02, -1.1875e-02,  6.5741e-02, -3.8470e-02, -6.9325e-03],\n",
      "          [ 3.0137e-02, -1.3775e-02,  3.9453e-02,  1.9392e-02,  4.9223e-02],\n",
      "          [-5.6803e-02, -3.1639e-03, -6.8433e-02,  3.5705e-02,  6.9340e-02],\n",
      "          [-3.3253e-02, -2.2261e-03, -4.9491e-02, -5.7190e-02, -4.0525e-02],\n",
      "          [-3.5510e-02,  8.9769e-03, -1.2187e-02, -2.3495e-03, -5.0215e-02]],\n",
      "\n",
      "         [[-1.8822e-02, -3.0401e-02, -3.3681e-02,  5.9101e-02,  5.5694e-02],\n",
      "          [-5.5847e-02, -7.6440e-03,  2.4967e-03,  3.6919e-02,  9.6074e-02],\n",
      "          [ 3.0147e-03,  2.9962e-02, -4.8451e-02, -3.1266e-02, -2.7683e-02],\n",
      "          [-3.5962e-03,  4.2061e-02,  4.9776e-03,  2.5287e-02, -3.1562e-02],\n",
      "          [-1.7140e-02,  2.2111e-02,  4.6475e-02, -7.2281e-02, -2.7355e-02]],\n",
      "\n",
      "         [[ 1.7423e-02, -3.2836e-02,  3.5917e-02,  3.3624e-02,  1.2646e-02],\n",
      "          [ 6.7738e-02,  7.9275e-02,  8.2878e-02,  5.1835e-02,  2.6210e-03],\n",
      "          [ 4.4609e-02,  3.2872e-02, -6.0878e-02,  1.5627e-02,  4.8950e-03],\n",
      "          [-6.4981e-02, -5.4624e-02, -4.3666e-02, -4.0021e-02, -9.2605e-03],\n",
      "          [ 1.7375e-02,  4.3073e-02,  5.3327e-03, -4.2189e-02,  4.7464e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.9679e-02,  2.5365e-02, -3.5368e-03, -7.3024e-03,  3.2371e-02],\n",
      "          [-5.7941e-02,  2.7108e-02,  2.9858e-02,  2.1386e-02,  6.6170e-02],\n",
      "          [ 4.2061e-03, -2.7167e-02,  1.6213e-02, -1.5371e-02,  1.7055e-02],\n",
      "          [ 6.2383e-02, -2.3615e-02,  9.6848e-03,  5.6025e-02, -5.4598e-02],\n",
      "          [-6.9437e-03,  6.9435e-02,  5.3783e-02,  1.8756e-02, -3.1032e-02]],\n",
      "\n",
      "         [[ 1.3919e-02, -3.3776e-02, -2.3189e-02, -3.0601e-02,  5.8212e-02],\n",
      "          [ 8.8058e-02,  6.9063e-02,  4.0668e-02,  9.7451e-02, -1.1665e-02],\n",
      "          [ 2.9966e-02, -1.5464e-02, -1.8991e-02,  1.5198e-03, -4.3636e-03],\n",
      "          [-1.0133e-01, -2.7121e-02, -3.5371e-02,  2.7856e-02,  3.6793e-02],\n",
      "          [-2.6684e-02,  1.1242e-02,  9.7551e-03,  3.8288e-02, -5.1829e-02]],\n",
      "\n",
      "         [[-1.8220e-02, -4.1367e-02,  4.0621e-02, -5.0586e-02, -4.0281e-02],\n",
      "          [ 4.4978e-02,  9.5031e-02,  8.3261e-02, -2.2247e-02, -4.4096e-02],\n",
      "          [ 9.4799e-02,  4.0147e-02, -2.2015e-02,  1.1185e-02,  3.8488e-02],\n",
      "          [-3.2851e-02, -7.2195e-02, -4.8405e-02, -1.5336e-02,  2.3033e-03],\n",
      "          [ 2.9549e-03,  7.6001e-03, -4.1966e-02, -6.9501e-03, -5.3573e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 8.6523e-02,  3.9363e-02,  1.9085e-02, -3.2412e-02, -5.3162e-02],\n",
      "          [-4.5507e-02,  4.2742e-03, -4.8782e-02, -6.6726e-02,  2.7131e-02],\n",
      "          [-4.7162e-02, -7.3335e-02, -5.5730e-02,  4.1472e-02, -2.8246e-02],\n",
      "          [-5.3204e-02, -6.7106e-02, -3.7352e-02,  5.6003e-02,  8.1278e-02],\n",
      "          [-2.7976e-03, -2.1776e-02, -1.0239e-02, -4.9404e-02, -1.8922e-02]],\n",
      "\n",
      "         [[ 4.0445e-02, -2.6461e-02,  6.7012e-02, -1.8419e-03, -4.8958e-02],\n",
      "          [-1.8005e-02,  5.3057e-02,  1.2708e-01,  5.1145e-02, -2.4838e-02],\n",
      "          [-2.7889e-02, -7.4472e-02,  1.0567e-01,  1.5721e-01,  3.1331e-02],\n",
      "          [-1.8719e-02, -7.8525e-02,  8.0529e-02,  7.6534e-02,  6.7679e-02],\n",
      "          [-1.8542e-02,  2.5356e-02, -2.6420e-02, -1.5704e-02,  9.7292e-03]],\n",
      "\n",
      "         [[ 3.9030e-03,  1.8108e-02,  3.8097e-02,  7.8770e-02, -5.0259e-02],\n",
      "          [ 1.2788e-02, -4.7009e-02,  3.1486e-02,  4.3737e-02, -7.7731e-02],\n",
      "          [-8.1400e-02, -5.6590e-02,  6.7822e-02, -2.6454e-02, -5.6770e-02],\n",
      "          [-5.0125e-02,  2.1095e-03, -2.8988e-02, -3.3914e-02, -4.5852e-02],\n",
      "          [ 3.2693e-02,  4.2416e-02,  1.4203e-02, -3.6195e-02, -4.0170e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.4106e-02,  2.1398e-02,  2.4313e-02, -3.7534e-02,  2.9685e-02],\n",
      "          [-2.3495e-02, -5.2854e-02, -2.6172e-02, -2.1196e-02,  1.7312e-03],\n",
      "          [ 1.8542e-02, -2.1014e-02, -6.0020e-03,  3.4407e-02,  5.4250e-02],\n",
      "          [-2.3676e-02, -2.6760e-02,  6.6241e-03, -3.1994e-02, -1.7335e-03],\n",
      "          [ 6.4212e-03, -1.7517e-02, -1.5455e-02,  3.3444e-02,  1.7745e-02]],\n",
      "\n",
      "         [[-2.5171e-03,  2.1867e-02, -2.7411e-02,  2.3138e-02,  1.5598e-03],\n",
      "          [ 4.7531e-02,  8.7063e-02,  1.0501e-02,  1.1256e-02, -4.8531e-02],\n",
      "          [ 3.2851e-02,  7.4039e-02,  8.4354e-02, -1.6206e-02, -1.8953e-02],\n",
      "          [-8.8931e-02,  5.8811e-02,  2.2090e-02,  3.2091e-02, -7.1534e-02],\n",
      "          [-4.1514e-02,  2.0816e-02, -4.6598e-02,  2.1590e-02,  1.3079e-02]],\n",
      "\n",
      "         [[ 2.0525e-02,  3.1643e-02, -5.6779e-02, -5.0460e-02,  2.1529e-02],\n",
      "          [ 1.9638e-02, -2.6060e-02, -5.0896e-02,  4.4247e-02, -5.8973e-02],\n",
      "          [ 5.7061e-02, -2.4205e-02,  7.2035e-02, -2.5173e-02,  1.0461e-02],\n",
      "          [ 3.2570e-02,  7.3619e-02,  1.2113e-02,  8.3302e-03, -4.3107e-02],\n",
      "          [-4.7218e-02,  1.9303e-02,  5.0970e-02, -9.4165e-03,  4.9071e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.0589e-02, -2.2722e-03, -4.6452e-02,  6.0870e-03,  2.3611e-03],\n",
      "          [ 3.1849e-02,  3.4016e-02,  3.7001e-02,  3.0604e-02, -3.5032e-03],\n",
      "          [ 3.8855e-02,  4.0807e-02,  3.5007e-02,  4.0670e-02, -1.7872e-02],\n",
      "          [ 7.0533e-03, -3.0238e-02,  2.8694e-02, -1.0996e-02, -6.4807e-02],\n",
      "          [-2.5493e-02, -4.8645e-02,  1.6879e-02,  5.9609e-02,  3.8212e-03]],\n",
      "\n",
      "         [[-2.4961e-02, -1.7946e-02, -5.6806e-02,  5.8737e-02,  6.8031e-02],\n",
      "          [-4.3567e-02,  3.4634e-02,  1.7863e-02, -5.9800e-03,  7.2008e-02],\n",
      "          [ 3.0940e-03, -3.2798e-02,  5.7946e-02,  2.2806e-02,  2.3360e-02],\n",
      "          [ 6.4005e-02,  5.3252e-02,  8.7479e-02, -2.4403e-04, -4.9976e-02],\n",
      "          [ 1.2632e-02,  2.5949e-02,  8.6816e-02,  5.5463e-02,  3.7615e-02]],\n",
      "\n",
      "         [[ 2.6127e-02, -5.9814e-02, -7.4630e-03,  1.7348e-02, -5.0992e-02],\n",
      "          [-2.7050e-02, -1.5421e-02, -2.9343e-02,  2.2776e-02, -8.7780e-02],\n",
      "          [ 1.7554e-02, -1.8924e-02,  6.1232e-02, -1.2262e-02, -7.9735e-02],\n",
      "          [ 1.9109e-02, -1.8772e-02,  5.9707e-02, -2.0524e-02, -3.6634e-03],\n",
      "          [ 3.6969e-02,  6.0724e-02,  4.5758e-02,  3.6263e-02, -6.7989e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5367e-02, -5.7458e-02, -5.2999e-02, -2.9618e-02, -6.8482e-02],\n",
      "          [ 1.5054e-03,  4.9713e-02,  5.2894e-02, -2.3796e-02, -4.1413e-02],\n",
      "          [ 4.0579e-02, -4.6367e-02,  2.2271e-02, -2.1102e-02, -1.0902e-02],\n",
      "          [ 3.4094e-02,  3.9790e-03, -2.2157e-02,  6.3322e-02, -3.9539e-02],\n",
      "          [-2.2909e-02, -4.2168e-02, -4.5603e-02, -4.9686e-02, -4.5396e-02]],\n",
      "\n",
      "         [[ 1.8190e-02, -2.3569e-02,  6.2585e-02, -2.6365e-02, -1.2693e-03],\n",
      "          [ 2.8216e-02,  1.6714e-02, -3.8392e-02, -3.6718e-02, -4.2759e-02],\n",
      "          [-2.2907e-02,  2.2621e-02, -4.7884e-02, -1.6477e-02, -7.9007e-02],\n",
      "          [ 7.0929e-02,  3.9243e-03, -6.8316e-02, -7.5893e-02, -7.9484e-02],\n",
      "          [ 2.1909e-02,  5.5827e-03, -3.6219e-02, -3.3198e-02, -4.8359e-02]],\n",
      "\n",
      "         [[-2.0220e-02, -1.6177e-02, -3.4049e-02,  1.8100e-02,  1.7509e-02],\n",
      "          [-4.0241e-02, -1.6379e-02, -1.4351e-02, -1.4042e-02, -2.2760e-02],\n",
      "          [-4.3060e-02,  4.5175e-02,  2.0928e-02,  2.7763e-02,  2.1438e-02],\n",
      "          [-9.7334e-03,  2.1304e-02,  3.1532e-02,  4.0265e-02, -7.3179e-02],\n",
      "          [ 5.1356e-03,  2.2862e-02,  1.9774e-02,  1.5479e-03,  5.1042e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.1042e-02, -5.2587e-02, -4.1298e-02,  2.5429e-02,  1.3077e-02],\n",
      "          [ 3.1492e-02,  4.4665e-02,  6.0337e-02,  2.0680e-02, -3.2496e-03],\n",
      "          [ 4.8670e-02, -2.9735e-03, -7.0241e-03, -4.7656e-02,  5.0155e-02],\n",
      "          [-5.5624e-02, -1.8965e-02,  6.0393e-02, -6.1548e-02,  2.2807e-02],\n",
      "          [-1.3845e-02,  6.9415e-03,  2.8087e-02,  3.3258e-02,  2.7349e-02]],\n",
      "\n",
      "         [[-6.0686e-03, -1.0569e-02,  5.9897e-02,  1.9721e-02, -1.9356e-02],\n",
      "          [-1.0504e-02,  3.6336e-02, -2.4843e-02, -5.6466e-02, -7.5812e-02],\n",
      "          [-1.4117e-02, -1.6370e-02,  2.4306e-02, -5.8184e-02,  3.3062e-02],\n",
      "          [ 3.2315e-02, -1.8696e-03,  1.5563e-02, -1.7917e-02, -1.7652e-02],\n",
      "          [ 7.0219e-02,  7.0019e-02,  4.2446e-02, -6.3506e-02,  5.6728e-02]],\n",
      "\n",
      "         [[ 3.8320e-02, -7.7835e-03,  2.8492e-02,  5.5607e-03, -3.7950e-02],\n",
      "          [-4.5342e-02, -1.2156e-02,  2.2669e-02, -2.1932e-02, -2.2832e-02],\n",
      "          [ 6.0706e-02,  4.7441e-02,  3.3945e-03, -7.5120e-02,  4.0037e-02],\n",
      "          [ 8.1290e-02, -1.8848e-02, -5.4272e-02, -2.2067e-02,  3.2247e-03],\n",
      "          [ 6.0878e-02,  4.8200e-02,  2.4126e-02, -3.3819e-02, -1.5035e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.9489e-03, -4.8014e-02, -2.9044e-02,  4.4588e-02,  2.8897e-02],\n",
      "          [ 3.9213e-02, -1.4528e-02,  5.8966e-02,  4.6873e-02,  3.2940e-02],\n",
      "          [ 2.4816e-02, -7.0089e-02, -3.6302e-02, -6.2394e-03,  3.0336e-03],\n",
      "          [ 5.4556e-02,  4.3625e-02, -3.6856e-02,  3.2194e-02,  1.6949e-02],\n",
      "          [-1.7572e-02, -4.6163e-02,  3.3810e-02,  1.4676e-02,  1.3313e-02]],\n",
      "\n",
      "         [[ 6.2623e-02, -1.7682e-02, -3.2955e-02,  1.4825e-02, -3.2060e-03],\n",
      "          [-3.1863e-02, -7.6526e-02, -7.4070e-02, -1.0943e-02,  7.1244e-02],\n",
      "          [-3.9196e-02, -3.6884e-03,  1.3035e-02,  1.2685e-02,  2.5987e-02],\n",
      "          [ 3.2981e-02, -8.0650e-02,  2.9288e-02,  5.3451e-02,  7.8924e-02],\n",
      "          [ 2.4607e-02, -3.5249e-02, -7.3643e-02, -3.9697e-02, -3.6431e-02]],\n",
      "\n",
      "         [[-1.7763e-02, -4.9764e-02,  4.5606e-02,  3.3903e-02, -1.2113e-02],\n",
      "          [ 1.1171e-02,  1.2169e-02, -6.1148e-03,  3.3703e-02,  3.4547e-02],\n",
      "          [-4.3376e-02,  6.0734e-02, -4.0443e-02, -3.7955e-02,  7.8885e-02],\n",
      "          [-2.9155e-02, -1.2963e-02, -7.3267e-03, -6.6372e-02,  6.7596e-02],\n",
      "          [ 4.7404e-02, -6.9597e-02, -2.6398e-02, -1.3218e-03,  5.4006e-02]]]])), ('conv2.bias', tensor([ 0.0277, -0.0152,  0.0487, -0.0056, -0.0092, -0.0343, -0.0369, -0.0138,\n",
      "        -0.0515, -0.0174,  0.0127, -0.0426, -0.0506,  0.0711, -0.0352, -0.0541,\n",
      "        -0.0096, -0.0467, -0.0599,  0.0035])), ('fc1.weight', tensor([[-0.0535, -0.0212,  0.0262,  ..., -0.0169,  0.0449,  0.0214],\n",
      "        [-0.0274, -0.0846, -0.0157,  ...,  0.0466, -0.0277, -0.0109],\n",
      "        [-0.0303, -0.0029, -0.0318,  ...,  0.0425, -0.0615,  0.0481],\n",
      "        ...,\n",
      "        [ 0.0090,  0.0031,  0.0340,  ..., -0.0391,  0.0078, -0.0360],\n",
      "        [ 0.0104,  0.0335,  0.0334,  ...,  0.0004, -0.0072,  0.0150],\n",
      "        [ 0.0695,  0.0347, -0.0064,  ...,  0.0349,  0.0082, -0.0127]])), ('fc1.bias', tensor([ 0.0449,  0.0335, -0.0074, -0.0041,  0.0149, -0.0097,  0.0014, -0.0399,\n",
      "         0.0113,  0.0067,  0.0238,  0.0459, -0.0194, -0.0069, -0.0117, -0.0417,\n",
      "         0.0513,  0.0163,  0.0595, -0.0472,  0.0087,  0.0154, -0.0281,  0.0343,\n",
      "         0.0348, -0.0020,  0.0641, -0.0271, -0.0464, -0.0356, -0.0390,  0.0431,\n",
      "         0.0071, -0.0461, -0.0487,  0.0677,  0.0042, -0.0570,  0.0286, -0.0325,\n",
      "         0.0085,  0.0644,  0.0368, -0.0382, -0.0278,  0.0139, -0.0468, -0.0494,\n",
      "         0.0502,  0.0310])), ('fc2.weight', tensor([[ 0.1057, -0.0609,  0.1000,  0.0265, -0.0552, -0.0318, -0.1565, -0.1321,\n",
      "         -0.0668, -0.0964, -0.1877, -0.1055, -0.0321,  0.0850,  0.1368,  0.0925,\n",
      "          0.0467,  0.1899,  0.0948, -0.0038, -0.0019, -0.1293, -0.0442, -0.1777,\n",
      "         -0.0263, -0.1684, -0.1568, -0.2165,  0.0925,  0.2134, -0.1653,  0.0192,\n",
      "          0.1986,  0.1103, -0.1059,  0.1513,  0.1387,  0.0642, -0.0939, -0.1259,\n",
      "         -0.1253, -0.2000,  0.0826, -0.0528, -0.0168,  0.1274, -0.0681, -0.0337,\n",
      "          0.0981,  0.0061],\n",
      "        [ 0.0173,  0.1315, -0.1415,  0.1033,  0.0900,  0.0940, -0.1939,  0.0389,\n",
      "          0.0087, -0.1148,  0.1451,  0.1442, -0.0908, -0.1138,  0.0086, -0.2152,\n",
      "          0.1118, -0.0259, -0.1508,  0.0336, -0.1073,  0.0627,  0.0923,  0.1480,\n",
      "          0.1697, -0.2333, -0.2142,  0.1322,  0.1099,  0.0847,  0.1716, -0.0415,\n",
      "         -0.1925, -0.1261,  0.1579,  0.0208, -0.1245, -0.0396,  0.1119,  0.1112,\n",
      "         -0.0101,  0.1186, -0.0521, -0.1870,  0.1361, -0.1196, -0.1357,  0.1073,\n",
      "         -0.1767,  0.0918],\n",
      "        [-0.0559, -0.0460, -0.0937, -0.0614, -0.0752,  0.1483,  0.1042, -0.0065,\n",
      "          0.1938,  0.0247,  0.0289,  0.2002,  0.0474,  0.1548,  0.1387,  0.1100,\n",
      "         -0.0513,  0.0021, -0.1124, -0.1338, -0.0627,  0.0369, -0.1266, -0.1225,\n",
      "         -0.0738, -0.0900, -0.1531,  0.0625, -0.1739, -0.0084, -0.0964, -0.0573,\n",
      "         -0.0292, -0.1324,  0.0727,  0.1589, -0.0976, -0.1401,  0.1251,  0.0168,\n",
      "          0.1474,  0.1299, -0.0582, -0.0238, -0.0049,  0.1563,  0.0937,  0.0718,\n",
      "         -0.1220,  0.1353],\n",
      "        [ 0.0170,  0.1845,  0.1154, -0.0881,  0.0049, -0.2000,  0.0561,  0.0701,\n",
      "          0.0185, -0.0361, -0.0324,  0.2297, -0.0940, -0.0297,  0.0896, -0.0310,\n",
      "         -0.1123, -0.0013, -0.1252,  0.1321,  0.1464,  0.1257,  0.0698, -0.0427,\n",
      "         -0.1024, -0.1315,  0.1007, -0.0911,  0.0960, -0.1135, -0.1908,  0.1161,\n",
      "         -0.1058,  0.0834,  0.0727,  0.0757,  0.1049,  0.0678, -0.1995,  0.0247,\n",
      "          0.1066,  0.1503, -0.1513,  0.0633,  0.1087,  0.0384, -0.1032, -0.0403,\n",
      "         -0.0437,  0.1278],\n",
      "        [ 0.0063, -0.0379, -0.0203,  0.0596,  0.0092,  0.1300,  0.1282, -0.1084,\n",
      "         -0.0387, -0.1279,  0.1676,  0.0114,  0.1693, -0.1702, -0.0332,  0.0824,\n",
      "         -0.1255, -0.0888,  0.0628, -0.0730, -0.1117, -0.1268,  0.1765,  0.1261,\n",
      "          0.0605,  0.1375,  0.0423, -0.0208,  0.0584, -0.0241,  0.0597,  0.1067,\n",
      "         -0.1425, -0.1649, -0.0761, -0.0870, -0.0156,  0.1904,  0.0834, -0.0174,\n",
      "         -0.1437, -0.0728,  0.0486,  0.0659, -0.1208,  0.0275, -0.0963, -0.1453,\n",
      "          0.1555, -0.1213],\n",
      "        [ 0.0401, -0.0592, -0.0325, -0.1253,  0.0220, -0.0481, -0.1408, -0.0701,\n",
      "          0.0883, -0.1036,  0.1216,  0.0276, -0.1479, -0.1927, -0.1341,  0.0073,\n",
      "         -0.0692,  0.1705,  0.1703,  0.0978,  0.1967, -0.1113, -0.0630,  0.0325,\n",
      "         -0.0175, -0.1065,  0.0645, -0.1522,  0.1647,  0.0948, -0.0390,  0.1087,\n",
      "         -0.0923,  0.0757, -0.0421,  0.1175,  0.1810,  0.0704, -0.1002, -0.0850,\n",
      "         -0.1037,  0.0153,  0.1020, -0.0948, -0.0330,  0.0159,  0.1433, -0.0112,\n",
      "          0.1437,  0.0207],\n",
      "        [-0.2013, -0.1598,  0.0287, -0.0461, -0.0047,  0.1146, -0.1855,  0.0615,\n",
      "          0.1456, -0.1127,  0.1672, -0.0356, -0.0184, -0.1466,  0.1117,  0.1148,\n",
      "         -0.2136,  0.1615,  0.0700, -0.0205, -0.0197, -0.0863, -0.0465,  0.0034,\n",
      "         -0.1088, -0.0550, -0.1522, -0.1092,  0.1078, -0.1101,  0.1417,  0.0585,\n",
      "         -0.0576, -0.0107, -0.0625,  0.1539, -0.1498,  0.1655,  0.1404,  0.1619,\n",
      "         -0.2103, -0.2129,  0.1789,  0.0133, -0.0289,  0.1285,  0.2153,  0.0449,\n",
      "          0.0879, -0.0089],\n",
      "        [ 0.1713,  0.1067,  0.0759, -0.0194,  0.1409, -0.1356,  0.1170, -0.0360,\n",
      "         -0.0232, -0.0446,  0.0084,  0.0181,  0.1236,  0.1184,  0.0104, -0.1561,\n",
      "          0.0574, -0.1561,  0.0644, -0.1791, -0.0766, -0.0883, -0.1559,  0.0643,\n",
      "         -0.1007,  0.1363, -0.1245,  0.1877,  0.0670,  0.0766, -0.0870, -0.0438,\n",
      "          0.1493,  0.0345,  0.0782, -0.2043, -0.0520,  0.0268, -0.1731, -0.0307,\n",
      "          0.1082,  0.1153, -0.1274,  0.1983,  0.0593, -0.0173, -0.0334,  0.0859,\n",
      "          0.1068, -0.1327],\n",
      "        [ 0.0268, -0.0964, -0.1430, -0.1022, -0.0348,  0.0077,  0.0098,  0.0525,\n",
      "          0.0954, -0.1304, -0.0525, -0.0976, -0.0305, -0.1112,  0.1275, -0.0125,\n",
      "          0.0817, -0.0142,  0.1640,  0.1214,  0.1849, -0.1071, -0.1185,  0.1255,\n",
      "          0.0878, -0.0276,  0.1027, -0.0427, -0.1516, -0.0126,  0.1514, -0.0778,\n",
      "         -0.1121, -0.0391, -0.0246,  0.1684, -0.1052, -0.1425, -0.0369,  0.0628,\n",
      "          0.0885,  0.1165, -0.0497, -0.0662, -0.1371,  0.1626, -0.1109, -0.0924,\n",
      "          0.1356,  0.0398],\n",
      "        [ 0.1519, -0.0969, -0.0338,  0.0263,  0.0380, -0.0867,  0.1494,  0.0088,\n",
      "         -0.1315, -0.0126,  0.1139, -0.0172,  0.0696,  0.0115,  0.0006, -0.0114,\n",
      "          0.0494, -0.0844,  0.1090, -0.0886, -0.0003, -0.0541,  0.0356,  0.0886,\n",
      "         -0.0264,  0.1543,  0.0851,  0.0532,  0.0651,  0.0173,  0.0006,  0.1368,\n",
      "         -0.0601,  0.0308, -0.1088, -0.1036, -0.0677,  0.0305,  0.0489,  0.0315,\n",
      "          0.0016,  0.0960, -0.1253,  0.2136, -0.1189, -0.1352, -0.0451,  0.0691,\n",
      "          0.1567, -0.1650]])), ('fc2.bias', tensor([-0.0829,  0.0606, -0.0421, -0.1419,  0.0362,  0.0465, -0.0492, -0.0574,\n",
      "        -0.0224, -0.0458]))])\n",
      "{'state': {0: {'momentum_buffer': tensor([[[[ 1.2649e-02,  1.4137e-02,  1.6283e-02,  1.2049e-02,  5.6369e-03],\n",
      "          [ 7.3155e-03,  1.0221e-02,  9.5372e-03,  1.3003e-03, -4.0819e-03],\n",
      "          [ 1.4266e-02,  1.2218e-02, -1.5313e-03, -1.1659e-02, -5.5284e-03],\n",
      "          [ 1.8210e-02,  1.1776e-02, -3.1668e-03, -1.0181e-02, -3.6586e-03],\n",
      "          [ 1.1165e-02,  6.8577e-03,  3.3553e-04, -9.5830e-05,  2.3575e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.9045e-03, -1.4167e-02,  1.8201e-03,  1.3518e-02,  1.8473e-02],\n",
      "          [-1.7852e-02, -1.6288e-02,  3.8088e-03,  1.5036e-02,  1.7599e-02],\n",
      "          [-1.8449e-02, -1.6095e-02,  1.3693e-02,  2.4462e-02,  2.0821e-02],\n",
      "          [-1.1135e-02, -5.1663e-03,  1.7637e-02,  2.1822e-02,  1.8635e-02],\n",
      "          [-1.0717e-03,  1.7612e-02,  3.3830e-02,  3.1328e-02,  2.4208e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0507e-04,  2.4168e-03,  5.6526e-03,  7.2258e-03,  1.4547e-02],\n",
      "          [ 3.7816e-03, -1.1730e-03,  3.5218e-04,  6.0438e-03,  1.0668e-02],\n",
      "          [ 4.8746e-04,  1.5005e-03, -3.1740e-03, -1.1837e-03,  1.9287e-02],\n",
      "          [-1.2789e-02, -6.7240e-03, -5.2814e-04,  9.4487e-03,  2.6805e-02],\n",
      "          [-1.0051e-02, -2.0228e-03,  5.8187e-03,  1.7749e-02,  2.8827e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8929e-04,  1.2852e-04,  1.5619e-03,  7.0103e-04, -6.4862e-03],\n",
      "          [-1.7315e-03, -2.8380e-03,  1.1003e-03, -2.8832e-03, -9.3424e-03],\n",
      "          [-3.3661e-03, -3.3304e-03, -2.7557e-03, -3.2813e-03, -6.5679e-03],\n",
      "          [-5.1088e-03, -4.6397e-03, -2.0228e-03,  7.3255e-04, -1.1185e-03],\n",
      "          [-6.2469e-03, -5.8844e-03, -4.4460e-04,  4.5991e-04, -1.6123e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4369e-03,  2.0867e-02,  1.3168e-02,  1.2959e-02,  2.7239e-02],\n",
      "          [ 7.1826e-03,  7.0637e-03, -3.7034e-03,  7.7557e-03,  2.1722e-02],\n",
      "          [-6.9810e-03, -1.7345e-02,  6.9706e-04,  1.8785e-02,  3.4348e-02],\n",
      "          [-2.1425e-02, -8.0789e-03,  1.2408e-03,  2.4630e-02,  3.3437e-02],\n",
      "          [-2.8978e-02, -1.4096e-02,  8.9688e-03,  2.6858e-02,  3.8200e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.7803e-04, -1.1566e-03, -7.4263e-04, -8.5965e-03, -1.6434e-02],\n",
      "          [ 2.4249e-03, -1.3759e-03, -2.7443e-03, -1.0818e-02, -8.1566e-03],\n",
      "          [-1.2856e-02, -1.1424e-02, -6.5077e-03, -9.4186e-03,  1.0896e-03],\n",
      "          [-1.9719e-02, -9.4755e-03, -7.5241e-03, -4.4163e-03,  8.4098e-03],\n",
      "          [-1.0633e-02, -1.8695e-03, -9.5993e-03, -1.5129e-02,  1.0947e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.3524e-03,  1.9838e-03, -2.5919e-03, -8.4111e-03, -3.6939e-03],\n",
      "          [ 6.7968e-03, -1.9756e-03, -6.6785e-03, -8.2164e-03,  8.9986e-04],\n",
      "          [-2.9480e-03, -8.0161e-03, -1.2516e-02, -1.0426e-02,  6.8130e-03],\n",
      "          [-4.3315e-03, -1.1846e-02, -1.5305e-02, -6.6448e-03,  6.9532e-03],\n",
      "          [-6.3410e-03, -7.1843e-03, -5.4831e-03, -4.3119e-03,  4.6958e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1160e-02,  1.6951e-02,  3.6298e-03, -4.0164e-06,  2.6060e-03],\n",
      "          [ 1.0467e-02,  5.3277e-03, -1.9491e-03,  4.8013e-03,  1.1280e-02],\n",
      "          [-6.1883e-03, -2.7429e-04, -3.3998e-03,  6.6046e-03,  1.0523e-02],\n",
      "          [-1.4071e-02, -1.9173e-02, -1.4773e-02, -9.9066e-03, -2.6925e-03],\n",
      "          [-1.1004e-02, -1.9291e-02, -2.4244e-02, -1.8685e-02, -1.0274e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.1049e-03, -5.1187e-03, -6.8091e-03, -3.5451e-03,  1.2979e-02],\n",
      "          [-7.3916e-03, -9.2365e-03, -1.0435e-02, -5.4696e-03,  6.0581e-03],\n",
      "          [-6.3056e-03, -1.0478e-02, -9.2871e-03, -2.4071e-03, -2.2196e-03],\n",
      "          [-4.4304e-03, -4.6008e-03, -5.8041e-03, -6.6083e-03, -5.1869e-03],\n",
      "          [ 3.2339e-03,  3.2381e-03, -5.8797e-03, -3.9333e-03,  6.8396e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.4373e-02, -1.3658e-02, -1.3212e-02, -1.2407e-02, -4.7511e-03],\n",
      "          [-1.6738e-02, -9.2547e-03, -3.6295e-03, -7.7318e-03, -7.2240e-03],\n",
      "          [-1.0026e-02, -1.5876e-03,  1.9004e-03, -3.8454e-03, -7.4760e-03],\n",
      "          [-7.4587e-04,  4.6143e-03, -9.1798e-04, -8.4527e-03, -8.6109e-03],\n",
      "          [ 4.9560e-03,  4.9949e-03, -3.9757e-03, -4.4871e-03, -3.4008e-03]]]])}, 1: {'momentum_buffer': tensor([ 0.0018, -0.0046,  0.0012, -0.0007, -0.0086, -0.0120,  0.0024, -0.0070,\n",
      "         0.0009, -0.0035])}, 2: {'momentum_buffer': tensor([[[[-4.3170e-03, -3.1450e-03, -4.2270e-03, -2.7402e-03, -2.8941e-03],\n",
      "          [-1.8281e-03, -1.5166e-03, -3.6985e-03, -4.9393e-03, -2.8811e-03],\n",
      "          [ 8.9118e-03,  8.3226e-03,  6.7772e-03,  5.4577e-03,  7.0654e-03],\n",
      "          [ 2.2625e-03, -7.5700e-04,  1.6790e-03,  3.4349e-03,  8.9611e-04],\n",
      "          [ 3.4551e-03,  2.9822e-03,  5.8093e-03,  3.0945e-03,  3.7002e-04]],\n",
      "\n",
      "         [[-7.0176e-03, -5.5869e-03, -6.3013e-03, -1.0857e-02,  8.3447e-03],\n",
      "          [ 3.0142e-03, -2.7507e-03,  6.0537e-03,  1.1412e-02,  2.1242e-02],\n",
      "          [ 4.5273e-03,  1.5941e-03,  1.3080e-02,  2.2605e-02,  1.7571e-02],\n",
      "          [ 5.6123e-03,  4.8302e-03,  1.8257e-02,  2.5403e-02,  7.1345e-03],\n",
      "          [ 1.0875e-03,  8.8623e-03,  2.6195e-02,  2.9312e-02,  8.2277e-03]],\n",
      "\n",
      "         [[-8.8105e-03, -1.2993e-02, -4.0452e-03,  1.3015e-02,  1.5857e-02],\n",
      "          [-3.9448e-03,  2.5672e-03,  1.3991e-02,  1.9189e-02,  7.2958e-03],\n",
      "          [ 1.1698e-02,  2.2142e-02,  2.8067e-02,  2.1379e-02,  3.4850e-03],\n",
      "          [ 2.0118e-02,  2.3149e-02,  3.2834e-02,  1.3398e-02, -1.7017e-03],\n",
      "          [ 1.9015e-02,  3.0382e-02,  2.7610e-02,  6.9578e-03, -3.9073e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.7097e-04,  4.6719e-03,  8.6712e-03,  2.7195e-03, -1.2920e-02],\n",
      "          [ 1.0493e-02,  1.1254e-02,  1.0799e-02,  1.7128e-03,  2.5483e-03],\n",
      "          [ 5.2448e-03,  4.7547e-03,  1.8132e-03, -2.8557e-03, -2.7916e-03],\n",
      "          [ 9.8340e-03,  9.5393e-03,  2.2483e-03,  3.1085e-03, -2.2924e-03],\n",
      "          [ 5.2745e-03,  9.1172e-03,  1.3930e-02,  1.4434e-02,  1.3075e-02]],\n",
      "\n",
      "         [[-1.1782e-02, -9.2768e-03, -6.0699e-03,  6.6522e-03,  3.1765e-03],\n",
      "          [-7.5662e-03,  1.6451e-03,  1.9105e-04,  4.4745e-03, -2.6027e-03],\n",
      "          [ 6.3285e-03,  2.2231e-02,  1.1758e-02,  8.2761e-03,  4.0987e-04],\n",
      "          [ 1.2344e-02,  2.3356e-02,  1.5799e-02,  4.9761e-03, -5.6474e-03],\n",
      "          [ 1.4435e-02,  2.0910e-02,  8.7521e-03, -2.9984e-03, -1.0005e-02]],\n",
      "\n",
      "         [[ 1.0156e-04, -2.0496e-03, -3.2626e-03,  8.6712e-03,  1.3991e-02],\n",
      "          [-9.4048e-03, -4.2987e-03, -3.4861e-03,  4.8759e-04, -8.5976e-05],\n",
      "          [ 2.1205e-03,  1.2487e-03,  4.9954e-03, -1.0521e-03, -6.5219e-03],\n",
      "          [ 1.0700e-02,  7.4998e-03,  1.6608e-02,  2.5820e-03,  1.6203e-03],\n",
      "          [ 1.1128e-02,  1.1179e-02,  9.6329e-03, -5.9709e-03, -7.4697e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 8.2842e-03,  7.6464e-03,  5.5441e-03,  4.4021e-03,  3.2544e-04],\n",
      "          [ 9.1213e-03,  4.4144e-03,  3.2915e-03,  7.7266e-03,  9.1616e-03],\n",
      "          [ 3.3275e-03,  3.8296e-03,  2.1754e-03, -6.2636e-03, -7.5132e-03],\n",
      "          [ 2.2322e-03,  7.0083e-03,  6.2935e-03, -5.3173e-03, -1.0337e-02],\n",
      "          [ 1.2005e-03,  9.7432e-04, -8.3570e-04, -2.2472e-03, -3.3379e-03]],\n",
      "\n",
      "         [[ 2.2623e-02,  2.0920e-02,  1.5159e-02,  1.6489e-02, -5.7127e-03],\n",
      "          [ 7.8802e-03,  1.8527e-02,  1.6373e-02,  1.2138e-03, -1.2990e-02],\n",
      "          [-7.3213e-03,  2.7535e-02,  2.5464e-02, -1.1502e-02, -2.5337e-02],\n",
      "          [-5.7959e-05,  3.8100e-02,  2.1838e-02, -1.0007e-02, -1.4535e-02],\n",
      "          [ 1.4957e-02,  2.9628e-02,  2.9195e-03, -1.9616e-02, -9.3099e-03]],\n",
      "\n",
      "         [[ 2.0059e-02,  1.1066e-02,  1.2371e-02, -1.2187e-02, -2.0585e-02],\n",
      "          [ 1.5177e-02,  2.5200e-02,  5.2202e-03, -1.4794e-02, -1.1529e-02],\n",
      "          [ 2.5808e-02,  3.0963e-02, -2.5206e-03, -1.4732e-02,  2.0017e-03],\n",
      "          [ 4.0544e-02,  2.6585e-02, -1.5931e-02, -1.8874e-02, -7.0013e-03],\n",
      "          [ 3.0715e-02,  4.0596e-03, -1.8674e-02, -1.3248e-02, -4.3535e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.8712e-03,  8.6369e-03,  5.4005e-03, -1.8756e-03,  1.0056e-02],\n",
      "          [ 1.1421e-02,  6.5267e-03, -1.3639e-03, -4.8917e-04, -7.9103e-03],\n",
      "          [ 9.2390e-03,  2.5447e-03,  5.1110e-03, -2.2817e-03, -8.6966e-03],\n",
      "          [-5.8693e-03, -6.5889e-03,  5.6479e-03,  5.6902e-05, -3.2167e-03],\n",
      "          [ 1.7891e-03,  8.5572e-03,  4.1284e-03, -3.9982e-03, -7.7642e-03]],\n",
      "\n",
      "         [[ 1.1252e-02,  5.8355e-03, -1.0492e-03, -1.0882e-02, -8.1533e-03],\n",
      "          [ 2.1035e-02, -7.3242e-05, -5.1722e-03, -1.6383e-03,  6.0521e-04],\n",
      "          [ 1.7880e-02, -6.5771e-03, -1.6708e-02, -7.9534e-04,  7.7569e-03],\n",
      "          [ 2.0540e-02,  6.2430e-04, -2.0047e-02, -8.5429e-03, -4.3429e-03],\n",
      "          [ 7.2808e-03, -9.5715e-03, -1.4009e-02, -2.3423e-03, -2.3285e-03]],\n",
      "\n",
      "         [[ 3.8297e-03,  2.4412e-04,  1.4882e-03, -6.2170e-03, -1.1746e-02],\n",
      "          [ 1.4526e-02,  5.9622e-03, -6.1787e-04, -4.8012e-03, -1.1674e-03],\n",
      "          [ 1.1346e-02,  7.8084e-03, -1.2833e-02, -3.0065e-03,  1.2795e-02],\n",
      "          [ 2.5717e-02,  1.1158e-02, -1.1489e-02, -1.4536e-02,  2.8970e-04],\n",
      "          [ 1.7775e-02,  1.1881e-03, -1.1370e-02, -1.6622e-02, -1.3036e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.9633e-03,  6.4564e-03,  1.1805e-02,  1.2036e-02,  1.5967e-02],\n",
      "          [ 3.4793e-03,  4.0218e-03,  4.2260e-03,  9.5898e-05,  1.6322e-03],\n",
      "          [ 7.6584e-03,  8.6519e-03,  3.6017e-03,  8.2594e-04, -1.5322e-03],\n",
      "          [ 8.3053e-03,  7.8291e-03,  4.8038e-03,  2.4654e-03,  3.8285e-03],\n",
      "          [ 9.4604e-03,  1.0394e-02,  1.3021e-02,  7.8432e-03,  3.6472e-03]],\n",
      "\n",
      "         [[ 2.3640e-03,  2.5698e-02,  2.2299e-02,  8.6367e-03,  2.0153e-02],\n",
      "          [ 2.0533e-02,  2.9675e-02,  1.4347e-02, -1.0924e-03,  4.4045e-04],\n",
      "          [ 2.8949e-02,  2.9483e-02,  1.2486e-02,  8.8712e-03,  5.5386e-03],\n",
      "          [ 2.7113e-02,  1.5405e-02,  1.0823e-02,  1.1017e-02,  3.4593e-03],\n",
      "          [ 1.4414e-02,  7.4943e-03,  1.0351e-02,  8.4721e-03,  6.3835e-03]],\n",
      "\n",
      "         [[ 3.6850e-02,  4.0460e-02,  2.9087e-02,  2.1678e-02,  1.6156e-02],\n",
      "          [ 4.1802e-02,  2.8192e-02,  1.8061e-02,  1.2151e-02,  1.3487e-02],\n",
      "          [ 3.6664e-02,  1.6786e-02,  1.0772e-02,  2.5980e-03, -7.2790e-03],\n",
      "          [ 2.5017e-02,  1.4663e-02,  1.4606e-02,  2.9058e-03,  8.1844e-03],\n",
      "          [ 1.0559e-02,  1.1334e-02,  5.0436e-03,  2.0127e-03,  6.3378e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5075e-03, -1.7217e-03,  3.0394e-03,  2.6417e-04, -8.7323e-03],\n",
      "          [ 5.5369e-03,  5.5859e-03,  1.0617e-02, -1.4949e-03, -3.6102e-03],\n",
      "          [ 3.1500e-03,  8.5699e-03,  1.1509e-02,  6.7437e-03,  1.2950e-02],\n",
      "          [ 4.3309e-03,  1.1272e-02,  6.4645e-03,  6.2839e-03,  2.6225e-03],\n",
      "          [ 8.0656e-03,  3.7329e-03,  2.9950e-03,  5.5713e-03,  5.2855e-03]],\n",
      "\n",
      "         [[ 2.1669e-02,  1.9479e-02,  2.2287e-02,  3.0080e-02,  2.4130e-02],\n",
      "          [ 2.1690e-02,  1.7846e-02,  1.5297e-02,  1.3996e-02,  9.6366e-03],\n",
      "          [ 2.1297e-02,  8.9491e-03,  2.6529e-03,  2.7213e-03, -6.5674e-03],\n",
      "          [ 1.7364e-02,  1.2675e-02, -2.9850e-03,  5.2210e-03, -5.0881e-03],\n",
      "          [ 2.0216e-02,  1.2281e-02,  6.9240e-03,  1.1769e-02,  1.7952e-03]],\n",
      "\n",
      "         [[ 1.1418e-02,  1.6422e-02,  1.5435e-02,  1.2365e-02,  7.2064e-03],\n",
      "          [ 1.5562e-02,  1.0363e-02,  8.0892e-03,  1.1378e-02,  1.5503e-02],\n",
      "          [ 1.1149e-02,  6.2756e-03, -1.1734e-04,  6.1807e-05,  2.0737e-03],\n",
      "          [ 1.6136e-02,  7.1534e-03,  3.0467e-03, -1.0056e-02,  5.4332e-03],\n",
      "          [ 1.1487e-02,  1.1596e-02,  7.3985e-03,  2.9715e-03,  9.1014e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.3294e-03, -4.1609e-03,  9.7726e-04,  3.0218e-03,  5.1684e-03],\n",
      "          [-2.8025e-03, -5.1831e-03, -3.3863e-04, -2.8851e-03,  2.1455e-03],\n",
      "          [-2.8452e-03, -4.7836e-03, -5.2854e-03, -4.7216e-03,  5.5854e-03],\n",
      "          [-4.1760e-03, -8.4824e-03, -2.9464e-03,  2.5748e-03,  8.2079e-03],\n",
      "          [-2.8022e-03, -9.7944e-03, -3.2581e-03,  2.8378e-03,  1.9025e-03]],\n",
      "\n",
      "         [[-1.0140e-03, -1.5713e-02, -1.2735e-02, -1.1669e-02, -4.2809e-03],\n",
      "          [-2.0090e-03, -1.3809e-02, -3.3495e-02, -1.8425e-02,  5.4287e-03],\n",
      "          [-5.0518e-03, -2.3103e-02, -3.4530e-02, -8.9279e-03,  1.6817e-02],\n",
      "          [-8.2179e-03, -3.4690e-02, -2.3762e-02,  2.2072e-03,  1.0346e-02],\n",
      "          [-2.1566e-02, -2.6639e-02, -9.6022e-04, -1.0038e-03, -4.6335e-03]],\n",
      "\n",
      "         [[-1.8971e-02, -1.5602e-02, -9.5598e-03, -1.0595e-03,  3.1323e-02],\n",
      "          [-2.6761e-02, -2.5553e-02, -1.4943e-02,  2.2939e-02,  4.3257e-02],\n",
      "          [-3.3959e-02, -3.3885e-02,  1.5760e-05,  3.4184e-02,  3.2006e-02],\n",
      "          [-4.8615e-02, -2.0319e-02,  2.4072e-02,  2.2613e-02,  9.2483e-03],\n",
      "          [-3.2712e-02,  6.3750e-03,  1.6638e-02, -1.0586e-03,  1.4295e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.3482e-03, -2.0618e-03, -2.3618e-03,  4.9784e-03, -1.1057e-03],\n",
      "          [-5.3692e-03, -1.5253e-03, -2.5850e-04, -1.1838e-03, -3.8686e-03],\n",
      "          [-7.0197e-03, -6.7362e-04, -1.0632e-03, -7.4587e-03, -9.7820e-04],\n",
      "          [ 7.1030e-04,  2.9162e-03, -7.9721e-03, -4.2281e-03,  4.2650e-03],\n",
      "          [ 4.4458e-03, -3.8991e-03, -9.0615e-03,  2.7723e-03,  6.5735e-03]],\n",
      "\n",
      "         [[-1.0388e-02, -8.6232e-03,  8.5370e-03,  1.3156e-02,  2.1933e-02],\n",
      "          [-2.0717e-02, -1.0854e-02,  8.4568e-03,  2.4091e-02,  2.4605e-02],\n",
      "          [-2.1057e-02, -4.0969e-03,  1.0957e-02,  2.5455e-02,  1.5690e-02],\n",
      "          [-1.8063e-02,  3.8775e-03,  1.0350e-02,  1.7817e-02,  8.1720e-03],\n",
      "          [-1.2955e-02,  5.0865e-03,  1.4033e-03,  4.4009e-03,  6.6773e-03]],\n",
      "\n",
      "         [[-2.8070e-03,  6.4678e-03,  8.0664e-03, -4.2455e-04,  1.1327e-02],\n",
      "          [-5.8928e-03,  5.8640e-03,  4.5554e-03,  9.9776e-03,  1.9655e-02],\n",
      "          [-6.9039e-03, -3.9893e-03,  6.7339e-03,  1.1943e-02,  1.1129e-02],\n",
      "          [-1.9828e-02, -2.5428e-03,  1.9979e-02,  1.4935e-02,  8.0188e-03],\n",
      "          [-1.6870e-02,  1.0286e-02,  1.6032e-02,  4.5841e-03,  7.8507e-04]]],\n",
      "\n",
      "\n",
      "        [[[-4.0183e-03, -3.9881e-03,  1.0995e-03,  5.9453e-03,  4.3206e-03],\n",
      "          [-6.0927e-03, -6.0923e-03, -2.4773e-03,  3.6400e-03,  7.7826e-03],\n",
      "          [ 1.2211e-03,  1.4242e-03, -1.3633e-03,  8.7587e-04,  2.1077e-03],\n",
      "          [-3.6602e-03,  4.2176e-03,  7.0731e-03,  2.7947e-03, -2.7032e-03],\n",
      "          [-8.0570e-03, -6.4818e-04,  2.6718e-03, -4.8942e-04, -4.5324e-03]],\n",
      "\n",
      "         [[-1.9330e-02, -1.9898e-02,  4.7950e-04, -2.1403e-04,  9.8060e-03],\n",
      "          [-2.0648e-02, -1.1223e-02, -4.0068e-03, -3.4551e-03,  6.3808e-03],\n",
      "          [-1.1058e-02,  3.3559e-03,  6.1672e-03, -3.8667e-03, -9.9120e-04],\n",
      "          [-1.5095e-02, -1.0378e-03,  2.6953e-02,  4.5673e-03, -5.9159e-03],\n",
      "          [-1.7175e-02,  5.4689e-03,  2.8146e-02,  1.4644e-02, -1.2258e-03]],\n",
      "\n",
      "         [[-2.5708e-02,  8.3389e-04,  5.3981e-03,  9.4208e-03,  1.5143e-02],\n",
      "          [-1.4498e-02, -3.8761e-04,  7.3939e-03,  1.2793e-02,  1.7583e-02],\n",
      "          [-2.9499e-04,  9.7384e-03,  1.5078e-02,  1.0933e-02,  6.7295e-03],\n",
      "          [-3.7968e-03,  1.9666e-02,  8.1261e-03, -6.1738e-03,  1.5875e-04],\n",
      "          [ 5.7632e-03,  2.4498e-02,  4.0639e-03, -2.4564e-03,  7.5681e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.0926e-03, -1.2334e-02, -6.4966e-03,  2.7717e-03,  7.5537e-03],\n",
      "          [-1.1026e-03,  6.0431e-04,  2.6828e-03, -1.3452e-03,  3.6246e-03],\n",
      "          [-1.9537e-03,  2.0650e-03, -1.8411e-03, -2.3092e-03, -1.4564e-03],\n",
      "          [-8.1209e-04, -8.2888e-04, -2.9593e-03,  1.2374e-03, -8.1047e-04],\n",
      "          [ 7.7014e-03,  1.3431e-03,  7.6744e-03,  1.1091e-02,  3.4768e-03]],\n",
      "\n",
      "         [[-5.1188e-03,  2.5418e-03,  4.3160e-03,  1.0893e-02,  5.0704e-03],\n",
      "          [-4.6796e-03, -2.0822e-05,  4.9582e-03,  1.8905e-02,  1.5014e-02],\n",
      "          [ 5.9694e-03,  2.5205e-03,  1.3674e-03,  1.6983e-02,  1.1960e-02],\n",
      "          [ 1.2649e-02,  1.1246e-02, -1.6428e-03,  1.6811e-03,  5.3912e-03],\n",
      "          [ 1.4748e-02,  8.7579e-03, -4.5861e-03, -5.9737e-03,  2.4253e-03]],\n",
      "\n",
      "         [[-1.7187e-02, -8.2575e-04,  2.3725e-03,  3.4522e-03,  1.9762e-03],\n",
      "          [-6.5148e-03,  9.5814e-03,  5.5441e-03,  8.0914e-03,  4.4358e-03],\n",
      "          [-4.2270e-03, -3.7739e-03, -8.6730e-04,  7.9969e-03,  9.3055e-03],\n",
      "          [ 8.5478e-03,  1.3538e-02,  9.8412e-04, -8.0413e-04,  5.5887e-03],\n",
      "          [ 1.0696e-02,  1.5202e-02, -7.1879e-03, -1.0019e-02, -4.0220e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 8.4912e-04,  1.7008e-03,  1.1013e-03,  7.9544e-03,  4.2056e-03],\n",
      "          [ 7.5621e-03,  2.5480e-03,  4.3585e-03,  6.6646e-03,  1.5958e-03],\n",
      "          [ 3.3228e-04,  4.5966e-03,  4.9898e-03,  3.9897e-03,  4.2333e-04],\n",
      "          [-8.7590e-03, -2.5058e-03,  5.3688e-03,  2.9857e-03, -1.6313e-03],\n",
      "          [-2.3009e-03, -3.4175e-03, -3.0349e-03, -6.1992e-04, -1.0055e-03]],\n",
      "\n",
      "         [[ 1.5246e-02, -1.0772e-02,  1.2840e-02,  1.8800e-02,  3.3801e-03],\n",
      "          [ 5.3145e-03,  1.5376e-03,  2.1960e-02,  9.8925e-03, -5.8485e-03],\n",
      "          [-1.5844e-02,  6.7110e-03,  1.4882e-02,  3.0650e-03, -2.5079e-03],\n",
      "          [-1.4980e-02,  2.9904e-03,  1.9913e-03, -8.9893e-04, -5.4348e-03],\n",
      "          [-6.1809e-04,  7.9565e-03, -5.1209e-03,  8.2885e-04, -2.8298e-03]],\n",
      "\n",
      "         [[ 2.4647e-03,  1.7171e-02,  2.4223e-02,  9.1018e-03, -1.0958e-03],\n",
      "          [ 4.1582e-03,  2.2865e-02,  1.0150e-02,  2.5895e-04,  4.7344e-03],\n",
      "          [ 5.2960e-03,  1.7133e-02,  4.3065e-03,  9.9861e-03,  2.6563e-04],\n",
      "          [ 6.7290e-03,  7.3478e-03,  2.3084e-03,  1.9954e-03, -9.3445e-03],\n",
      "          [ 1.2884e-02, -5.3114e-04, -2.7367e-04, -9.0772e-03, -2.0288e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.1423e-03,  3.8580e-03, -5.4823e-03,  8.4196e-03,  8.1863e-03],\n",
      "          [ 9.0243e-03, -2.4356e-03,  5.2675e-03,  8.4164e-03,  3.4361e-03],\n",
      "          [-1.3502e-03, -2.8739e-03,  8.6991e-03,  4.3018e-03, -7.4529e-04],\n",
      "          [-2.9207e-05, -3.2466e-03,  1.2615e-03, -4.8650e-04,  4.1040e-04],\n",
      "          [-1.8306e-03,  4.4261e-03,  8.2311e-04, -9.0354e-04,  3.8035e-04]],\n",
      "\n",
      "         [[ 1.5058e-03,  1.3047e-02,  1.3434e-02,  3.1099e-03,  5.4427e-03],\n",
      "          [ 1.1479e-02,  7.6472e-03,  4.2517e-03, -2.0118e-03,  5.2694e-03],\n",
      "          [ 1.1646e-02,  7.0950e-03,  4.4298e-03, -1.5706e-03,  2.3644e-03],\n",
      "          [ 4.9068e-03,  6.7688e-03,  5.7927e-03, -8.4609e-03, -6.8929e-03],\n",
      "          [-9.4661e-04,  7.7651e-04, -1.4200e-04, -1.1091e-02, -1.3635e-02]],\n",
      "\n",
      "         [[-1.0502e-02,  7.0772e-03,  1.4021e-02,  6.3268e-03,  1.0123e-03],\n",
      "          [-2.6010e-03,  1.5104e-02,  4.8095e-03,  2.9100e-03,  3.2045e-03],\n",
      "          [ 3.8265e-03,  8.5475e-03,  4.3608e-04,  3.6180e-03, -2.7376e-04],\n",
      "          [ 6.6574e-03,  4.8164e-03,  6.0878e-03,  1.6094e-03, -6.2281e-03],\n",
      "          [ 6.1686e-04, -1.8215e-03,  4.1795e-03, -2.3101e-03, -1.0964e-02]]]])}, 3: {'momentum_buffer': tensor([ 0.0049,  0.0028,  0.0063, -0.0082, -0.0032, -0.0037,  0.0040, -0.0052,\n",
      "        -0.0005,  0.0119, -0.0055, -0.0076, -0.0079, -0.0115,  0.0060, -0.0005,\n",
      "        -0.0045,  0.0012,  0.0011,  0.0011])}, 4: {'momentum_buffer': tensor([[ 0.0253,  0.0271,  0.0200,  ...,  0.0091, -0.0149,  0.0194],\n",
      "        [ 0.0374,  0.0569,  0.0178,  ..., -0.0063, -0.0044, -0.0040],\n",
      "        [-0.0736, -0.0612, -0.0079,  ..., -0.0019, -0.0029, -0.0017],\n",
      "        ...,\n",
      "        [ 0.0582,  0.0644,  0.0132,  ...,  0.0027, -0.0042,  0.0167],\n",
      "        [ 0.0880,  0.0717,  0.0118,  ..., -0.0066, -0.0219, -0.0164],\n",
      "        [-0.0230, -0.0293, -0.0153,  ...,  0.0008, -0.0042,  0.0090]])}, 5: {'momentum_buffer': tensor([ 5.9376e-03, -4.3972e-03, -1.0094e-02,  2.7711e-03,  8.3756e-04,\n",
      "        -1.6070e-05, -5.6054e-03, -9.9014e-03,  4.4271e-03, -1.5165e-03,\n",
      "        -5.5826e-04, -9.4688e-04, -5.1196e-03,  6.2855e-03,  1.2958e-03,\n",
      "        -5.3897e-03,  4.5988e-04,  8.8340e-03,  3.0583e-03, -5.5027e-04,\n",
      "        -6.0252e-03, -4.4623e-03, -1.3331e-03,  1.0621e-03,  6.8278e-03,\n",
      "         2.8725e-03, -1.5715e-02, -8.1494e-04, -9.3553e-04,  3.7950e-03,\n",
      "         9.9445e-03, -6.4098e-03, -6.4667e-03, -5.1381e-03, -7.4098e-03,\n",
      "         8.5730e-03, -5.4039e-03, -1.8498e-03, -1.4792e-04, -3.1167e-03,\n",
      "         4.6104e-03, -1.9824e-03,  1.8572e-03, -3.3358e-04, -5.0284e-03,\n",
      "        -1.9529e-03,  5.2806e-03,  4.8356e-03,  9.5976e-03, -4.2180e-03])}, 6: {'momentum_buffer': tensor([[ 1.3640e-02,  3.4493e-03,  2.7633e-02, -8.6994e-03, -6.8267e-04,\n",
      "          6.0256e-03,  2.9994e-03,  2.0446e-02,  8.9215e-03, -1.9322e-03,\n",
      "          1.3041e-02,  2.8747e-03,  2.3577e-02,  4.4378e-02, -2.3328e-02,\n",
      "          4.1224e-02, -7.9679e-03,  4.4741e-02,  2.6038e-02,  5.9095e-02,\n",
      "          4.3049e-02, -1.0610e-03,  1.3437e-02,  1.5318e-02,  2.1970e-02,\n",
      "          4.2508e-04,  2.8539e-02,  1.3117e-03,  3.1466e-02, -9.0953e-03,\n",
      "          9.3508e-03,  1.8881e-02, -3.5835e-02,  1.0515e-01,  5.5501e-03,\n",
      "          1.6109e-01,  1.7906e-02,  9.3602e-03,  1.3461e-02,  1.4823e-02,\n",
      "         -7.4578e-03, -1.3709e-02,  8.9734e-03, -3.6286e-03,  1.1110e-02,\n",
      "          6.6912e-02,  8.4804e-03, -1.9107e-03,  3.3351e-02,  1.8038e-03],\n",
      "        [ 8.7778e-03,  1.6742e-02,  4.5750e-03,  7.4476e-04, -2.2714e-03,\n",
      "         -4.4653e-02,  8.4005e-03, -1.2355e-01,  3.6870e-02,  3.3531e-04,\n",
      "         -5.3982e-03, -1.7505e-02, -1.3317e-03,  2.5888e-02,  4.9982e-03,\n",
      "          5.5907e-03,  9.3724e-02,  5.2212e-03, -1.1371e-02,  1.9661e-02,\n",
      "          3.5023e-02,  1.0597e-03, -5.2029e-03,  2.4278e-02,  5.4490e-02,\n",
      "          2.9341e-03,  3.4213e-02,  5.0744e-02, -3.5558e-02,  1.5457e-03,\n",
      "          8.1867e-03,  1.4913e-02,  6.1564e-03,  2.0386e-02, -3.5375e-02,\n",
      "          3.6949e-02, -1.8289e-03, -1.1195e-02,  1.0725e-03,  7.2969e-03,\n",
      "         -3.8892e-02,  5.3211e-02,  3.2578e-03,  1.2459e-02, -1.6327e-02,\n",
      "         -2.5362e-03,  1.1328e-02, -5.7767e-03, -3.8832e-02, -4.2063e-04],\n",
      "        [-3.0550e-03, -7.8680e-03,  3.2669e-02, -4.9295e-04, -2.7063e-02,\n",
      "          1.7375e-02,  3.0013e-02, -2.7737e-02, -6.9116e-02,  1.0206e-03,\n",
      "          1.2878e-02, -7.5010e-03, -5.3110e-03,  1.0231e-01,  2.1630e-01,\n",
      "         -1.1139e-01, -2.4043e-02, -7.5016e-02,  4.0751e-03,  5.5810e-02,\n",
      "         -1.3792e-02, -1.4419e-03,  2.0738e-02, -4.2596e-02,  1.9971e-02,\n",
      "          1.5740e-02,  3.4506e-02, -3.1843e-02,  1.1973e-02, -1.0060e-02,\n",
      "         -8.5336e-02, -2.5176e-02, -1.1092e-02,  1.9108e-02, -2.4978e-02,\n",
      "          1.1598e-01,  1.5665e-02,  3.5744e-03, -4.6473e-02, -6.0932e-02,\n",
      "          2.7525e-01,  5.8063e-02, -5.1880e-02,  3.7692e-03,  3.2402e-02,\n",
      "          3.1534e-02,  3.4836e-03,  1.3075e-01, -6.6831e-02,  8.2653e-02],\n",
      "        [-6.5083e-02, -5.5686e-02, -6.3269e-02,  1.5656e-03, -5.8223e-03,\n",
      "          9.0879e-03, -6.3976e-02, -2.2361e-02, -8.5110e-02,  5.1044e-04,\n",
      "          6.4084e-03, -1.8788e-02, -3.7454e-02, -1.7821e-01, -3.1706e-01,\n",
      "          1.4456e-02, -4.0245e-02,  7.9033e-03,  1.4928e-02, -1.8169e-01,\n",
      "         -1.2597e-01, -1.9189e-03, -3.7259e-02,  1.5298e-02,  1.8339e-02,\n",
      "         -3.9225e-03, -2.0145e-01,  6.8914e-03,  2.7975e-02, -1.0609e-02,\n",
      "          1.6920e-02, -1.1374e-02,  2.5314e-03, -6.9533e-02,  9.8546e-03,\n",
      "         -3.4040e-01, -7.2214e-02,  1.0454e-02,  8.1016e-03, -4.1556e-03,\n",
      "         -2.9427e-01, -3.4341e-01,  8.6892e-04,  8.3153e-03, -8.5427e-02,\n",
      "         -1.7832e-01,  1.3619e-03, -1.2365e-01,  4.1043e-03, -1.9919e-01],\n",
      "        [-1.7489e-02,  1.4045e-02,  1.8963e-03,  3.5425e-03, -6.5355e-03,\n",
      "          2.7579e-02, -8.8753e-02,  1.5965e-02,  2.5469e-02,  5.1571e-04,\n",
      "         -8.3465e-02,  2.1243e-02, -2.0041e-02, -5.2686e-04, -4.9013e-03,\n",
      "          3.6531e-03,  3.7028e-02,  1.4894e-02,  1.1601e-02,  1.4395e-04,\n",
      "          1.2672e-02,  1.6096e-03, -1.1445e-02, -2.9796e-02, -1.1431e-04,\n",
      "         -1.1548e-01, -5.0189e-02,  5.3047e-03,  1.0066e-02,  4.2011e-03,\n",
      "         -5.6981e-02, -5.1766e-02,  3.8543e-03,  1.9060e-02,  1.0615e-02,\n",
      "          5.5787e-02,  6.3630e-03, -6.0649e-02, -5.1305e-02,  2.8657e-02,\n",
      "          4.7590e-03, -1.0687e-03, -4.1989e-02, -6.4323e-03,  4.5220e-03,\n",
      "          2.2814e-02, -1.7937e-02,  8.0983e-03, -2.1729e-01,  1.6546e-02],\n",
      "        [ 2.0125e-02,  2.2219e-02,  2.0852e-02,  4.0764e-03,  1.5437e-02,\n",
      "          3.2821e-02,  2.4646e-02,  4.2750e-02,  2.8041e-02,  3.9357e-03,\n",
      "          3.6390e-02,  1.1617e-02,  4.4347e-02,  9.4675e-03,  1.8372e-02,\n",
      "          1.0514e-01,  1.7343e-02,  1.4888e-01,  1.4342e-01,  1.3600e-01,\n",
      "          7.6450e-02,  1.3966e-03,  1.2436e-02, -4.3604e-03, -1.0248e-02,\n",
      "         -4.4584e-04, -6.5390e-02, -1.0986e-02,  5.3386e-02,  2.1834e-02,\n",
      "         -2.2059e-02,  2.8202e-02,  1.5874e-02, -3.8724e-02,  1.6685e-02,\n",
      "          3.9421e-02, -1.9349e-02,  1.6447e-02,  6.4082e-03,  9.0569e-03,\n",
      "          3.0170e-02,  3.6783e-02,  3.7715e-02, -2.6135e-03,  1.8121e-02,\n",
      "          8.4975e-02,  2.0490e-02,  1.1083e-02,  7.3468e-02, -1.2030e-02],\n",
      "        [-6.3484e-04,  2.5180e-03, -7.4974e-02, -6.1773e-03,  3.8865e-03,\n",
      "         -5.1613e-02, -2.2001e-02,  2.7500e-02,  3.7154e-02, -1.6496e-03,\n",
      "          5.4737e-02,  9.0248e-03, -1.7059e-03,  1.9544e-03,  3.5253e-03,\n",
      "         -6.1851e-02,  3.1395e-02,  1.5885e-02, -6.1206e-02, -8.5267e-02,\n",
      "         -6.1166e-03, -2.5177e-03, -5.4916e-02,  6.5725e-03, -1.0711e-02,\n",
      "         -1.0681e-02,  3.9886e-02,  4.6841e-03, -3.9347e-02, -6.9486e-03,\n",
      "          1.6285e-01, -1.7959e-02,  1.3545e-02, -7.3424e-02, -1.2588e-03,\n",
      "         -1.7375e-01,  2.0694e-02, -1.1209e-02,  5.0626e-02, -1.0337e-02,\n",
      "         -7.6474e-03,  1.9094e-02, -5.0515e-03,  1.2856e-02,  5.3139e-03,\n",
      "         -6.2266e-02,  3.6674e-03,  3.3223e-03, -6.3066e-03,  8.7368e-03],\n",
      "        [ 4.2436e-02,  1.7438e-02,  1.4699e-02,  6.9779e-04, -2.5872e-03,\n",
      "          4.6974e-03, -9.1208e-02,  1.9288e-02, -2.1160e-02, -1.6510e-04,\n",
      "          7.5600e-03,  2.6283e-03, -3.1114e-02,  3.0386e-02,  3.2475e-02,\n",
      "          1.1582e-02,  4.9933e-02,  8.1721e-03, -9.1886e-03,  1.5139e-02,\n",
      "          2.2546e-02, -1.8647e-03,  2.1225e-03, -5.0644e-03,  4.0103e-03,\n",
      "         -1.3088e-01,  3.2461e-02, -6.4814e-02, -2.4992e-02, -2.6708e-03,\n",
      "         -1.0898e-03, -1.4724e-02, -1.0444e-02, -3.2933e-02,  8.3496e-03,\n",
      "          1.1257e-02, -3.1017e-02, -2.4980e-02,  5.3184e-03, -2.1854e-02,\n",
      "         -1.4945e-02,  8.6182e-02,  9.1770e-03,  4.8676e-02,  2.7262e-05,\n",
      "         -3.9143e-03,  3.0523e-03, -5.5805e-03,  4.7279e-02,  3.2518e-03],\n",
      "        [ 3.3608e-02, -1.9154e-02,  3.2270e-02,  4.1769e-03,  1.3511e-02,\n",
      "          1.0694e-02,  2.9293e-02,  3.1529e-02,  5.4744e-02, -1.0682e-03,\n",
      "         -1.8172e-03,  8.3533e-03,  3.5179e-02,  5.6258e-03,  8.8118e-02,\n",
      "          4.4649e-03, -3.5759e-02, -1.5949e-01, -9.9400e-02,  3.6455e-03,\n",
      "         -3.5970e-02,  3.5436e-03,  2.8088e-02,  1.0773e-01,  1.3778e-02,\n",
      "          4.8722e-02,  1.4761e-01, -1.4065e-02, -6.9773e-02,  3.8587e-04,\n",
      "         -2.5320e-02,  2.2632e-02,  1.1018e-02,  2.7935e-02, -5.0810e-03,\n",
      "          1.5261e-01,  3.7582e-02,  2.5731e-02, -2.1300e-02,  2.9062e-02,\n",
      "          8.6575e-02,  2.5915e-01,  2.5513e-02,  3.2103e-02,  2.9510e-03,\n",
      "          2.8049e-02, -1.4394e-02, -3.3593e-02,  1.8221e-01,  7.8675e-02],\n",
      "        [-3.2325e-02,  6.2972e-03,  3.6492e-03,  5.6558e-04,  1.2127e-02,\n",
      "         -1.2015e-02,  1.7059e-01,  1.6169e-02, -1.5813e-02, -1.5026e-03,\n",
      "         -4.0334e-02, -1.1947e-02, -6.1445e-03, -4.1278e-02, -1.8497e-02,\n",
      "         -1.2866e-02, -1.2141e-01, -1.1182e-02, -1.8895e-02, -2.2536e-02,\n",
      "         -7.8882e-03,  1.1948e-03,  3.2000e-02, -8.7377e-02, -1.1149e-01,\n",
      "          1.9359e-01, -1.8258e-04,  5.2772e-02,  3.4803e-02,  1.1417e-02,\n",
      "         -6.5225e-03,  3.6371e-02,  4.3917e-03,  2.2973e-02,  1.5638e-02,\n",
      "         -5.8948e-02,  2.6199e-02,  4.2466e-02,  3.4091e-02,  8.3835e-03,\n",
      "         -3.3549e-02, -1.5429e-01,  1.3415e-02, -1.0550e-01,  2.7306e-02,\n",
      "          1.2754e-02, -1.9533e-02,  1.7250e-02, -1.1154e-02,  1.9978e-02]])}, 7: {'momentum_buffer': tensor([ 0.0144,  0.0025,  0.0024, -0.0482,  0.0027,  0.0121,  0.0046,  0.0028,\n",
      "         0.0144, -0.0078])}}, 'param_groups': [{'lr': 0.01, 'momentum': 0.5, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7]}]}\n"
     ]
    }
   ],
   "source": [
    "# First open arrays\n",
    "model_array_1 = tiledb.open('tiledb-pytorch-mnist-1')[:]\n",
    "\n",
    "# Load model state_dict\n",
    "model_1_state_dict = pickle.loads(model_array_1['model_state_dict'].item(0))\n",
    "\n",
    "# Load optimizer state_dict\n",
    "optimizer_1_state_dict = pickle.loads(model_array_1['optimizer_state_dict'].item(0))\n",
    "\n",
    "print(model_1_state_dict)\n",
    "print(optimizer_1_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Moving on, we can load the trained models for prediction, evaluation or retraining, as usual with\n",
    "PyTorch models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Place holder for the loaded model\n",
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "# Load returns possible extra attributes, other than model's and optimizer's state dicts. In case there were\n",
    "# no extra attributes it will return an empty dict\n",
    "_ = tiledb_model_1.load(model=network, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is really nice with saving models as TileDB array, is native versioning based on fragments as described\n",
    "[here](https://docs.tiledb.com/main/basic-concepts/data-format#immutable-fragments). We can load a model, retrain it\n",
    "with new data and update the already existing TileDB model array with new model parameters and metadata. All information, old\n",
    "and new will be there and accessible. This is extremely useful when you retrain with new data or trying different architectures for the same\n",
    "problem, and you want to keep track of all your experiments without having to store different model instances. In our case,\n",
    "let's continue training model_1 with the rest of our dataset and for 2 more epochs. After training is done, you will\n",
    "notice the extra directories and files (fragments) added to tiledb-keras-mnist-sequential-1 TileDB array directory,\n",
    "which keep all versions of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.573581\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.668981\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.641363\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.613981\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.729578\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.647342\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.523893\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.522834\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.553014\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.631665\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.675059\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.577137\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.690339\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.560791\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.448240\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.499283\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.514028\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.574534\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.563722\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.576612\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.602701\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.566739\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.617015\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.532814\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.310423\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.763585\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.419300\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.376709\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.390927\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.455096\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.449101\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.257266\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.583116\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.464200\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.579690\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.418093\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.500246\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.388821\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.571540\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.483734\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.421154\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.396881\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.402959\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.599389\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.601874\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.494976\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.439669\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.404646\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.458129\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.524563\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.338054\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.503622\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.563895\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.483622\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.433404\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.584137\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.460160\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.438504\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.328059\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.366664\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.307853\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.354741\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.338711\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.509960\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.458819\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.290797\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.387099\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.517490\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.290813\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.462535\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.495739\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.353947\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.376202\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.306197\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.477052\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.569357\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.346301\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.343630\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.377869\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.364698\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.401787\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.246437\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.340890\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.340572\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.422975\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.394721\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.268832\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.370986\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.410943\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.325218\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.301102\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.407067\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.368569\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.474715\n",
      "\n",
      "\n",
      "['tiledb-pytorch-mnist-1/__meta',\n",
      " 'tiledb-pytorch-mnist-1/__lock.tdb',\n",
      " 'tiledb-pytorch-mnist-1/__array_schema.tdb',\n",
      " 'tiledb-pytorch-mnist-1/__1617026221818_1617026221818_c46cfa643653480b930b4ef803ce3eac_8.ok',\n",
      " 'tiledb-pytorch-mnist-1/__1617026221818_1617026221818_c46cfa643653480b930b4ef803ce3eac_8',\n",
      " 'tiledb-pytorch-mnist-1/__1617026164071_1617026164071_66e47eea64e44eb9bc296acb9955988a_8',\n",
      " 'tiledb-pytorch-mnist-1/__1617026164071_1617026164071_66e47eea64e44eb9bc296acb9955988a_8.ok']\n",
      "\n",
      "====== FRAGMENTS  INFO ======\n",
      "array uri: tiledb-pytorch-mnist-1\n",
      "number of fragments: 2\n",
      "\n",
      "===== FRAGMENT NUMBER 0 =====\n",
      "fragment uri: file:///Users/george/PycharmProjects/TileDB-ML/example_notebooks/models/tiledb-pytorch-mnist-1/__1617026164071_1617026164071_66e47eea64e44eb9bc296acb9955988a_8\n",
      "is dense: True\n",
      "is sparse: False\n",
      "cell num: 1\n",
      "has consolidated metadata: False\n",
      "non empty domain: ((1, 1),)\n",
      "timestamp range: (1617026164071, 1617026164071)\n",
      "number of fragments to vacuum: 0\n",
      "uri of fragments to vacuum: []\n",
      "number of unconsolidated metadata: 2\n",
      "version: 8\n",
      "\n",
      "===== FRAGMENT NUMBER 1 =====\n",
      "fragment uri: file:///Users/george/PycharmProjects/TileDB-ML/example_notebooks/models/tiledb-pytorch-mnist-1/__1617026221818_1617026221818_c46cfa643653480b930b4ef803ce3eac_8\n",
      "is dense: True\n",
      "is sparse: False\n",
      "cell num: 1\n",
      "has consolidated metadata: False\n",
      "non empty domain: ((1, 1),)\n",
      "timestamp range: (1617026221818, 1617026221818)\n",
      "number of fragments to vacuum: 0\n",
      "uri of fragments to vacuum: []\n",
      "number of unconsolidated metadata: 2\n",
      "version: 8\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "\n",
    "# We train for some extra 2 epochs\n",
    "for epoch in range(1, 2 + 1):\n",
    "  train(epoch)\n",
    "\n",
    "# and update\n",
    "tiledb_model_1.save(update=True, model_info={\n",
    "    'model_state_dict': network.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    },\n",
    "                    meta={'epochs': epochs,\n",
    "                          'train_loss': train_losses})\n",
    "\n",
    "# Check array directory\n",
    "print()\n",
    "pprint(glob.glob('tiledb-pytorch-mnist-1/*'))\n",
    "\n",
    "# tiledb.array_fragments() requires TileDB-Py version > 0.8.5\n",
    "fragments_info = tiledb.array_fragments('tiledb-pytorch-mnist-1')\n",
    "\n",
    "print()\n",
    "print(\"====== FRAGMENTS  INFO ======\")\n",
    "print(\"array uri: {}\".format(fragments_info.array_uri))\n",
    "print(\"number of fragments: {}\".format(len(fragments_info)))\n",
    "\n",
    "for fragment_num, fragment in enumerate(fragments_info, start=1):\n",
    "    print()\n",
    "    print(\"===== FRAGMENT NUMBER {} =====\".format(fragment.num))\n",
    "    print(\"fragment uri: {}\".format(fragment.uri))\n",
    "    print(\"is dense: {}\".format(fragment.dense))\n",
    "    print(\"is sparse: {}\".format(fragment.sparse))\n",
    "    print(\"cell num: {}\".format(fragment.cell_num))\n",
    "    print(\"has consolidated metadata: {}\".format(fragment.has_consolidated_metadata))\n",
    "    print(\"non empty domain: {}\".format(fragment.non_empty_domain))\n",
    "    print(\"timestamp range: {}\".format(fragment.timestamp_range))\n",
    "    print(\"number of fragments to vacuum: {}\".format(fragment.to_vacuum_num))\n",
    "    print(\"uri of fragments to vacuum: {}\".format(fragment.to_vacuum_uri))\n",
    "    print(\n",
    "        \"number of unconsolidated metadata: {}\".format(\n",
    "            fragment.unconsolidated_metadata_num\n",
    "        )\n",
    "    )\n",
    "    print(\"version: {}\".format(fragment.version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, a very interesting and useful, for machine learning models, TileDB feature that is described\n",
    "[here](https://docs.tiledb.com/main/basic-concepts/data-format#groups) and [here](https://docs.tiledb.com/main/solutions/tiledb-embedded/api-usage/object-management#creating-tiledb-groups)\n",
    "are groups. Assuming we want to solve the MNIST problem, and we want to try several architectures. We can save each architecture\n",
    "as a separate TileDB array with native versioning each time it is re-trained, and then organise all models that solve the same problem (MNIST)\n",
    "as a TileDB array group with any kind of hierarchy. Let's firstly define a new model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class OtherNet(nn.Module):\n",
    "    # For the sake of simplicity we just tweak the initial architecture by replacing a relu with relu6.\n",
    "    def __init__(self):\n",
    "        super(OtherNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu6(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then train it and save it as a new TileDB array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.337260\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 1.897245\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 1.235484\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 1.009100\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 1.129466\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.807468\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.628168\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.623165\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.525108\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.639337\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.460995\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.564493\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.600411\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.707955\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.619303\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.562256\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.577714\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.474819\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.435444\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.694258\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.290269\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.514281\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.555931\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.393810\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.478275\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.363487\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.438306\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.553783\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.325208\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.555157\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.488264\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.366434\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.531246\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.347857\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.352849\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.494789\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.445856\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.374059\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.408256\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.324857\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.433975\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.317178\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.402140\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.305382\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.369798\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.484200\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.382847\n"
     ]
    }
   ],
   "source": [
    "network = OtherNet()\n",
    "optimizer = optim.Adam(network.parameters(), lr=learning_rate)\n",
    "\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "\n",
    "tiledb_model_2 = PyTorchTileDB(uri='tiledb-pytorch-mnist-2')\n",
    "\n",
    "tiledb_model_2.save(update=False, model_info={\n",
    "    'model_state_dict': network.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    },\n",
    "                    meta={'epochs': epochs,\n",
    "                          'train_loss': train_losses})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a TileDB group and organise (in hierarchies, e.g., sophisticated vs less sophisticated) all our\n",
    "MNIST models as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tiledb.group_create('MNIST_Group')\n",
    "os.system('mv tiledb-pytorch-mnist-1 MNIST_Group/')\n",
    "os.system('mv tiledb-pytorch-mnist-2 MNIST_Group/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any time we can check and query all the available models, including their metadata, for a specific problem like MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file:///Users/george/PycharmProjects/TileDB-ML/example_notebooks/models/MNIST_Group/tiledb-pytorch-mnist-1 array\n",
      "file:///Users/george/PycharmProjects/TileDB-ML/example_notebooks/models/MNIST_Group/tiledb-pytorch-mnist-2 array\n"
     ]
    }
   ],
   "source": [
    "tiledb.ls('MNIST_Group', lambda obj_path, obj_type: print(obj_path, obj_type))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}