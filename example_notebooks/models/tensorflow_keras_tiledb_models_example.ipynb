{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example notebook shows how we can train an image classification model, as described [here](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb),\n",
    "and store it as TileDB array. Firstly, let's import what we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tiledb\n",
    "import os\n",
    "import json\n",
    "\n",
    "from models.tensorflow_keras_models import TensorflowTileDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load MNIST dataset for Keras datasets and scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then define a function that creates a basic digit classifier for the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=loss_fn,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then train a model using some of our data. Let's assume that we initially train with the first 30000\n",
    "observations from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 1s 702us/step - loss: 0.6236 - accuracy: 0.8197\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 1s 677us/step - loss: 0.1941 - accuracy: 0.9415\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 1s 674us/step - loss: 0.1454 - accuracy: 0.9583\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 1s 674us/step - loss: 0.1131 - accuracy: 0.9660\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 1s 690us/step - loss: 0.0923 - accuracy: 0.9726\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1716654a8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.fit(x_train[:30000], y_train[:30000], epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now save the trained model as a TileDB array. In case we want to train  the model further in a later time, we can save\n",
    "optimizer's information in our TileDB array. In case we will use our model only for inference, we don't have to save optimizer's\n",
    "information and we only keep model's weights. We first declare a TileDB-Keras model object (with the corresponding uri) and then\n",
    "save the model as a TileDB array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tiledb_model_1 = TensorflowTileDB(uri='tiledb-keras-mnist-sequential-1')\n",
    "\n",
    "tiledb_model_1.save(model=model,\n",
    "                    include_optimizer=True,\n",
    "                    update=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above step will create a TileDB array in your working directory. For information about the structure of a dense\n",
    "TileDB array in terms of files on disk please take a look [here](https://docs.tiledb.com/main/basic-concepts/data-format).\n",
    "Let's open our TileDB array model and check metadata. Metadata that are of type list, dict or tuple have been JSON\n",
    "serialized while saving, i.e., we need json.loads to deserialize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: backend, Value: tensorflow\n",
      "Key: keras_version, Value: 2.4.0\n",
      "Key: model_config, Value: {'class_name': 'Sequential', 'config': {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': [None, 28, 28], 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'flatten_3_input'}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'batch_input_shape': [None, 28, 28], 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 128, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.2, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 10, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}]}}\n",
      "Key: python_version, Value: 3.7.3\n",
      "Key: training_config, Value: {'loss': {'class_name': 'SparseCategoricalCrossentropy', 'config': {'reduction': 'auto', 'name': 'sparse_categorical_crossentropy', 'from_logits': True}}, 'metrics': [[{'class_name': 'MeanMetricWrapper', 'config': {'name': 'accuracy', 'dtype': 'float32', 'fn': 'sparse_categorical_accuracy'}}]], 'weighted_metrics': None, 'loss_weights': None, 'optimizer_config': {'class_name': 'Adam', 'config': {'name': 'Adam', 'learning_rate': 0.0010000000474974513, 'decay': 0.0, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'epsilon': 1e-07, 'amsgrad': False}}}\n"
     ]
    }
   ],
   "source": [
    "# Open in write mode in order to add metadata\n",
    "model_array_1 = tiledb.open('tiledb-keras-mnist-sequential-1')\n",
    "for key, value in model_array_1.meta.items():\n",
    "    if isinstance(value, bytes):\n",
    "        value = json.loads(value)\n",
    "    print(\"Key: {}, Value: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, in array's metadata we have by default information about the backend we used for training, keras version,\n",
    "python version, model configuration and training configuration. We can load and check any of the aforementioned without\n",
    "having to load the entire model in memory. Moreover, we can add any kind of extra information about model accuracy, model\n",
    "version, deployment status etc, in the model's metadata either while saving the model, by passing a dictionary with any\n",
    "kind of information, or by opening the TileDB array and adding new keys. Both cases are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: accuracy, Value: [0.890333354473114, 0.9450333118438721, 0.9590333104133606, 0.9666000008583069, 0.9712666869163513]\n",
      "Key: backend, Value: tensorflow\n",
      "Key: keras_version, Value: 2.4.0\n",
      "Key: last_epoch_accuracy, Value: 0.9712666869163513\n",
      "Key: last_epoch_loss, Value: 0.09391548484563828\n",
      "Key: loss, Value: [0.3824021816253662, 0.18665964901447296, 0.13953274488449097, 0.1090812087059021, 0.09391548484563828]\n",
      "Key: model_config, Value: {'class_name': 'Sequential', 'config': {'name': 'sequential_3', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': [None, 28, 28], 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'flatten_3_input'}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_3', 'trainable': True, 'batch_input_shape': [None, 28, 28], 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 128, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.2, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 10, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}]}}\n",
      "Key: python_version, Value: 3.7.3\n",
      "Key: training_config, Value: {'loss': {'class_name': 'SparseCategoricalCrossentropy', 'config': {'reduction': 'auto', 'name': 'sparse_categorical_crossentropy', 'from_logits': True}}, 'metrics': [[{'class_name': 'MeanMetricWrapper', 'config': {'name': 'accuracy', 'dtype': 'float32', 'fn': 'sparse_categorical_accuracy'}}]], 'weighted_metrics': None, 'loss_weights': None, 'optimizer_config': {'class_name': 'Adam', 'config': {'name': 'Adam', 'learning_rate': 0.0010000000474974513, 'decay': 0.0, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'epsilon': 1e-07, 'amsgrad': False}}}\n"
     ]
    }
   ],
   "source": [
    "# Open the array in write mode\n",
    "with tiledb.Array('tiledb-keras-mnist-sequential-1', \"w\") as A:\n",
    "    # Keep all history\n",
    "    A.meta['loss'] = json.dumps(model.history.history['loss'])\n",
    "    A.meta['accuracy'] = json.dumps(model.history.history['accuracy'])\n",
    "\n",
    "    # Or keep last epoch's loss and accuracy\n",
    "    A.meta['last_epoch_loss'] = json.dumps(model.history.history['loss'][-1])\n",
    "    A.meta['last_epoch_accuracy'] = json.dumps(model.history.history['accuracy'][-1])\n",
    "\n",
    "# Check that everything is there\n",
    "model_array_1 = tiledb.open('tiledb-keras-mnist-sequential-1')\n",
    "for key, value in model_array_1.meta.items():\n",
    "    if isinstance(value, bytes):\n",
    "        value = json.loads(value)\n",
    "    print(\"Key: {}, Value: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also save any kind of metadata while saving the model as a TileDB array, and avoid opening it multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 1s 680us/step - loss: 0.6439 - accuracy: 0.8134\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 1s 681us/step - loss: 0.2042 - accuracy: 0.9420\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 1s 676us/step - loss: 0.1414 - accuracy: 0.9596\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 1s 679us/step - loss: 0.1112 - accuracy: 0.9676\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 1s 681us/step - loss: 0.0907 - accuracy: 0.9732\n",
      "Key: accuracy, Value: [0.8869333267211914, 0.9460999965667725, 0.9593333601951599, 0.9661666750907898, 0.9733333587646484]\n",
      "Key: backend, Value: tensorflow\n",
      "Key: keras_version, Value: 2.4.0\n",
      "Key: loss, Value: [0.3882191777229309, 0.19028112292289734, 0.1363549530506134, 0.1107335016131401, 0.09010602533817291]\n",
      "Key: model_config, Value: {'class_name': 'Sequential', 'config': {'name': 'sequential_4', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': [None, 28, 28], 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'flatten_4_input'}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_4', 'trainable': True, 'batch_input_shape': [None, 28, 28], 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 128, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.2, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 10, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}]}}\n",
      "Key: python_version, Value: 3.7.3\n",
      "Key: status, Value: experimental\n",
      "Key: training_config, Value: {'loss': {'class_name': 'SparseCategoricalCrossentropy', 'config': {'reduction': 'auto', 'name': 'sparse_categorical_crossentropy', 'from_logits': True}}, 'metrics': [[{'class_name': 'MeanMetricWrapper', 'config': {'name': 'accuracy', 'dtype': 'float32', 'fn': 'sparse_categorical_accuracy'}}]], 'weighted_metrics': None, 'loss_weights': None, 'optimizer_config': {'class_name': 'Adam', 'config': {'name': 'Adam', 'learning_rate': 0.0010000000474974513, 'decay': 0.0, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'epsilon': 1e-07, 'amsgrad': False}}}\n",
      "Key: version, Value: 0.0.1\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.fit(x_train[:30000], y_train[:30000], epochs=5)\n",
    "\n",
    "tiledb_model_2 = TensorflowTileDB(uri='tiledb-keras-mnist-sequential-2')\n",
    "\n",
    "tiledb_model_2.save(model=model,\n",
    "                    include_optimizer=True,\n",
    "                    update=False,\n",
    "                    meta={\"accuracy\": model.history.history['accuracy'],\n",
    "                          \"loss\": model.history.history['loss'],\n",
    "                          \"version\": '0.0.1',\n",
    "                          \"status\": 'experimental'})\n",
    "\n",
    "# Check that everything is there\n",
    "model_array_1 = tiledb.open('tiledb-keras-mnist-sequential-2')\n",
    "for key, value in model_array_1.meta.items():\n",
    "    if isinstance(value, bytes):\n",
    "        value = json.loads(value)\n",
    "    print(\"Key: {}, Value: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on, we can load the trained models for prediction or evaluation (we have to compile the model), as usual with\n",
    "Tensorflow Keras models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.1279027   -6.568434    -0.4252091  ...  11.660195    -3.3526886\n",
      "   -2.766497  ]\n",
      " [ -3.7407515    2.6952996   11.920709   ... -14.252106     0.44303626\n",
      "  -12.41744   ]\n",
      " [ -4.9525685    6.792746     0.26711312 ...  -0.45758492  -0.30579057\n",
      "   -4.1699696 ]\n",
      " ...\n",
      " [ -6.6460347  -10.294316    -9.749106   ...   1.1787943    1.3536193\n",
      "    2.4386663 ]\n",
      " [ -1.0649565   -5.223176    -9.355335   ...  -1.4681871    1.7254432\n",
      "   -1.9841626 ]\n",
      " [ -1.7826611   -9.365487     0.14322725 ...  -7.296979    -5.360878\n",
      "   -7.2144213 ]]\n",
      "[[ -4.6274433   -9.597495    -0.10862601 ...   9.1714      -2.376289\n",
      "   -4.1253734 ]\n",
      " [ -5.3148026    2.5041955   11.574888   ... -10.034176    -1.2081295\n",
      "   -9.236549  ]\n",
      " [ -6.4843216    6.324581     0.0203052  ...   0.02500642  -1.5317293\n",
      "   -4.378875  ]\n",
      " ...\n",
      " [ -9.435321   -11.73144     -8.514579   ...  -1.1290907   -1.9690759\n",
      "    2.2376351 ]\n",
      " [ -5.9645257   -5.699082    -8.42025    ...  -2.9483845    2.9252856\n",
      "   -6.2881393 ]\n",
      " [ -0.82890916  -7.8822355   -0.46922368 ...  -9.447393    -6.87423\n",
      "   -6.3536887 ]]\n",
      "313/313 [==============================] - 0s 501us/step - loss: 0.0973 - accuracy: 0.9711\n",
      "313/313 [==============================] - 0s 495us/step - loss: 0.0949 - accuracy: 0.9710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09490542113780975, 0.9710000157356262]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model_1 = tiledb_model_1.load()\n",
    "loaded_model_2 = tiledb_model_2.load()\n",
    "\n",
    "# Make some predictions\n",
    "print(loaded_model_1.predict(x_test))\n",
    "print(loaded_model_2.predict(x_test))\n",
    "\n",
    "# Evaluate models\n",
    "loaded_model_1 = tiledb_model_1.load(compile_model=True)\n",
    "loaded_model_2 = tiledb_model_2.load(compile_model=True)\n",
    "loaded_model_1.evaluate(x_test, y_test)\n",
    "loaded_model_2.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is really nice with saving models as TileDB array, is native versioning based on fragments as described\n",
    "[here](https://docs.tiledb.com/main/basic-concepts/data-format#immutable-fragments). We can load a model, retrain it\n",
    "with new data and update the already existing TileDB model array with the new model and metadata. All information, old\n",
    "and new will be there and accessible. This is extremely useful when trying many different architectures for the same\n",
    "problem and you want to keep track of all your experiments without having to store different model instances. In our case,\n",
    "let's continue training model_1 with the rest of our dataset and for 5 more epochs. After training is done, you will\n",
    "notice the extra directories and files (fragments) added to tiledb-keras-mnist-sequential-1 TileDB array directory,\n",
    "which keep all versions of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 1s 675us/step - loss: 0.1329 - accuracy: 0.9608\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 1s 673us/step - loss: 0.0986 - accuracy: 0.9696\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 1s 694us/step - loss: 0.0835 - accuracy: 0.9747\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 1s 670us/step - loss: 0.0718 - accuracy: 0.9771\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 1s 681us/step - loss: 0.0607 - accuracy: 0.9811\n"
     ]
    }
   ],
   "source": [
    "loaded_model_1 = tiledb_model_1.load(compile_model=True)\n",
    "loaded_model_1.fit(x_train[30000:], y_train[30000:], epochs=5)\n",
    "\n",
    "# and update\n",
    "tiledb_model_1.save(model=loaded_model_1,\n",
    "                    include_optimizer=True,\n",
    "                    update=True,\n",
    "                    meta={\"accuracy\": model.history.history['accuracy'],\n",
    "                          \"loss\": model.history.history['loss'],\n",
    "                          \"version\": '0.0.1',\n",
    "                          \"status\": 'experimental'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, a very interesting and useful, for machine learning models, TileDB feature that is described\n",
    "[here](https://docs.tiledb.com/main/basic-concepts/data-format#groups) and [here](https://docs.tiledb.com/main/solutions/tiledb-embedded/api-usage/object-management#creating-tiledb-groups)\n",
    "are groups. Assuming that we want to solve the MNIST problem, and we want to try many different architectures. We can save each architecture\n",
    "separate TileDB array with native versioning each time it's re-trained, and then organise all models that solve the same problem (MNIST)\n",
    "as a TileDB array group. Let's firstly define a new model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_deeper_model():\n",
    "    # For the sake of simplicity we just add an extra dense layer to the previous architecture.\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=loss_fn,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Then train it and save it as a new TileDB array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 2s 810us/step - loss: 0.3965 - accuracy: 0.8840\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 798us/step - loss: 0.1003 - accuracy: 0.9691\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 799us/step - loss: 0.0683 - accuracy: 0.9783\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 2s 808us/step - loss: 0.0543 - accuracy: 0.9831\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 797us/step - loss: 0.0400 - accuracy: 0.9868\n"
     ]
    }
   ],
   "source": [
    "model = create_deeper_model()\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "tiledb_deeper_model = TensorflowTileDB(uri='tiledb-keras-mnist-sequential-deeper')\n",
    "\n",
    "tiledb_deeper_model.save(model=model,\n",
    "                         include_optimizer=True,\n",
    "                         update=False,\n",
    "                        meta={\"accuracy\": model.history.history['accuracy'],\n",
    "                              \"loss\": model.history.history['loss'],\n",
    "                              \"version\": '0.0.1',\n",
    "                              \"status\": 'experimental'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we can create a TileDB group and organise (even in hierarchies, e.g., sophisticated vs less sophisticated) all our\n",
    "MNIST models as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "TileDBError",
     "evalue": "[TileDB::StorageManager] Error: Cannot create group; Group 'file:///Users/george/PycharmProjects/TileDB-ML/example_notebooks/models/MNIST_Group_2' already exists",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTileDBError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-29-65baa25d43a6>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtiledb\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgroup_create\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"MNIST_Group_2\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msystem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"mv tiledb-keras-mnist-sequential-1 MNIST_Group/\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msystem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"mv tiledb-keras-mnist-sequential-2 MNIST_Group/\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msystem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"mv tiledb-keras-mnist-sequential-deeper MNIST_Group/\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mtiledb/libtiledb.pyx\u001B[0m in \u001B[0;36mtiledb.libtiledb.group_create\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mtiledb/libtiledb.pyx\u001B[0m in \u001B[0;36mtiledb.libtiledb.check_error\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mtiledb/libtiledb.pyx\u001B[0m in \u001B[0;36mtiledb.libtiledb._raise_ctx_err\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mtiledb/libtiledb.pyx\u001B[0m in \u001B[0;36mtiledb.libtiledb._raise_tiledb_error\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mTileDBError\u001B[0m: [TileDB::StorageManager] Error: Cannot create group; Group 'file:///Users/george/PycharmProjects/TileDB-ML/example_notebooks/models/MNIST_Group_2' already exists"
     ]
    }
   ],
   "source": [
    "tiledb.group_create('MNIST_Group')\n",
    "os.system('mv tiledb-keras-mnist-sequential-1 MNIST_Group/')\n",
    "os.system('mv tiledb-keras-mnist-sequential-2 MNIST_Group/')\n",
    "os.system('mv tiledb-keras-mnist-sequential-deeper MNIST_Group/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And at any time check what kind of models are there for a specific problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tiledb.ls('MNIST_Group', lambda obj_path, obj_type: print(obj_path, obj_type))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}