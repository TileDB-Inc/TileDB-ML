{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example notebook shows how we can train an image classification model, as described [here](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb),\n",
    "and store it as TileDB array. Firstly, let's import what we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tiledb\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from tiledb.ml.models.tensorflow_keras import TensorflowKerasTileDBModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load MNIST dataset for Keras datasets and scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then define a function that creates a basic digit classifier for the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=loss_fn,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then train a model using some of our data. Let's assume that we initially train with the first 30000\n",
    "observations from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.fit(x_train[:30000], y_train[:30000], epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now save the trained model as a TileDB array. In case we want to train  the model further in a later time, we can save\n",
    "optimizer's information in our TileDB array. In case we will use our model only for inference, we don't have to save optimizer's\n",
    "information and we only keep model's weights. We first declare a TileDB-Keras model object (with the corresponding uri and model attributes)\n",
    "and then save the model as a TileDB array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tiledb_model_1 = TensorflowKerasTileDBModel(uri='tiledb-keras-mnist-sequential-1', model=model)\n",
    "\n",
    "tiledb_model_1.save(include_optimizer=True,\n",
    "                    update=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above step will create a TileDB array in your working directory. For information about the structure of a dense\n",
    "TileDB array in terms of files on disk please take a look [here](https://docs.tiledb.com/main/basic-concepts/data-format).\n",
    "Let's open our TileDB array model and check metadata. Metadata that are of type list, dict or tuple have been JSON\n",
    "serialized while saving, i.e., we need json.loads to deserialize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Check array directory\n",
    "pprint(glob.glob('tiledb-keras-mnist-sequential-1/*'))\n",
    "\n",
    "# Open in write mode in order to add metadata\n",
    "print()\n",
    "model_array_1 = tiledb.open('tiledb-keras-mnist-sequential-1')\n",
    "for key, value in model_array_1.meta.items():\n",
    "    if isinstance(value, bytes):\n",
    "        value = json.loads(value)\n",
    "    print(\"Key: {}, Value: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, in array's metadata we have by default information about the backend we used for training, keras version,\n",
    "python version, model configuration and training configuration. We can load and check any of the aforementioned without\n",
    "having to load the entire model in memory. Moreover, we can add any kind of extra information about model accuracy, model\n",
    "version, deployment status etc, in the model's metadata either while saving the model, by passing a dictionary with any\n",
    "kind of information, or by opening the TileDB array and adding new keys. Both cases are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Open the array in write mode\n",
    "with tiledb.Array('tiledb-keras-mnist-sequential-1', \"w\") as A:\n",
    "    # Keep all history\n",
    "    A.meta['loss'] = json.dumps(model.history.history['loss'])\n",
    "    A.meta['accuracy'] = json.dumps(model.history.history['accuracy'])\n",
    "\n",
    "    # Or keep last epoch's loss and accuracy\n",
    "    A.meta['last_epoch_loss'] = json.dumps(model.history.history['loss'][-1])\n",
    "    A.meta['last_epoch_accuracy'] = json.dumps(model.history.history['accuracy'][-1])\n",
    "\n",
    "# Check that everything is there\n",
    "model_array_1 = tiledb.open('tiledb-keras-mnist-sequential-1')\n",
    "for key, value in model_array_1.meta.items():\n",
    "    if isinstance(value, bytes):\n",
    "        value = json.loads(value)\n",
    "    print(\"Key: {}, Value: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also save any kind of metadata while saving the model as a TileDB array, and avoid opening it multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.fit(x_train[:30000], y_train[:30000], epochs=5)\n",
    "\n",
    "tiledb_model_2 = TensorflowKerasTileDBModel(uri='tiledb-keras-mnist-sequential-2', model=model)\n",
    "\n",
    "tiledb_model_2.save(include_optimizer=True,\n",
    "                    update=False,\n",
    "                    meta={\"accuracy\": model.history.history['accuracy'],\n",
    "                          \"loss\": model.history.history['loss'],\n",
    "                          \"status\": 'experimental'})\n",
    "\n",
    "# Check array directory\n",
    "print()\n",
    "pprint(glob.glob('tiledb-keras-mnist-sequential-2/*'))\n",
    "\n",
    "# Check that everything is there\n",
    "print()\n",
    "model_array_2 = tiledb.open('tiledb-keras-mnist-sequential-2')\n",
    "for key, value in model_array_2.meta.items():\n",
    "    if isinstance(value, bytes):\n",
    "        value = json.loads(value)\n",
    "    print(\"Key: {}, Value: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For the case of Tensorflow Keras models, apart from model configuration (architecture) which is saved in the metadata\n",
    "section of the TileDB array, we save model's weights and optimizer's weights, as variable sized attributes (pickled),\n",
    "i.e., we can open the TileDB and get only the weights of a model or model's optimizer without bringing the whole model in\n",
    "memory. For example, we can load model's and optimizer's weights for models tiledb-keras-mnist-sequential-1 and\n",
    "tiledb-keras-mnist-sequential-2 as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# First open arrays\n",
    "model_array_1 = tiledb.open('tiledb-keras-mnist-sequential-1')[:]\n",
    "model_array_2 = tiledb.open('tiledb-keras-mnist-sequential-2')[:]\n",
    "\n",
    "# Load model weights\n",
    "model_1_weights = pickle.loads(model_array_1['model_weights'].item(0))\n",
    "model_2_weights = pickle.loads(model_array_2['model_weights'].item(0))\n",
    "\n",
    "# Load optimizer weights\n",
    "optimizer_1_weights = pickle.loads(model_array_1['optimizer_weights'].item(0))\n",
    "optimizer_2_weights = pickle.loads(model_array_2['optimizer_weights'].item(0))\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8,10)\n",
    "\n",
    "# Maybe plot a part of layer 1 weights for both NNs\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.suptitle('1st 50x50 weights of layer 1 for NN1 and NN2', size=16, y=0.72)\n",
    "ax1.matshow(model_1_weights[0][:50, :50])\n",
    "ax2.matshow(model_2_weights[0][:50, :50])\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.95)\n",
    "plt.show()\n",
    "\n",
    "# Maybe plot a part of optimizer weights for both NNs\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.suptitle('1st 50x50 optimizer weights for NN1 and NN2', size=16, y=0.72)\n",
    "ax1.matshow(optimizer_1_weights[1][:50, :50])\n",
    "ax2.matshow(optimizer_2_weights[1][:50, :50])\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on, we can load the trained models for prediction or evaluation (we have to compile the model), as usual with\n",
    "Tensorflow Keras models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loaded_model_1 = tiledb_model_1.load()\n",
    "loaded_model_2 = tiledb_model_2.load()\n",
    "\n",
    "# Make some predictions\n",
    "print(loaded_model_1.predict(x_test))\n",
    "print(loaded_model_2.predict(x_test))\n",
    "\n",
    "# Evaluate models\n",
    "loaded_model_1 = tiledb_model_1.load(compile_model=True)\n",
    "loaded_model_2 = tiledb_model_2.load(compile_model=True)\n",
    "loaded_model_1.evaluate(x_test, y_test)\n",
    "loaded_model_2.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is really nice with saving models as TileDB array, is native versioning based on fragments as described\n",
    "[here](https://docs.tiledb.com/main/basic-concepts/data-format#immutable-fragments). We can load a model, retrain it\n",
    "with new data and update the already existing TileDB model array with new model parameters and metadata. All information, old\n",
    "and new will be there and accessible. This is extremely useful when you retrain with new data or trying different architectures\n",
    "for the same problem, and you want to keep track of all your experiments without having to store different model instances. In our case,\n",
    "let's continue training model_1 with the rest of our dataset and for 5 more epochs. After training is done, you will\n",
    "notice the extra directories and files (fragments) added to tiledb-keras-mnist-sequential-1 TileDB array directory,\n",
    "which keep all versions of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loaded_model_1 = tiledb_model_1.load(compile_model=True)\n",
    "loaded_model_1.fit(x_train[30000:], y_train[30000:], epochs=5)\n",
    "\n",
    "# and update\n",
    "tiledb_model_1 = TensorflowKerasTileDBModel(uri='tiledb-keras-mnist-sequential-1', model=loaded_model_1)\n",
    "tiledb_model_1.save(include_optimizer=True,\n",
    "                    update=True,\n",
    "                    meta={\"accuracy\": model.history.history['accuracy'],\n",
    "                          \"loss\": model.history.history['loss'],\n",
    "                          \"version\": '0.0.1',\n",
    "                          \"status\": 'experimental'})\n",
    "\n",
    "# Check array directory\n",
    "print()\n",
    "pprint(glob.glob('tiledb-keras-mnist-sequential-1/*'))\n",
    "\n",
    "# tiledb.array_fragments() requires TileDB-Py version > 0.8.5\n",
    "fragments_info = tiledb.array_fragments('tiledb-keras-mnist-sequential-1')\n",
    "\n",
    "print()\n",
    "print(\"====== FRAGMENTS  INFO ======\")\n",
    "print(\"array uri: {}\".format(fragments_info.array_uri))\n",
    "print(\"number of fragments: {}\".format(len(fragments_info)))\n",
    "\n",
    "for fragment_num, fragment in enumerate(fragments_info, start=1):\n",
    "    print()\n",
    "    print(\"===== FRAGMENT NUMBER {} =====\".format(fragment.num))\n",
    "    print(\"fragment uri: {}\".format(fragment.uri))\n",
    "    print(\"is dense: {}\".format(fragment.dense))\n",
    "    print(\"is sparse: {}\".format(fragment.sparse))\n",
    "    print(\"cell num: {}\".format(fragment.cell_num))\n",
    "    print(\"has consolidated metadata: {}\".format(fragment.has_consolidated_metadata))\n",
    "    print(\"non empty domain: {}\".format(fragment.non_empty_domain))\n",
    "    print(\"timestamp range: {}\".format(fragment.timestamp_range))\n",
    "    print(\"number of fragments to vacuum: {}\".format(fragment.to_vacuum_num))\n",
    "    print(\"uri of fragments to vacuum: {}\".format(fragment.to_vacuum_uri))\n",
    "    print(\n",
    "        \"number of unconsolidated metadata: {}\".format(\n",
    "            fragment.unconsolidated_metadata_num\n",
    "        )\n",
    "    )\n",
    "    print(\"version: {}\".format(fragment.version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, a very interesting and useful, for machine learning models, TileDB feature that is described\n",
    "[here](https://docs.tiledb.com/main/basic-concepts/data-format#groups) and [here](https://docs.tiledb.com/main/solutions/tiledb-embedded/api-usage/object-management#creating-tiledb-groups)\n",
    "are groups. Assuming we want to solve the MNIST problem, and we want to try several architectures. We can save each architecture\n",
    "as a separate TileDB array with native versioning each time it is re-trained, and then organise all models that solve the same problem (MNIST)\n",
    "as a TileDB array group with any kind of hierarchy. Let's firstly define a new model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_deeper_model():\n",
    "    # For the sake of simplicity we just add an extra dense layer to the previous architecture.\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=loss_fn,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Then train it and save it as a new TileDB array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = create_deeper_model()\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "tiledb_deeper_model = TensorflowKerasTileDBModel(uri='tiledb-keras-mnist-sequential-deeper', model=model)\n",
    "\n",
    "tiledb_deeper_model.save(include_optimizer=True,\n",
    "                         update=False,\n",
    "                         meta={\"accuracy\": model.history.history['accuracy'],\n",
    "                               \"loss\": model.history.history['loss'],\n",
    "                               \"status\": 'experimental'})\n",
    "\n",
    "# Check array directory\n",
    "print()\n",
    "pprint(glob.glob('tiledb-keras-mnist-sequential-deeper/*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we can create a TileDB group and organise (in hierarchies, e.g., sophisticated vs less sophisticated) all our\n",
    "MNIST models as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tiledb.group_create('MNIST_Group')\n",
    "os.system('mv tiledb-keras-mnist-sequential-1 MNIST_Group/')\n",
    "os.system('mv tiledb-keras-mnist-sequential-2 MNIST_Group/')\n",
    "os.system('mv tiledb-keras-mnist-sequential-deeper MNIST_Group/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Any time we can check and query all the available models, including their metadata, for a specific problem like MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tiledb.ls('MNIST_Group', lambda obj_path, obj_type: print(obj_path, obj_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Subclassing\n",
    "\n",
    "Apart from being able to store models, which have been created with Symbolic APIs\n",
    "(Sequential, Functional) someone can store models that are being designed based on\n",
    "Imperative API (aka. Model Subclassing).\n",
    "\n",
    "Let's first design a simple model:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self, hidden_units):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.hidden_units = hidden_units\n",
    "        self.dense_layers = [keras.layers.Dense(u) for u in hidden_units]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.dense_layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"hidden_units\": self.hidden_units}\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we can create a trivial input dataset for testing the model. Remember that\n",
    "for custom models to be initialised they need to be called on data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = CustomModel([16, 16, 10])\n",
    "# Build the model by calling it\n",
    "input_arr = tf.random.uniform((1, 5))\n",
    "outputs = model(input_arr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We then can save the model as a TileDB array."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tiledb_model_custom = TensorflowKerasTileDBModel(uri='tiledb-keras-custom-model', model=model)\n",
    "tiledb_model_custom.save(include_optimizer=True, update=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading the subclassed model requires `custom_objects` to be passed as an argument\n",
    "and the `input_shape` of the model so it can be built. The output of two models are\n",
    "exactly the same"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loaded_custom = tiledb_model_custom.load(custom_objects={\"CustomModel\": CustomModel}, input_shape=(1, 5))\n",
    "outputs_loaded = loaded_custom((1, 5))\n",
    "outputs == outputs_loaded"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}