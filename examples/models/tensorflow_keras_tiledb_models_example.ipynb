{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example notebook shows how we can train an image classification model, as described [here](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb),\n",
    "and store it as TileDB array. Firstly, let's import what we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tiledb\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from tiledb.ml.models.tensorflow_keras import TensorflowKerasTileDBModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load MNIST dataset for Keras datasets and scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then define a function that creates a basic digit classifier for the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=loss_fn,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then train a model using some of our data. Let's assume that we initially train with the first 30000\n",
    "observations from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 1s 781us/step - loss: 0.3860 - accuracy: 0.8908\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 1s 754us/step - loss: 0.1857 - accuracy: 0.9459\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 1s 721us/step - loss: 0.1367 - accuracy: 0.9601\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 1s 700us/step - loss: 0.1092 - accuracy: 0.9674\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 1s 745us/step - loss: 0.0901 - accuracy: 0.9720\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x189bd5910>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "cb = [tf.keras.callbacks.TensorBoard(log_dir='./logs')]\n",
    "model.fit(x_train[:30000], y_train[:30000], epochs=5, callbacks=cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now save the trained model as a TileDB array. In case we want to train  the model further in a later time, we can save\n",
    "optimizer's information in our TileDB array. In case we will use our model only for inference, we don't have to save optimizer's\n",
    "information and we only keep model's weights. We first declare a TileDB-Keras model object (with the corresponding uri and model attributes)\n",
    "and then save the model as a TileDB array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "b'\\x80\\x05\\x958\\x85\\x00\\x00\\x00\\x00\\x00\\x00B1\\x85\\x00\\x00\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xa3\\x7fK\"\\t\\x00\\x00\\x00\\x9e\\x97\\x97\\xd8A\\x1a\\rbrain.Event:2&w\\xff\\xfc\\xdd\\x05\\x00\\x00\\x00\\x00\\x00\\x00%nF\\x8c\\t\\xab\\xb4\\x0f\\x9e\\x97\\x97\\xd8A*\\xd1\\x0b\\n\\xce\\x0b\\n\\x05kerasB\\xaa\\x0b\\x08\\x07\\x12\\x00B\\xa3\\x0b{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 28, 28], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"flatten_input\"}}, {\"class_name\": \"Flatten\", \"config\": {\"name\": \"flatten\", \"trainable\": true, \"batch_input_shape\": [null, 28, 28], \"dtype\": \"float32\", \"data_format\": \"channels_last\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 128, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dropout\", \"config\": {\"name\": \"dropout\", \"trainable\": true, \"dtype\": \"float32\", \"rate\": 0.2, \"noise_shape\": null, \"seed\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 10, \"activation\": \"linear\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.5.0\", \"backend\": \"tensorflow\"}J\\x18\\n\\x16\\n\\x11graph_keras_model\\x12\\x011s\\xfd&\\xab\\xcb|\\x00\\x00\\x00\\x00\\x00\\x000\\x01\\x9b\\xf7\\t\\x7f\\xf6#\\x9e\\x97\\x97\\xd8A\"\\xbe\\xf9\\x01\\nm\\n\\x08iterator\\x12\\x0bPlaceholder*\"\\n\\x14_user_specified_name\\x12\\n\\x12\\x08iterator*\\x0b\\n\\x05dtype\\x12\\x020\\x14*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x0b\\n\\x05shape\\x12\\x02:\\x00\\no\\n\\niterator_1\\x12\\x0bPlaceholder*\\x0b\\n\\x05shape\\x12\\x02:\\x00*\"\\n\\x14_user_specified_name\\x12\\n\\x12\\x08iterator*\\x0b\\n\\x05dtype\\x12\\x020\\x15*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\xd8\\x01\\n\\x0fIteratorGetNext\\x12\\x0fIteratorGetNext\\x1a\\x08iterator*\\x16\\n\\x0coutput_types\\x12\\x06\\n\\x042\\x02\\x01\\x04*9\\n\\routput_shapes\\x12(\\n&:\\x15\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x12\\x02\\x08\\x1c\\x12\\x02\\x08\\x1c:\\r\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01*\\x1b\\n\\x06_class\\x12\\x11\\n\\x0f\\x12\\rloc:@iterator*:\\n\\x0e_output_shapes\\x12(\\n&:\\x15\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x12\\x02\\x08\\x1c\\x12\\x02\\x08\\x1c:\\r\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\nY\\n\\x0eExpandDims/dim\\x12\\x05Const*\\x0b\\n\\x05dtype\\x12\\x020\\x03*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x1b\\n\\x05value\\x12\\x12B\\x10\\x08\\x03\\x12\\x00:\\n\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\ny\\n\\nExpandDims\\x12\\nExpandDims\\x1a\\x11IteratorGetNext:1\\x1a\\x0eExpandDims/dim*\\'\\n\\x0e_output_shapes\\x12\\x15\\n\\x13:\\x11\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x12\\x02\\x08\\x01*\\n\\n\\x04Tdim\\x12\\x020\\x03*\\x07\\n\\x01T\\x12\\x020\\x04\\ni\\n\\x18sequential/flatten/Const\\x12\\x05Const*\\x1d\\n\\x05value\\x12\\x14B\\x12\\x08\\x03\\x12\\x04\\x12\\x02\\x08\\x02\"\\x08\\xff\\xff\\xff\\xff\\x10\\x03\\x00\\x00*\\x0b\\n\\x05dtype\\x12\\x020\\x03*\\x1a\\n\\x0e_output_shapes\\x12\\x08\\n\\x06:\\x04\\x12\\x02\\x08\\x02\\n\\x91\\x01\\n\\x1asequential/flatten/Reshape\\x12\\x07Reshape\\x1a\\x0fIteratorGetNext\\x1a\\x18sequential/flatten/Const*(\\n\\x0e_output_shapes\\x12\\x16\\n\\x14:\\x12\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x12\\x03\\x08\\x90\\x06*\\x07\\n\\x01T\\x12\\x020\\x01*\\x0c\\n\\x06Tshape\\x12\\x020\\x03\\np\\n/sequential/dense/MatMul/ReadVariableOp/resource\\x12\\x0bPlaceholder*\\x0b\\n\\x05dtype\\x12\\x020\\x14*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x0b\\n\\x05shape\\x12\\x02:\\x00\\n\\x98\\x01\\n&sequential/dense/MatMul/ReadVariableOp\\x12\\x0eReadVariableOp\\x1a/sequential/dense/MatMul/ReadVariableOp/resource*\\x0b\\n\\x05dtype\\x12\\x020\\x01* \\n\\x0e_output_shapes\\x12\\x0e\\n\\x0c:\\n\\x12\\x03\\x08\\x90\\x06\\x12\\x03\\x08\\x80\\x01\\n\\xbe\\x01\\n\\x17sequential/dense/MatMul\\x12\\x06MatMul\\x1a\\x1asequential/flatten/Reshape\\x1a&sequential/dense/MatMul/ReadVariableOp*\\x11\\n\\x0btranspose_b\\x12\\x02(\\x00*\\x07\\n\\x01T\\x12\\x020\\x01*\\x11\\n\\x0btranspose_a\\x12\\x02(\\x00*(\\n\\x0e_output_shapes\\x12\\x16\\n\\x14:\\x12\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x12\\x03\\x08\\x80\\x01\\nq\\n0sequential/dense/BiasAdd/ReadVariableOp/resource\\x12\\x0bPlaceholder*\\x0b\\n\\x05dtype\\x12\\x020\\x14*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x0b\\n\\x05shape\\x12\\x02:\\x00\\n\\x95\\x01\\n\\'sequential/dense/BiasAdd/ReadVariableOp\\x12\\x0eReadVariableOp\\x1a0sequential/dense/BiasAdd/ReadVariableOp/resource*\\x0b\\n\\x05dtype\\x12\\x020\\x01*\\x1b\\n\\x0e_output_shapes\\x12\\t\\n\\x07:\\x05\\x12\\x03\\x08\\x80\\x01\\n\\xaf\\x01\\n\\x18sequential/dense/BiasAdd\\x12\\x07BiasAdd\\x1a\\x17sequential/dense/MatMul\\x1a\\'sequential/dense/BiasAdd/ReadVariableOp*\\x07\\n\\x01T\\x12\\x020\\x01*\\x15\\n\\x0bdata_format\\x12\\x06\\x12\\x04NHWC*(\\n\\x0e_output_shapes\\x12\\x16\\n\\x14:\\x12\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x12\\x03\\x08\\x80\\x01\\nj\\n\\x15sequential/dense/Relu\\x12\\x04Relu\\x1a\\x18sequential/dense/BiasAdd*\\x07\\n\\x01T\\x12\\x020\\x01*(\\n\\x0e_output_shapes\\x12\\x16\\n\\x14:\\x12\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x12\\x03\\x08\\x80\\x01\\ne\\n sequential/dropout/dropout/Const\\x12\\x05Const*\\x0b\\n\\x05dtype\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x15\\n\\x05value\\x12\\x0cB\\n\\x08\\x01\\x12\\x00*\\x04\\x00\\x00\\xa0?\\n\\x91\\x01\\n\\x1esequential/dropout/dropout/Mul\\x12\\x03Mul\\x1a\\x15sequential/dense/Relu\\x1a sequential/dropout/dropout/Const*\\x07\\n\\x01T\\x12\\x020\\x01*(\\n\\x0e_output_shapes\\x12\\x16\\n\\x14:\\x12\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x12\\x03\\x08\\x80\\x01\\nu\\n sequential/dropout/dropout/Shape\\x12\\x05Shape\\x1a\\x15sequential/dense/Relu*\\x1a\\n\\x0e_output_shapes\\x12\\x08\\n\\x06:\\x04\\x12\\x02\\x08\\x02*\\x07\\n\\x01T\\x12\\x020\\x01*\\x0e\\n\\x08out_type\\x12\\x020\\x03\\n\\xc3\\x01\\n7sequential/dropout/dropout/random_uniform/RandomUniform\\x12\\rRandomUniform\\x1a sequential/dropout/dropout/Shape*\\x07\\n\\x01T\\x12\\x020\\x03*\\x0b\\n\\x05dtype\\x12\\x020\\x01*\\x0b\\n\\x05seed2\\x12\\x02\\x18\\x00*(\\n\\x0e_output_shapes\\x12\\x16\\n\\x14:\\x12\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x12\\x03\\x08\\x80\\x01*\\n\\n\\x04seed\\x12\\x02\\x18\\x00\\nn\\n)sequential/dropout/dropout/GreaterEqual/y\\x12\\x05Const*\\x15\\n\\x05value\\x12\\x0cB\\n\\x08\\x01\\x12\\x00*\\x04\\xcd\\xccL>*\\x0b\\n\\x05dtype\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\xce\\x01\\n\\'sequential/dropout/dropout/GreaterEqual\\x12\\x0cGreaterEqual\\x1a7sequential/dropout/dropout/random_uniform/RandomUniform\\x1a)sequential/dropout/dropout/GreaterEqual/y*\\x07\\n\\x01T\\x12\\x020\\x01*(\\n\\x0e_output_shapes\\x12\\x16\\n\\x14:\\x12\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x12\\x03\\x08\\x80\\x01\\n\\xa2\\x01\\n\\x1fsequential/dropout/dropout/Cast\\x12\\x04Cast\\x1a\\'sequential/dropout/dropout/GreaterEqual*\\x0e\\n\\x08Truncate\\x12\\x02(\\x00*(\\n\\x0e_output_shapes\\x12\\x16\\n\\x14:\\x12\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x12\\x03\\x08\\x80\\x01*\\n\\n\\x04DstT\\x12\\x020\\x01*\\n\\n\\x04SrcT\\x12\\x020\\n\\n\\x9b\\x01\\n sequential/dropout/dropout/Mul_1\\x12\\x03Mul\\x1a\\x1esequential/dropout/dropout/Mul\\x1a\\x1fsequential/dropout/dropout/Cast*\\x07\\n\\x01T\\x12\\x020\\x01*(\\n\\x0e_output_shapes\\x12\\x16\\n\\x14:\\x12\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x12\\x03\\x08\\x80\\x01\\nr\\n1sequential/dense_1/MatMul/ReadVariableOp/resource\\x12\\x0bPlaceholder*\\x0b\\n\\x05dtype\\x12\\x020\\x14*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x0b\\n\\x05shape\\x12\\x02:\\x00\\n\\x9b\\x01\\n(sequential/dense_1/MatMul/ReadVariableOp\\x12\\x0eReadVariableOp\\x1a1sequential/dense_1/MatMul/ReadVariableOp/resource*\\x0b\\n\\x05dtype\\x12\\x020\\x01*\\x1f\\n\\x0e_output_shapes\\x12\\r\\n\\x0b:\\t\\x12\\x03\\x08\\x80\\x01\\x12\\x02\\x08\\n\\n\\xc7\\x01\\n\\x19sequential/dense_1/MatMul\\x12\\x06MatMul\\x1a sequential/dropout/dropout/Mul_1\\x1a(sequential/dense_1/MatMul/ReadVariableOp*\\x07\\n\\x01T\\x12\\x020\\x01*\\x11\\n\\x0btranspose_a\\x12\\x02(\\x00*\\'\\n\\x0e_output_shapes\\x12\\x15\\n\\x13:\\x11\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x12\\x02\\x08\\n*\\x11\\n\\x0btranspose_b\\x12\\x02(\\x00\\ns\\n2sequential/dense_1/BiasAdd/ReadVariableOp/resource\\x12\\x0bPlaceholder*\\x0b\\n\\x05dtype\\x12\\x020\\x14*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x0b\\n\\x05shape\\x12\\x02:\\x00\\n\\x98\\x01\\n)sequential/dense_1/BiasAdd/ReadVariableOp\\x12\\x0eReadVariableOp\\x1a2sequential/dense_1/BiasAdd/ReadVariableOp/resource*\\x0b\\n\\x05dtype\\x12\\x020\\x01*\\x1a\\n\\x0e_output_shapes\\x12\\x08\\n\\x06:\\x04\\x12\\x02\\x08\\n\\n\\xb4\\x01\\n\\x1asequential/dense_1/BiasAdd\\x12\\x07BiasAdd\\x1a\\x19sequential/dense_1/MatMul\\x1a)sequential/dense_1/BiasAdd/ReadVariableOp*\\x15\\n\\x0bdata_format\\x12\\x06\\x12\\x04NHWC*\\'\\n\\x0e_output_shapes\\x12\\x15\\n\\x13:\\x11\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x12\\x02\\x08\\n*\\x07\\n\\x01T\\x12\\x020\\x01\\n\\x89\\x01\\n$sparse_categorical_crossentropy/Cast\\x12\\x04Cast\\x1a\\nExpandDims*\\n\\n\\x04SrcT\\x12\\x020\\x04*\\x0e\\n\\x08Truncate\\x12\\x02(\\x00*\\n\\n\\x04DstT\\x12\\x020\\x01*\\'\\n\\x0e_output_shapes\\x12\\x15\\n\\x13:\\x11\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x12\\x02\\x08\\x01\\n\\xa5\\x01\\n&sparse_categorical_crossentropy/Cast_1\\x12\\x04Cast\\x1a$sparse_categorical_crossentropy/Cast*\\n\\n\\x04SrcT\\x12\\x020\\x01*\\x0e\\n\\x08Truncate\\x12\\x02(\\x00*\\'\\n\\x0e_output_shapes\\x12\\x15\\n\\x13:\\x11\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x12\\x02\\x08\\x01*\\n\\n\\x04DstT\\x12\\x020\\t\\n\\x7f\\n%sparse_categorical_crossentropy/Shape\\x12\\x05Shape\\x1a\\x1asequential/dense_1/BiasAdd*\\x07\\n\\x01T\\x12\\x020\\x01*\\x0e\\n\\x08out_type\\x12\\x020\\x03*\\x1a\\n\\x0e_output_shapes\\x12\\x08\\n\\x06:\\x04\\x12\\x02\\x08\\x02\\n\\x80\\x01\\n-sparse_categorical_crossentropy/Reshape/shape\\x12\\x05Const*\\x0b\\n\\x05dtype\\x12\\x020\\x03*\\x1a\\n\\x0e_output_shapes\\x12\\x08\\n\\x06:\\x04\\x12\\x02\\x08\\x01*\\x1f\\n\\x05value\\x12\\x16B\\x14\\x08\\x03\\x12\\x04\\x12\\x02\\x08\\x01:\\n\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\n\\xc5\\x01\\n\\'sparse_categorical_crossentropy/Reshape\\x12\\x07Reshape\\x1a&sparse_categorical_crossentropy/Cast_1\\x1a-sparse_categorical_crossentropy/Reshape/shape*\\x07\\n\\x01T\\x12\\x020\\t*\\x0c\\n\\x06Tshape\\x12\\x020\\x03*#\\n\\x0e_output_shapes\\x12\\x11\\n\\x0f:\\r\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\n\\x86\\x01\\n3sparse_categorical_crossentropy/strided_slice/stack\\x12\\x05Const*\\x1f\\n\\x05value\\x12\\x16B\\x14\\x08\\x03\\x12\\x04\\x12\\x02\\x08\\x01:\\n\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01*\\x0b\\n\\x05dtype\\x12\\x020\\x03*\\x1a\\n\\x0e_output_shapes\\x12\\x08\\n\\x06:\\x04\\x12\\x02\\x08\\x01\\n\\x7f\\n5sparse_categorical_crossentropy/strided_slice/stack_1\\x12\\x05Const*\\x16\\n\\x05value\\x12\\rB\\x0b\\x08\\x03\\x12\\x04\\x12\\x02\\x08\\x01:\\x01\\x00*\\x0b\\n\\x05dtype\\x12\\x020\\x03*\\x1a\\n\\x0e_output_shapes\\x12\\x08\\n\\x06:\\x04\\x12\\x02\\x08\\x01\\n\\x7f\\n5sparse_categorical_crossentropy/strided_slice/stack_2\\x12\\x05Const*\\x16\\n\\x05value\\x12\\rB\\x0b\\x08\\x03\\x12\\x04\\x12\\x02\\x08\\x01:\\x01\\x01*\\x0b\\n\\x05dtype\\x12\\x020\\x03*\\x1a\\n\\x0e_output_shapes\\x12\\x08\\n\\x06:\\x04\\x12\\x02\\x08\\x01\\n\\x99\\x03\\n-sparse_categorical_crossentropy/strided_slice\\x12\\x0cStridedSlice\\x1a%sparse_categorical_crossentropy/Shape\\x1a3sparse_categorical_crossentropy/strided_slice/stack\\x1a5sparse_categorical_crossentropy/strided_slice/stack_1\\x1a5sparse_categorical_crossentropy/strided_slice/stack_2*\\x0b\\n\\x05Index\\x12\\x020\\x03*\\x07\\n\\x01T\\x12\\x020\\x03*\\x16\\n\\x10shrink_axis_mask\\x12\\x02\\x18\\x01*\\x13\\n\\rellipsis_mask\\x12\\x02\\x18\\x00*\\x10\\n\\nbegin_mask\\x12\\x02\\x18\\x00*\\x13\\n\\rnew_axis_mask\\x12\\x02\\x18\\x00*\\x0e\\n\\x08end_mask\\x12\\x02\\x18\\x00*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n|\\n1sparse_categorical_crossentropy/Reshape_1/shape/0\\x12\\x05Const*\\x1b\\n\\x05value\\x12\\x12B\\x10\\x08\\x03\\x12\\x00:\\n\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01*\\x0b\\n\\x05dtype\\x12\\x020\\x03*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\xd3\\x01\\n/sparse_categorical_crossentropy/Reshape_1/shape\\x12\\x04Pack\\x1a1sparse_categorical_crossentropy/Reshape_1/shape/0\\x1a-sparse_categorical_crossentropy/strided_slice*\\x07\\n\\x01T\\x12\\x020\\x03*\\n\\n\\x04axis\\x12\\x02\\x18\\x00*\\x07\\n\\x01N\\x12\\x02\\x18\\x02*\\x1a\\n\\x0e_output_shapes\\x12\\x08\\n\\x06:\\x04\\x12\\x02\\x08\\x02\\n\\xca\\x01\\n)sparse_categorical_crossentropy/Reshape_1\\x12\\x07Reshape\\x1a\\x1asequential/dense_1/BiasAdd\\x1a/sparse_categorical_crossentropy/Reshape_1/shape*\\x07\\n\\x01T\\x12\\x020\\x01*\\x0c\\n\\x06Tshape\\x12\\x020\\x03*0\\n\\x0e_output_shapes\\x12\\x1e\\n\\x1c:\\x1a\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\n\\xb0\\x01\\nIsparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/Shape\\x12\\x05Shape\\x1a\\'sparse_categorical_crossentropy/Reshape*\\x1a\\n\\x0e_output_shapes\\x12\\x08\\n\\x06:\\x04\\x12\\x02\\x08\\x01*\\x07\\n\\x01T\\x12\\x020\\t*\\x0e\\n\\x08out_type\\x12\\x020\\x03\\n\\xbb\\x02\\ngsparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\\x12#SparseSoftmaxCrossEntropyWithLogits\\x1a)sparse_categorical_crossentropy/Reshape_1\\x1a\\'sparse_categorical_crossentropy/Reshape*\\x07\\n\\x01T\\x12\\x020\\x01*\\r\\n\\x07Tlabels\\x12\\x020\\t*?\\n\\x0e_output_shapes\\x12-\\n+:\\r\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01:\\x1a\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\nx\\n3sparse_categorical_crossentropy/weighted_loss/Const\\x12\\x05Const*\\x15\\n\\x05value\\x12\\x0cB\\n\\x08\\x01\\x12\\x00*\\x04\\x00\\x00\\x80?*\\x0b\\n\\x05dtype\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\x84\\x02\\n1sparse_categorical_crossentropy/weighted_loss/Mul\\x12\\x03Mul\\x1agsparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\\x1a3sparse_categorical_crossentropy/weighted_loss/Const*\\x07\\n\\x01T\\x12\\x020\\x01*#\\n\\x0e_output_shapes\\x12\\x11\\n\\x0f:\\r\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\n\\x7f\\n5sparse_categorical_crossentropy/weighted_loss/Const_1\\x12\\x05Const*\\x16\\n\\x05value\\x12\\rB\\x0b\\x08\\x03\\x12\\x04\\x12\\x02\\x08\\x01:\\x01\\x00*\\x0b\\n\\x05dtype\\x12\\x020\\x03*\\x1a\\n\\x0e_output_shapes\\x12\\x08\\n\\x06:\\x04\\x12\\x02\\x08\\x01\\n\\xe0\\x01\\n1sparse_categorical_crossentropy/weighted_loss/Sum\\x12\\x03Sum\\x1a1sparse_categorical_crossentropy/weighted_loss/Mul\\x1a5sparse_categorical_crossentropy/weighted_loss/Const_1*\\n\\n\\x04Tidx\\x12\\x020\\x03*\\x0f\\n\\tkeep_dims\\x12\\x02(\\x00*\\x07\\n\\x01T\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\xa6\\x01\\n:sparse_categorical_crossentropy/weighted_loss/num_elements\\x12\\x04Size\\x1a1sparse_categorical_crossentropy/weighted_loss/Mul*\\x07\\n\\x01T\\x12\\x020\\x01*\\x0e\\n\\x08out_type\\x12\\x020\\x03*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\xc3\\x01\\n?sparse_categorical_crossentropy/weighted_loss/num_elements/Cast\\x12\\x04Cast\\x1a:sparse_categorical_crossentropy/weighted_loss/num_elements*\\x0e\\n\\x08Truncate\\x12\\x02(\\x00*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\n\\n\\x04DstT\\x12\\x020\\x01*\\n\\n\\x04SrcT\\x12\\x020\\x03\\nt\\n2sparse_categorical_crossentropy/weighted_loss/Rank\\x12\\x05Const*\\x12\\n\\x05value\\x12\\tB\\x07\\x08\\x03\\x12\\x00:\\x01\\x00*\\x0b\\n\\x05dtype\\x12\\x020\\x03*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n{\\n9sparse_categorical_crossentropy/weighted_loss/range/start\\x12\\x05Const*\\x0b\\n\\x05dtype\\x12\\x020\\x03*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x12\\n\\x05value\\x12\\tB\\x07\\x08\\x03\\x12\\x00:\\x01\\x00\\n{\\n9sparse_categorical_crossentropy/weighted_loss/range/delta\\x12\\x05Const*\\x12\\n\\x05value\\x12\\tB\\x07\\x08\\x03\\x12\\x00:\\x01\\x01*\\x0b\\n\\x05dtype\\x12\\x020\\x03*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\x8c\\x02\\n3sparse_categorical_crossentropy/weighted_loss/range\\x12\\x05Range\\x1a9sparse_categorical_crossentropy/weighted_loss/range/start\\x1a2sparse_categorical_crossentropy/weighted_loss/Rank\\x1a9sparse_categorical_crossentropy/weighted_loss/range/delta*\\x18\\n\\x0e_output_shapes\\x12\\x06\\n\\x04:\\x02\\x12\\x00*\\n\\n\\x04Tidx\\x12\\x020\\x03\\n\\xe0\\x01\\n3sparse_categorical_crossentropy/weighted_loss/Sum_1\\x12\\x03Sum\\x1a1sparse_categorical_crossentropy/weighted_loss/Sum\\x1a3sparse_categorical_crossentropy/weighted_loss/range*\\x07\\n\\x01T\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\n\\n\\x04Tidx\\x12\\x020\\x03*\\x0f\\n\\tkeep_dims\\x12\\x02(\\x00\\n\\xd6\\x01\\n3sparse_categorical_crossentropy/weighted_loss/value\\x12\\x08DivNoNan\\x1a3sparse_categorical_crossentropy/weighted_loss/Sum_1\\x1a?sparse_categorical_crossentropy/weighted_loss/num_elements/Cast*\\x07\\n\\x01T\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\nO\\n\\x05Shape\\x12\\x05Shape\\x1a\\nExpandDims*\\x07\\n\\x01T\\x12\\x020\\x04*\\x0e\\n\\x08out_type\\x12\\x020\\x03*\\x1a\\n\\x0e_output_shapes\\x12\\x08\\n\\x06:\\x04\\x12\\x02\\x08\\x02\\n]\\n\\x13strided_slice/stack\\x12\\x05Const*\\x16\\n\\x05value\\x12\\rB\\x0b\\x08\\x03\\x12\\x04\\x12\\x02\\x08\\x01:\\x01\\x00*\\x0b\\n\\x05dtype\\x12\\x020\\x03*\\x1a\\n\\x0e_output_shapes\\x12\\x08\\n\\x06:\\x04\\x12\\x02\\x08\\x01\\n_\\n\\x15strided_slice/stack_1\\x12\\x05Const*\\x16\\n\\x05value\\x12\\rB\\x0b\\x08\\x03\\x12\\x04\\x12\\x02\\x08\\x01:\\x01\\x01*\\x0b\\n\\x05dtype\\x12\\x020\\x03*\\x1a\\n\\x0e_output_shapes\\x12\\x08\\n\\x06:\\x04\\x12\\x02\\x08\\x01\\n_\\n\\x15strided_slice/stack_2\\x12\\x05Const*\\x16\\n\\x05value\\x12\\rB\\x0b\\x08\\x03\\x12\\x04\\x12\\x02\\x08\\x01:\\x01\\x01*\\x0b\\n\\x05dtype\\x12\\x020\\x03*\\x1a\\n\\x0e_output_shapes\\x12\\x08\\n\\x06:\\x04\\x12\\x02\\x08\\x01\\n\\xf9\\x01\\n\\rstrided_slice\\x12\\x0cStridedSlice\\x1a\\x05Shape\\x1a\\x13strided_slice/stack\\x1a\\x15strided_slice/stack_1\\x1a\\x15strided_slice/stack_2*\\x16\\n\\x10shrink_axis_mask\\x12\\x02\\x18\\x01*\\x13\\n\\rellipsis_mask\\x12\\x02\\x18\\x00*\\x10\\n\\nbegin_mask\\x12\\x02\\x18\\x00*\\x13\\n\\rnew_axis_mask\\x12\\x02\\x18\\x00*\\x0e\\n\\x08end_mask\\x12\\x02\\x18\\x00*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x07\\n\\x01T\\x12\\x020\\x03*\\x0b\\n\\x05Index\\x12\\x020\\x03\\n[\\n\\x04Cast\\x12\\x04Cast\\x1a\\rstrided_slice*\\n\\n\\x04SrcT\\x12\\x020\\x03*\\x0e\\n\\x08Truncate\\x12\\x02(\\x00*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\n\\n\\x04DstT\\x12\\x020\\x01\\nf\\n\\x03Mul\\x12\\x03Mul\\x1a3sparse_categorical_crossentropy/weighted_loss/value\\x1a\\x04Cast*\\x07\\n\\x01T\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\nF\\n\\x04Rank\\x12\\x05Const*\\x12\\n\\x05value\\x12\\tB\\x07\\x08\\x03\\x12\\x00:\\x01\\x00*\\x0b\\n\\x05dtype\\x12\\x020\\x03*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\nM\\n\\x0brange/start\\x12\\x05Const*\\x12\\n\\x05value\\x12\\tB\\x07\\x08\\x03\\x12\\x00:\\x01\\x00*\\x0b\\n\\x05dtype\\x12\\x020\\x03*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\nM\\n\\x0brange/delta\\x12\\x05Const*\\x12\\n\\x05value\\x12\\tB\\x07\\x08\\x03\\x12\\x00:\\x01\\x01*\\x0b\\n\\x05dtype\\x12\\x020\\x03*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\nT\\n\\x05range\\x12\\x05Range\\x1a\\x0brange/start\\x1a\\x04Rank\\x1a\\x0brange/delta*\\x18\\n\\x0e_output_shapes\\x12\\x06\\n\\x04:\\x02\\x12\\x00*\\n\\n\\x04Tidx\\x12\\x020\\x03\\nT\\n\\x03Sum\\x12\\x03Sum\\x1a\\x03Mul\\x1a\\x05range*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x0f\\n\\tkeep_dims\\x12\\x02(\\x00*\\n\\n\\x04Tidx\\x12\\x020\\x03*\\x07\\n\\x01T\\x12\\x020\\x01\\n]\\n\\x1cAssignAddVariableOp/resource\\x12\\x0bPlaceholder*\\x0b\\n\\x05dtype\\x12\\x020\\x14*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x0b\\n\\x05shape\\x12\\x02:\\x00\\nZ\\n\\x13AssignAddVariableOp\\x12\\x13AssignAddVariableOp\\x1a\\x1cAssignAddVariableOp/resource\\x1a\\x03Sum*\\x0b\\n\\x05dtype\\x12\\x020\\x01\\nH\\n\\x06Rank_1\\x12\\x05Const*\\x0b\\n\\x05dtype\\x12\\x020\\x03*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x12\\n\\x05value\\x12\\tB\\x07\\x08\\x03\\x12\\x00:\\x01\\x00\\nO\\n\\rrange_1/start\\x12\\x05Const*\\x12\\n\\x05value\\x12\\tB\\x07\\x08\\x03\\x12\\x00:\\x01\\x00*\\x0b\\n\\x05dtype\\x12\\x020\\x03*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\nO\\n\\rrange_1/delta\\x12\\x05Const*\\x12\\n\\x05value\\x12\\tB\\x07\\x08\\x03\\x12\\x00:\\x01\\x01*\\x0b\\n\\x05dtype\\x12\\x020\\x03*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\\\\\n\\x07range_1\\x12\\x05Range\\x1a\\rrange_1/start\\x1a\\x06Rank_1\\x1a\\rrange_1/delta*\\x18\\n\\x0e_output_shapes\\x12\\x06\\n\\x04:\\x02\\x12\\x00*\\n\\n\\x04Tidx\\x12\\x020\\x03\\nY\\n\\x05Sum_1\\x12\\x03Sum\\x1a\\x04Cast\\x1a\\x07range_1*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\n\\n\\x04Tidx\\x12\\x020\\x03*\\x0f\\n\\tkeep_dims\\x12\\x02(\\x00*\\x07\\n\\x01T\\x12\\x020\\x01\\n_\\n\\x1eAssignAddVariableOp_1/resource\\x12\\x0bPlaceholder*\\x0b\\n\\x05dtype\\x12\\x020\\x14*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x0b\\n\\x05shape\\x12\\x02:\\x00\\nv\\n\\x15AssignAddVariableOp_1\\x12\\x13AssignAddVariableOp\\x1a\\x1eAssignAddVariableOp_1/resource\\x1a\\x05Sum_1\\x1a\\x14^AssignAddVariableOp*\\x0b\\n\\x05dtype\\x12\\x020\\x01\\nX\\n\\x13Adam/gradients/ones\\x12\\x05Const*\\x15\\n\\x05value\\x12\\x0cB\\n\\x08\\x01\\x12\\x00*\\x04\\x00\\x00\\x80?*\\x0b\\n\\x05dtype\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\x8a\\x01\\nGgradient_tape/sparse_categorical_crossentropy/weighted_loss/value/Shape\\x12\\x05Const*\\x11\\n\\x05value\\x12\\x08B\\x06\\x08\\x03\\x12\\x02\\x12\\x00*\\x0b\\n\\x05dtype\\x12\\x020\\x03*\\x18\\n\\x0e_output_shapes\\x12\\x06\\n\\x04:\\x02\\x12\\x00\\n\\x8c\\x01\\nIgradient_tape/sparse_categorical_crossentropy/weighted_loss/value/Shape_1\\x12\\x05Const*\\x11\\n\\x05value\\x12\\x08B\\x06\\x08\\x03\\x12\\x02\\x12\\x00*\\x0b\\n\\x05dtype\\x12\\x020\\x03*\\x18\\n\\x0e_output_shapes\\x12\\x06\\n\\x04:\\x02\\x12\\x00\\n\\xc1\\x02\\nWgradient_tape/sparse_categorical_crossentropy/weighted_loss/value/BroadcastGradientArgs\\x12\\x15BroadcastGradientArgs\\x1aGgradient_tape/sparse_categorical_crossentropy/weighted_loss/value/Shape\\x1aIgradient_tape/sparse_categorical_crossentropy/weighted_loss/value/Shape_1*\\x07\\n\\x01T\\x12\\x020\\x03*2\\n\\x0e_output_shapes\\x12 \\n\\x1e:\\r\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01:\\r\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\n\\xcf\\x01\\nLgradient_tape/sparse_categorical_crossentropy/weighted_loss/value/div_no_nan\\x12\\x08DivNoNan\\x1a\\x13Adam/gradients/ones\\x1a?sparse_categorical_crossentropy/weighted_loss/num_elements/Cast*\\x07\\n\\x01T\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\xb1\\x02\\nEgradient_tape/sparse_categorical_crossentropy/weighted_loss/value/Sum\\x12\\x03Sum\\x1aLgradient_tape/sparse_categorical_crossentropy/weighted_loss/value/div_no_nan\\x1aWgradient_tape/sparse_categorical_crossentropy/weighted_loss/value/BroadcastGradientArgs*\\x07\\n\\x01T\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x0f\\n\\tkeep_dims\\x12\\x02(\\x00*\\n\\n\\x04Tidx\\x12\\x020\\x03\\n\\x93\\x02\\nIgradient_tape/sparse_categorical_crossentropy/weighted_loss/value/Reshape\\x12\\x07Reshape\\x1aEgradient_tape/sparse_categorical_crossentropy/weighted_loss/value/Sum\\x1aGgradient_tape/sparse_categorical_crossentropy/weighted_loss/value/Shape*\\x07\\n\\x01T\\x12\\x020\\x01*\\x0c\\n\\x06Tshape\\x12\\x020\\x03*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\xa2\\x01\\nEgradient_tape/sparse_categorical_crossentropy/weighted_loss/value/Neg\\x12\\x03Neg\\x1a3sparse_categorical_crossentropy/weighted_loss/Sum_1*\\x07\\n\\x01T\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\x83\\x02\\nNgradient_tape/sparse_categorical_crossentropy/weighted_loss/value/div_no_nan_1\\x12\\x08DivNoNan\\x1aEgradient_tape/sparse_categorical_crossentropy/weighted_loss/value/Neg\\x1a?sparse_categorical_crossentropy/weighted_loss/num_elements/Cast*\\x07\\n\\x01T\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\x8c\\x02\\nNgradient_tape/sparse_categorical_crossentropy/weighted_loss/value/div_no_nan_2\\x12\\x08DivNoNan\\x1aNgradient_tape/sparse_categorical_crossentropy/weighted_loss/value/div_no_nan_1\\x1a?sparse_categorical_crossentropy/weighted_loss/num_elements/Cast*\\x07\\n\\x01T\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\xd2\\x01\\nEgradient_tape/sparse_categorical_crossentropy/weighted_loss/value/mul\\x12\\x03Mul\\x1a\\x13Adam/gradients/ones\\x1aNgradient_tape/sparse_categorical_crossentropy/weighted_loss/value/div_no_nan_2*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x07\\n\\x01T\\x12\\x020\\x01\\n\\xae\\x02\\nGgradient_tape/sparse_categorical_crossentropy/weighted_loss/value/Sum_1\\x12\\x03Sum\\x1aEgradient_tape/sparse_categorical_crossentropy/weighted_loss/value/mul\\x1aYgradient_tape/sparse_categorical_crossentropy/weighted_loss/value/BroadcastGradientArgs:1*\\x07\\n\\x01T\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\n\\n\\x04Tidx\\x12\\x020\\x03*\\x0f\\n\\tkeep_dims\\x12\\x02(\\x00\\n\\x99\\x02\\nKgradient_tape/sparse_categorical_crossentropy/weighted_loss/value/Reshape_1\\x12\\x07Reshape\\x1aGgradient_tape/sparse_categorical_crossentropy/weighted_loss/value/Sum_1\\x1aIgradient_tape/sparse_categorical_crossentropy/weighted_loss/value/Shape_1*\\x07\\n\\x01T\\x12\\x020\\x01*\\x0c\\n\\x06Tshape\\x12\\x020\\x03*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\x8c\\x01\\nIgradient_tape/sparse_categorical_crossentropy/weighted_loss/Reshape/shape\\x12\\x05Const*\\x11\\n\\x05value\\x12\\x08B\\x06\\x08\\x01\\x12\\x02\\x12\\x00*\\x0b\\n\\x05dtype\\x12\\x020\\x01*\\x18\\n\\x0e_output_shapes\\x12\\x06\\n\\x04:\\x02\\x12\\x00\\n\\x8e\\x01\\nKgradient_tape/sparse_categorical_crossentropy/weighted_loss/Reshape/shape_1\\x12\\x05Const*\\x0b\\n\\x05dtype\\x12\\x020\\x03*\\x18\\n\\x0e_output_shapes\\x12\\x06\\n\\x04:\\x02\\x12\\x00*\\x11\\n\\x05value\\x12\\x08B\\x06\\x08\\x03\\x12\\x02\\x12\\x00\\n\\x95\\x02\\nCgradient_tape/sparse_categorical_crossentropy/weighted_loss/Reshape\\x12\\x07Reshape\\x1aIgradient_tape/sparse_categorical_crossentropy/weighted_loss/value/Reshape\\x1aKgradient_tape/sparse_categorical_crossentropy/weighted_loss/Reshape/shape_1*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x07\\n\\x01T\\x12\\x020\\x01*\\x0c\\n\\x06Tshape\\x12\\x020\\x03\\n\\x84\\x01\\nAgradient_tape/sparse_categorical_crossentropy/weighted_loss/Const\\x12\\x05Const*\\x0b\\n\\x05dtype\\x12\\x020\\x03*\\x18\\n\\x0e_output_shapes\\x12\\x06\\n\\x04:\\x02\\x12\\x00*\\x11\\n\\x05value\\x12\\x08B\\x06\\x08\\x03\\x12\\x02\\x12\\x00\\n\\x83\\x02\\n@gradient_tape/sparse_categorical_crossentropy/weighted_loss/Tile\\x12\\x04Tile\\x1aCgradient_tape/sparse_categorical_crossentropy/weighted_loss/Reshape\\x1aAgradient_tape/sparse_categorical_crossentropy/weighted_loss/Const*\\x07\\n\\x01T\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x10\\n\\nTmultiples\\x12\\x020\\x03\\n\\x95\\x01\\nKgradient_tape/sparse_categorical_crossentropy/weighted_loss/Reshape_1/shape\\x12\\x05Const*\\x16\\n\\x05value\\x12\\rB\\x0b\\x08\\x03\\x12\\x04\\x12\\x02\\x08\\x01:\\x01\\x01*\\x0b\\n\\x05dtype\\x12\\x020\\x03*\\x1a\\n\\x0e_output_shapes\\x12\\x08\\n\\x06:\\x04\\x12\\x02\\x08\\x01\\n\\x92\\x02\\nEgradient_tape/sparse_categorical_crossentropy/weighted_loss/Reshape_1\\x12\\x07Reshape\\x1a@gradient_tape/sparse_categorical_crossentropy/weighted_loss/Tile\\x1aKgradient_tape/sparse_categorical_crossentropy/weighted_loss/Reshape_1/shape*\\x1a\\n\\x0e_output_shapes\\x12\\x08\\n\\x06:\\x04\\x12\\x02\\x08\\x01*\\x07\\n\\x01T\\x12\\x020\\x01*\\x0c\\n\\x06Tshape\\x12\\x020\\x03\\n\\xb2\\x01\\nAgradient_tape/sparse_categorical_crossentropy/weighted_loss/Shape\\x12\\x05Shape\\x1a1sparse_categorical_crossentropy/weighted_loss/Mul*\\x07\\n\\x01T\\x12\\x020\\x01*\\x0e\\n\\x08out_type\\x12\\x020\\x03*\\x1a\\n\\x0e_output_shapes\\x12\\x08\\n\\x06:\\x04\\x12\\x02\\x08\\x01\\n\\x94\\x02\\nBgradient_tape/sparse_categorical_crossentropy/weighted_loss/Tile_1\\x12\\x04Tile\\x1aEgradient_tape/sparse_categorical_crossentropy/weighted_loss/Reshape_1\\x1aAgradient_tape/sparse_categorical_crossentropy/weighted_loss/Shape*\\x10\\n\\nTmultiples\\x12\\x020\\x03*\\x07\\n\\x01T\\x12\\x020\\x01*#\\n\\x0e_output_shapes\\x12\\x11\\n\\x0f:\\r\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\n\\xed\\x01\\n?gradient_tape/sparse_categorical_crossentropy/weighted_loss/Mul\\x12\\x03Mul\\x1aBgradient_tape/sparse_categorical_crossentropy/weighted_loss/Tile_1\\x1a3sparse_categorical_crossentropy/weighted_loss/Const*\\x07\\n\\x01T\\x12\\x020\\x01*#\\n\\x0e_output_shapes\\x12\\x11\\n\\x0f:\\r\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\n\\xab\\x01\\n`gradient_tape/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/ExpandDims/dim\\x12\\x05Const*\\x0b\\n\\x05dtype\\x12\\x020\\x03*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x1b\\n\\x05value\\x12\\x12B\\x10\\x08\\x03\\x12\\x00:\\n\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\n\\xcb\\x02\\n\\\\gradient_tape/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/ExpandDims\\x12\\nExpandDims\\x1a?gradient_tape/sparse_categorical_crossentropy/weighted_loss/Mul\\x1a`gradient_tape/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/ExpandDims/dim*\\'\\n\\x0e_output_shapes\\x12\\x15\\n\\x13:\\x11\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x12\\x02\\x08\\x01*\\n\\n\\x04Tdim\\x12\\x020\\x03*\\x07\\n\\x01T\\x12\\x020\\x01\\n\\xe0\\x02\\nUgradient_tape/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/mul\\x12\\x03Mul\\x1a\\\\gradient_tape/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/ExpandDims\\x1aisparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1*\\x07\\n\\x01T\\x12\\x020\\x01*0\\n\\x0e_output_shapes\\x12\\x1e\\n\\x1c:\\x1a\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\n\\x8d\\x01\\n3gradient_tape/sparse_categorical_crossentropy/Shape\\x12\\x05Shape\\x1a\\x1asequential/dense_1/BiasAdd*\\x07\\n\\x01T\\x12\\x020\\x01*\\x0e\\n\\x08out_type\\x12\\x020\\x03*\\x1a\\n\\x0e_output_shapes\\x12\\x08\\n\\x06:\\x04\\x12\\x02\\x08\\x02\\n\\x8c\\x02\\n5gradient_tape/sparse_categorical_crossentropy/Reshape\\x12\\x07Reshape\\x1aUgradient_tape/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/mul\\x1a3gradient_tape/sparse_categorical_crossentropy/Shape*\\'\\n\\x0e_output_shapes\\x12\\x15\\n\\x13:\\x11\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x12\\x02\\x08\\n*\\x07\\n\\x01T\\x12\\x020\\x01*\\x0c\\n\\x06Tshape\\x12\\x020\\x03\\n\\xb6\\x01\\n4gradient_tape/sequential/dense_1/BiasAdd/BiasAddGrad\\x12\\x0bBiasAddGrad\\x1a5gradient_tape/sparse_categorical_crossentropy/Reshape*\\x07\\n\\x01T\\x12\\x020\\x01*\\x15\\n\\x0bdata_format\\x12\\x06\\x12\\x04NHWC*\\x1a\\n\\x0e_output_shapes\\x12\\x08\\n\\x06:\\x04\\x12\\x02\\x08\\n\\n\\xeb\\x01\\n\\'gradient_tape/sequential/dense_1/MatMul\\x12\\x06MatMul\\x1a5gradient_tape/sparse_categorical_crossentropy/Reshape\\x1a(sequential/dense_1/MatMul/ReadVariableOp*\\x07\\n\\x01T\\x12\\x020\\x01*(\\n\\x0e_output_shapes\\x12\\x16\\n\\x14:\\x12\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x12\\x03\\x08\\x80\\x01*\\x11\\n\\x0btranspose_a\\x12\\x02(\\x00*\\x11\\n\\x0btranspose_b\\x12\\x02(\\x01\\n\\xdc\\x01\\n)gradient_tape/sequential/dense_1/MatMul_1\\x12\\x06MatMul\\x1a sequential/dropout/dropout/Mul_1\\x1a5gradient_tape/sparse_categorical_crossentropy/Reshape*\\x07\\n\\x01T\\x12\\x020\\x01*\\x11\\n\\x0btranspose_a\\x12\\x02(\\x01*\\x1f\\n\\x0e_output_shapes\\x12\\r\\n\\x0b:\\t\\x12\\x03\\x08\\x80\\x01\\x12\\x02\\x08\\n*\\x11\\n\\x0btranspose_b\\x12\\x02(\\x00\\n\\x8c\\x01\\n.gradient_tape/sequential/dropout/dropout/Shape\\x12\\x05Shape\\x1a\\x1esequential/dropout/dropout/Mul*\\x07\\n\\x01T\\x12\\x020\\x01*\\x0e\\n\\x08out_type\\x12\\x020\\x03*\\x1a\\n\\x0e_output_shapes\\x12\\x08\\n\\x06:\\x04\\x12\\x02\\x08\\x02\\n\\x8f\\x01\\n0gradient_tape/sequential/dropout/dropout/Shape_1\\x12\\x05Shape\\x1a\\x1fsequential/dropout/dropout/Cast*\\x07\\n\\x01T\\x12\\x020\\x01*\\x0e\\n\\x08out_type\\x12\\x020\\x03*\\x1a\\n\\x0e_output_shapes\\x12\\x08\\n\\x06:\\x04\\x12\\x02\\x08\\x02\\n\\xf6\\x01\\n>gradient_tape/sequential/dropout/dropout/BroadcastGradientArgs\\x12\\x15BroadcastGradientArgs\\x1a.gradient_tape/sequential/dropout/dropout/Shape\\x1a0gradient_tape/sequential/dropout/dropout/Shape_1*\\x07\\n\\x01T\\x12\\x020\\x03*2\\n\\x0e_output_shapes\\x12 \\n\\x1e:\\r\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01:\\r\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\n\\xb0\\x01\\n,gradient_tape/sequential/dropout/dropout/Mul\\x12\\x03Mul\\x1a\\'gradient_tape/sequential/dense_1/MatMul\\x1a\\x1fsequential/dropout/dropout/Cast*\\x07\\n\\x01T\\x12\\x020\\x01*(\\n\\x0e_output_shapes\\x12\\x16\\n\\x14:\\x12\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x12\\x03\\x08\\x80\\x01\\n\\xe1\\x01\\n,gradient_tape/sequential/dropout/dropout/Sum\\x12\\x03Sum\\x1a,gradient_tape/sequential/dropout/dropout/Mul\\x1a>gradient_tape/sequential/dropout/dropout/BroadcastGradientArgs*\\x07\\n\\x01T\\x12\\x020\\x01*\\x18\\n\\x0e_output_shapes\\x12\\x06\\n\\x04:\\x02\\x18\\x01*\\n\\n\\x04Tidx\\x12\\x020\\x03*\\x0f\\n\\tkeep_dims\\x12\\x02(\\x00\\n\\xda\\x01\\n0gradient_tape/sequential/dropout/dropout/Reshape\\x12\\x07Reshape\\x1a,gradient_tape/sequential/dropout/dropout/Sum\\x1a.gradient_tape/sequential/dropout/dropout/Shape*\\x07\\n\\x01T\\x12\\x020\\x01*\\x0c\\n\\x06Tshape\\x12\\x020\\x03*(\\n\\x0e_output_shapes\\x12\\x16\\n\\x14:\\x12\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x12\\x03\\x08\\x80\\x01\\n\\xbc\\x01\\n.gradient_tape/sequential/dropout/dropout/Mul_1\\x12\\x03Mul\\x1a0gradient_tape/sequential/dropout/dropout/Reshape\\x1a sequential/dropout/dropout/Const*\\x07\\n\\x01T\\x12\\x020\\x01*(\\n\\x0e_output_shapes\\x12\\x16\\n\\x14:\\x12\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x12\\x03\\x08\\x80\\x01\\n\\xad\\x01\\n\\'gradient_tape/sequential/dense/ReluGrad\\x12\\x08ReluGrad\\x1a.gradient_tape/sequential/dropout/dropout/Mul_1\\x1a\\x15sequential/dense/Relu*\\x07\\n\\x01T\\x12\\x020\\x01*(\\n\\x0e_output_shapes\\x12\\x16\\n\\x14:\\x12\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x12\\x03\\x08\\x80\\x01\\n\\xa7\\x01\\n2gradient_tape/sequential/dense/BiasAdd/BiasAddGrad\\x12\\x0bBiasAddGrad\\x1a\\'gradient_tape/sequential/dense/ReluGrad*\\x07\\n\\x01T\\x12\\x020\\x01*\\x15\\n\\x0bdata_format\\x12\\x06\\x12\\x04NHWC*\\x1b\\n\\x0e_output_shapes\\x12\\t\\n\\x07:\\x05\\x12\\x03\\x08\\x80\\x01\\n\\xc5\\x01\\n%gradient_tape/sequential/dense/MatMul\\x12\\x06MatMul\\x1a\\x1asequential/flatten/Reshape\\x1a\\'gradient_tape/sequential/dense/ReluGrad*\\x07\\n\\x01T\\x12\\x020\\x01* \\n\\x0e_output_shapes\\x12\\x0e\\n\\x0c:\\n\\x12\\x03\\x08\\x90\\x06\\x12\\x03\\x08\\x80\\x01*\\x11\\n\\x0btranspose_a\\x12\\x02(\\x01*\\x11\\n\\x0btranspose_b\\x12\\x02(\\x00\\nb\\n!Adam/Cast/ReadVariableOp/resource\\x12\\x0bPlaceholder*\\x0b\\n\\x05dtype\\x12\\x020\\x14*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x0b\\n\\x05shape\\x12\\x02:\\x00\\nr\\n\\x18Adam/Cast/ReadVariableOp\\x12\\x0eReadVariableOp\\x1a!Adam/Cast/ReadVariableOp/resource*\\x0b\\n\\x05dtype\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\x82\\x01\\n\\rAdam/Identity\\x12\\x08Identity\\x1a\\x18Adam/Cast/ReadVariableOp\",/job:localhost/replica:0/task:0/device:CPU:0*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x07\\n\\x01T\\x12\\x020\\x01\\n]\\n\\x1cAdam/ReadVariableOp/resource\\x12\\x0bPlaceholder*\\x0b\\n\\x05dtype\\x12\\x020\\x14*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x0b\\n\\x05shape\\x12\\x02:\\x00\\nh\\n\\x13Adam/ReadVariableOp\\x12\\x0eReadVariableOp\\x1a\\x1cAdam/ReadVariableOp/resource*\\x0b\\n\\x05dtype\\x12\\x020\\t*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\nz\\n\\nAdam/add/y\\x12\\x05Const\",/job:localhost/replica:0/task:0/device:CPU:0*\\x12\\n\\x05value\\x12\\tB\\x07\\x08\\t\\x12\\x00R\\x01\\x01*\\x0b\\n\\x05dtype\\x12\\x020\\t*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\x81\\x01\\n\\x08Adam/add\\x12\\x05AddV2\\x1a\\x13Adam/ReadVariableOp\\x1a\\nAdam/add/y\",/job:localhost/replica:0/task:0/device:CPU:0*\\x07\\n\\x01T\\x12\\x020\\t*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\x8b\\x01\\n\\x0bAdam/Cast_1\\x12\\x04Cast\\x1a\\x08Adam/add\",/job:localhost/replica:0/task:0/device:CPU:0*\\n\\n\\x04SrcT\\x12\\x020\\t*\\x0e\\n\\x08Truncate\\x12\\x02(\\x00*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\n\\n\\x04DstT\\x12\\x020\\x01\\nd\\n#Adam/Cast_2/ReadVariableOp/resource\\x12\\x0bPlaceholder*\\x0b\\n\\x05shape\\x12\\x02:\\x00*\\x0b\\n\\x05dtype\\x12\\x020\\x14*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\nv\\n\\x1aAdam/Cast_2/ReadVariableOp\\x12\\x0eReadVariableOp\\x1a#Adam/Cast_2/ReadVariableOp/resource*\\x0b\\n\\x05dtype\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\x86\\x01\\n\\x0fAdam/Identity_1\\x12\\x08Identity\\x1a\\x1aAdam/Cast_2/ReadVariableOp\",/job:localhost/replica:0/task:0/device:CPU:0*\\x07\\n\\x01T\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\nd\\n#Adam/Cast_3/ReadVariableOp/resource\\x12\\x0bPlaceholder*\\x0b\\n\\x05dtype\\x12\\x020\\x14*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x0b\\n\\x05shape\\x12\\x02:\\x00\\nv\\n\\x1aAdam/Cast_3/ReadVariableOp\\x12\\x0eReadVariableOp\\x1a#Adam/Cast_3/ReadVariableOp/resource*\\x0b\\n\\x05dtype\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\x86\\x01\\n\\x0fAdam/Identity_2\\x12\\x08Identity\\x1a\\x1aAdam/Cast_3/ReadVariableOp\",/job:localhost/replica:0/task:0/device:CPU:0*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x07\\n\\x01T\\x12\\x020\\x01\\n|\\n\\x08Adam/Pow\\x12\\x03Pow\\x1a\\x0fAdam/Identity_1\\x1a\\x0bAdam/Cast_1\",/job:localhost/replica:0/task:0/device:CPU:0*\\x07\\n\\x01T\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n~\\n\\nAdam/Pow_1\\x12\\x03Pow\\x1a\\x0fAdam/Identity_2\\x1a\\x0bAdam/Cast_1\",/job:localhost/replica:0/task:0/device:CPU:0*\\x07\\n\\x01T\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n}\\n\\nAdam/sub/x\\x12\\x05Const\",/job:localhost/replica:0/task:0/device:CPU:0*\\x15\\n\\x05value\\x12\\x0cB\\n\\x08\\x01\\x12\\x00*\\x04\\x00\\x00\\x80?*\\x0b\\n\\x05dtype\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\nv\\n\\x08Adam/sub\\x12\\x03Sub\\x1a\\nAdam/sub/x\\x1a\\nAdam/Pow_1\",/job:localhost/replica:0/task:0/device:CPU:0*\\x07\\n\\x01T\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\nj\\n\\tAdam/Sqrt\\x12\\x04Sqrt\\x1a\\x08Adam/sub\",/job:localhost/replica:0/task:0/device:CPU:0*\\x07\\n\\x01T\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\x7f\\n\\x0cAdam/sub_1/x\\x12\\x05Const\",/job:localhost/replica:0/task:0/device:CPU:0*\\x15\\n\\x05value\\x12\\x0cB\\n\\x08\\x01\\x12\\x00*\\x04\\x00\\x00\\x80?*\\x0b\\n\\x05dtype\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\nx\\n\\nAdam/sub_1\\x12\\x03Sub\\x1a\\x0cAdam/sub_1/x\\x1a\\x08Adam/Pow\",/job:localhost/replica:0/task:0/device:CPU:0*\\x07\\n\\x01T\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n}\\n\\x0cAdam/truediv\\x12\\x07RealDiv\\x1a\\tAdam/Sqrt\\x1a\\nAdam/sub_1\",/job:localhost/replica:0/task:0/device:CPU:0*\\x07\\n\\x01T\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n{\\n\\x08Adam/mul\\x12\\x03Mul\\x1a\\rAdam/Identity\\x1a\\x0cAdam/truediv\",/job:localhost/replica:0/task:0/device:CPU:0*\\x07\\n\\x01T\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n}\\n\\nAdam/Const\\x12\\x05Const\",/job:localhost/replica:0/task:0/device:CPU:0*\\x0b\\n\\x05dtype\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x15\\n\\x05value\\x12\\x0cB\\n\\x08\\x01\\x12\\x00*\\x04\\x95\\xbf\\xd63\\n\\x7f\\n\\x0cAdam/sub_2/x\\x12\\x05Const\",/job:localhost/replica:0/task:0/device:CPU:0*\\x15\\n\\x05value\\x12\\x0cB\\n\\x08\\x01\\x12\\x00*\\x04\\x00\\x00\\x80?*\\x0b\\n\\x05dtype\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\x7f\\n\\nAdam/sub_2\\x12\\x03Sub\\x1a\\x0cAdam/sub_2/x\\x1a\\x0fAdam/Identity_1\",/job:localhost/replica:0/task:0/device:CPU:0*\\x07\\n\\x01T\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\x7f\\n\\x0cAdam/sub_3/x\\x12\\x05Const\",/job:localhost/replica:0/task:0/device:CPU:0*\\x15\\n\\x05value\\x12\\x0cB\\n\\x08\\x01\\x12\\x00*\\x04\\x00\\x00\\x80?*\\x0b\\n\\x05dtype\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\x7f\\n\\nAdam/sub_3\\x12\\x03Sub\\x1a\\x0cAdam/sub_3/x\\x1a\\x0fAdam/Identity_2\",/job:localhost/replica:0/task:0/device:CPU:0*\\x07\\n\\x01T\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\xd7\\x01\\n$Adam/Adam/update/ResourceApplyAdam/m\\x12\\x0bPlaceholder\",/job:localhost/replica:0/task:0/device:CPU:0*B\\n\\x06_class\\x128\\n6\\x124loc:@sequential/dense/MatMul/ReadVariableOp/resource*\\x0b\\n\\x05dtype\\x12\\x020\\x14*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x0b\\n\\x05shape\\x12\\x02:\\x00\\n\\xd7\\x01\\n$Adam/Adam/update/ResourceApplyAdam/v\\x12\\x0bPlaceholder\",/job:localhost/replica:0/task:0/device:CPU:0*\\x0b\\n\\x05dtype\\x12\\x020\\x14*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x0b\\n\\x05shape\\x12\\x02:\\x00*B\\n\\x06_class\\x128\\n6\\x124loc:@sequential/dense/MatMul/ReadVariableOp/resource\\n\\xf9\\x03\\n\"Adam/Adam/update/ResourceApplyAdam\\x12\\x11ResourceApplyAdam\\x1a/sequential/dense/MatMul/ReadVariableOp/resource\\x1a$Adam/Adam/update/ResourceApplyAdam/m\\x1a$Adam/Adam/update/ResourceApplyAdam/v\\x1a\\x08Adam/Pow\\x1a\\nAdam/Pow_1\\x1a\\rAdam/Identity\\x1a\\x0fAdam/Identity_1\\x1a\\x0fAdam/Identity_2\\x1a\\nAdam/Const\\x1a%gradient_tape/sequential/dense/MatMul\\x1a\\'^sequential/dense/MatMul/ReadVariableOp\",/job:localhost/replica:0/task:0/device:CPU:0*\\x12\\n\\x0cuse_nesterov\\x12\\x02(\\x00*\\x11\\n\\x0buse_locking\\x12\\x02(\\x01*\\x07\\n\\x01T\\x12\\x020\\x01*B\\n\\x06_class\\x128\\n6\\x124loc:@sequential/dense/MatMul/ReadVariableOp/resource\\n\\xda\\x01\\n&Adam/Adam/update_1/ResourceApplyAdam/m\\x12\\x0bPlaceholder\",/job:localhost/replica:0/task:0/device:CPU:0*C\\n\\x06_class\\x129\\n7\\x125loc:@sequential/dense/BiasAdd/ReadVariableOp/resource*\\x0b\\n\\x05dtype\\x12\\x020\\x14*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x0b\\n\\x05shape\\x12\\x02:\\x00\\n\\xda\\x01\\n&Adam/Adam/update_1/ResourceApplyAdam/v\\x12\\x0bPlaceholder\",/job:localhost/replica:0/task:0/device:CPU:0*\\x0b\\n\\x05shape\\x12\\x02:\\x00*C\\n\\x06_class\\x129\\n7\\x125loc:@sequential/dense/BiasAdd/ReadVariableOp/resource*\\x0b\\n\\x05dtype\\x12\\x020\\x14*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\x8f\\x04\\n$Adam/Adam/update_1/ResourceApplyAdam\\x12\\x11ResourceApplyAdam\\x1a0sequential/dense/BiasAdd/ReadVariableOp/resource\\x1a&Adam/Adam/update_1/ResourceApplyAdam/m\\x1a&Adam/Adam/update_1/ResourceApplyAdam/v\\x1a\\x08Adam/Pow\\x1a\\nAdam/Pow_1\\x1a\\rAdam/Identity\\x1a\\x0fAdam/Identity_1\\x1a\\x0fAdam/Identity_2\\x1a\\nAdam/Const\\x1a2gradient_tape/sequential/dense/BiasAdd/BiasAddGrad\\x1a(^sequential/dense/BiasAdd/ReadVariableOp\",/job:localhost/replica:0/task:0/device:CPU:0*\\x11\\n\\x0buse_locking\\x12\\x02(\\x01*\\x07\\n\\x01T\\x12\\x020\\x01*C\\n\\x06_class\\x129\\n7\\x125loc:@sequential/dense/BiasAdd/ReadVariableOp/resource*\\x12\\n\\x0cuse_nesterov\\x12\\x02(\\x00\\n\\xdb\\x01\\n&Adam/Adam/update_2/ResourceApplyAdam/m\\x12\\x0bPlaceholder\",/job:localhost/replica:0/task:0/device:CPU:0*\\x0b\\n\\x05shape\\x12\\x02:\\x00*D\\n\\x06_class\\x12:\\n8\\x126loc:@sequential/dense_1/MatMul/ReadVariableOp/resource*\\x0b\\n\\x05dtype\\x12\\x020\\x14*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\xdb\\x01\\n&Adam/Adam/update_2/ResourceApplyAdam/v\\x12\\x0bPlaceholder\",/job:localhost/replica:0/task:0/device:CPU:0*D\\n\\x06_class\\x12:\\n8\\x126loc:@sequential/dense_1/MatMul/ReadVariableOp/resource*\\x0b\\n\\x05dtype\\x12\\x020\\x14*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x0b\\n\\x05shape\\x12\\x02:\\x00\\n\\x89\\x04\\n$Adam/Adam/update_2/ResourceApplyAdam\\x12\\x11ResourceApplyAdam\\x1a1sequential/dense_1/MatMul/ReadVariableOp/resource\\x1a&Adam/Adam/update_2/ResourceApplyAdam/m\\x1a&Adam/Adam/update_2/ResourceApplyAdam/v\\x1a\\x08Adam/Pow\\x1a\\nAdam/Pow_1\\x1a\\rAdam/Identity\\x1a\\x0fAdam/Identity_1\\x1a\\x0fAdam/Identity_2\\x1a\\nAdam/Const\\x1a)gradient_tape/sequential/dense_1/MatMul_1\\x1a)^sequential/dense_1/MatMul/ReadVariableOp\",/job:localhost/replica:0/task:0/device:CPU:0*\\x12\\n\\x0cuse_nesterov\\x12\\x02(\\x00*\\x11\\n\\x0buse_locking\\x12\\x02(\\x01*\\x07\\n\\x01T\\x12\\x020\\x01*D\\n\\x06_class\\x12:\\n8\\x126loc:@sequential/dense_1/MatMul/ReadVariableOp/resource\\n\\xdc\\x01\\n&Adam/Adam/update_3/ResourceApplyAdam/m\\x12\\x0bPlaceholder\",/job:localhost/replica:0/task:0/device:CPU:0*E\\n\\x06_class\\x12;\\n9\\x127loc:@sequential/dense_1/BiasAdd/ReadVariableOp/resource*\\x0b\\n\\x05dtype\\x12\\x020\\x14*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x0b\\n\\x05shape\\x12\\x02:\\x00\\n\\xdc\\x01\\n&Adam/Adam/update_3/ResourceApplyAdam/v\\x12\\x0bPlaceholder\",/job:localhost/replica:0/task:0/device:CPU:0*\\x0b\\n\\x05dtype\\x12\\x020\\x14*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x0b\\n\\x05shape\\x12\\x02:\\x00*E\\n\\x06_class\\x12;\\n9\\x127loc:@sequential/dense_1/BiasAdd/ReadVariableOp/resource\\n\\x97\\x04\\n$Adam/Adam/update_3/ResourceApplyAdam\\x12\\x11ResourceApplyAdam\\x1a2sequential/dense_1/BiasAdd/ReadVariableOp/resource\\x1a&Adam/Adam/update_3/ResourceApplyAdam/m\\x1a&Adam/Adam/update_3/ResourceApplyAdam/v\\x1a\\x08Adam/Pow\\x1a\\nAdam/Pow_1\\x1a\\rAdam/Identity\\x1a\\x0fAdam/Identity_1\\x1a\\x0fAdam/Identity_2\\x1a\\nAdam/Const\\x1a4gradient_tape/sequential/dense_1/BiasAdd/BiasAddGrad\\x1a*^sequential/dense_1/BiasAdd/ReadVariableOp\",/job:localhost/replica:0/task:0/device:CPU:0*\\x07\\n\\x01T\\x12\\x020\\x01*E\\n\\x06_class\\x12;\\n9\\x127loc:@sequential/dense_1/BiasAdd/ReadVariableOp/resource*\\x12\\n\\x0cuse_nesterov\\x12\\x02(\\x00*\\x11\\n\\x0buse_locking\\x12\\x02(\\x01\\n\\xe4\\x01\\n\\x14Adam/Adam/group_deps\\x12\\x04NoOp\\x1a#^Adam/Adam/update/ResourceApplyAdam\\x1a%^Adam/Adam/update_1/ResourceApplyAdam\\x1a%^Adam/Adam/update_2/ResourceApplyAdam\\x1a%^Adam/Adam/update_3/ResourceApplyAdam\",/job:localhost/replica:0/task:0/device:CPU:0\\nh\\n\\x0fAdam/Adam/Const\\x12\\x05Const\\x1a\\x15^Adam/Adam/group_deps*\\x12\\n\\x05value\\x12\\tB\\x07\\x08\\t\\x12\\x00R\\x01\\x01*\\x0b\\n\\x05dtype\\x12\\x020\\t*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\x86\\x01\\n\\x1dAdam/Adam/AssignAddVariableOp\\x12\\x13AssignAddVariableOp\\x1a\\x1cAdam/ReadVariableOp/resource\\x1a\\x0fAdam/Adam/Const\\x1a\\x14^Adam/ReadVariableOp*\\x0b\\n\\x05dtype\\x12\\x020\\t\\nk\\n\\x06Cast_1\\x12\\x04Cast\\x1a\\nExpandDims*\\n\\n\\x04SrcT\\x12\\x020\\x04*\\x0e\\n\\x08Truncate\\x12\\x02(\\x00*\\'\\n\\x0e_output_shapes\\x12\\x15\\n\\x13:\\x11\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\x12\\x02\\x08\\x01*\\n\\n\\x04DstT\\x12\\x020\\x01\\nh\\n\\x07Squeeze\\x12\\x07Squeeze\\x1a\\x06Cast_1*\\x1e\\n\\x0csqueeze_dims\\x12\\x0e\\n\\x0c\\x1a\\n\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01*\\x07\\n\\x01T\\x12\\x020\\x01*#\\n\\x0e_output_shapes\\x12\\x11\\n\\x0f:\\r\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01\\n[\\n\\x10ArgMax/dimension\\x12\\x05Const*\\x1b\\n\\x05value\\x12\\x12B\\x10\\x08\\x03\\x12\\x00:\\n\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01*\\x0b\\n\\x05dtype\\x12\\x020\\x03*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\x8b\\x01\\n\\x06ArgMax\\x12\\x06ArgMax\\x1a\\x1asequential/dense_1/BiasAdd\\x1a\\x10ArgMax/dimension*\\x07\\n\\x01T\\x12\\x020\\x01*\\x11\\n\\x0boutput_type\\x12\\x020\\t*#\\n\\x0e_output_shapes\\x12\\x11\\n\\x0f:\\r\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01*\\n\\n\\x04Tidx\\x12\\x020\\x03\\nc\\n\\x06Cast_2\\x12\\x04Cast\\x1a\\x06ArgMax*\\x0e\\n\\x08Truncate\\x12\\x02(\\x00*\\n\\n\\x04DstT\\x12\\x020\\x01*#\\n\\x0e_output_shapes\\x12\\x11\\n\\x0f:\\r\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01*\\n\\n\\x04SrcT\\x12\\x020\\t\\nm\\n\\x05Equal\\x12\\x05Equal\\x1a\\x07Squeeze\\x1a\\x06Cast_2*\\x07\\n\\x01T\\x12\\x020\\x01*#\\n\\x0e_output_shapes\\x12\\x11\\n\\x0f:\\r\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01*\\x1e\\n\\x18incompatible_shape_error\\x12\\x02(\\x01\\nb\\n\\x06Cast_3\\x12\\x04Cast\\x1a\\x05Equal*\\n\\n\\x04SrcT\\x12\\x020\\n*\\x0e\\n\\x08Truncate\\x12\\x02(\\x00*#\\n\\x0e_output_shapes\\x12\\x11\\n\\x0f:\\r\\x12\\x0b\\x08\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x01*\\n\\n\\x04DstT\\x12\\x020\\x01\\nO\\n\\x05Const\\x12\\x05Const*\\x16\\n\\x05value\\x12\\rB\\x0b\\x08\\x03\\x12\\x04\\x12\\x02\\x08\\x01:\\x01\\x00*\\x0b\\n\\x05dtype\\x12\\x020\\x03*\\x1a\\n\\x0e_output_shapes\\x12\\x08\\n\\x06:\\x04\\x12\\x02\\x08\\x01\\nY\\n\\x05Sum_2\\x12\\x03Sum\\x1a\\x06Cast_3\\x1a\\x05Const*\\x07\\n\\x01T\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\n\\n\\x04Tidx\\x12\\x020\\x03*\\x0f\\n\\tkeep_dims\\x12\\x02(\\x00\\n_\\n\\x1eAssignAddVariableOp_2/resource\\x12\\x0bPlaceholder*\\x0b\\n\\x05dtype\\x12\\x020\\x14*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x0b\\n\\x05shape\\x12\\x02:\\x00\\n`\\n\\x15AssignAddVariableOp_2\\x12\\x13AssignAddVariableOp\\x1a\\x1eAssignAddVariableOp_2/resource\\x1a\\x05Sum_2*\\x0b\\n\\x05dtype\\x12\\x020\\x01\\nE\\n\\x04Size\\x12\\x04Size\\x1a\\x06Cast_3*\\x07\\n\\x01T\\x12\\x020\\x01*\\x0e\\n\\x08out_type\\x12\\x020\\x03*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\nT\\n\\x06Cast_4\\x12\\x04Cast\\x1a\\x04Size*\\n\\n\\x04SrcT\\x12\\x020\\x03*\\x0e\\n\\x08Truncate\\x12\\x02(\\x00*\\n\\n\\x04DstT\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n_\\n\\x1eAssignAddVariableOp_3/resource\\x12\\x0bPlaceholder*\\x0b\\n\\x05dtype\\x12\\x020\\x14*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x0b\\n\\x05shape\\x12\\x02:\\x00\\ny\\n\\x15AssignAddVariableOp_3\\x12\\x13AssignAddVariableOp\\x1a\\x1eAssignAddVariableOp_3/resource\\x1a\\x06Cast_4\\x1a\\x16^AssignAddVariableOp_2*\\x0b\\n\\x05dtype\\x12\\x020\\x01\\n\\x84\\x01\\n\\x19div_no_nan/ReadVariableOp\\x12\\x0eReadVariableOp\\x1a\\x1cAssignAddVariableOp/resource\\x1a\\x14^AssignAddVariableOp*\\x0b\\n\\x05dtype\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\x8a\\x01\\n\\x1bdiv_no_nan/ReadVariableOp_1\\x12\\x0eReadVariableOp\\x1a\\x1eAssignAddVariableOp_1/resource\\x1a\\x16^AssignAddVariableOp_1*\\x0b\\n\\x05dtype\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\no\\n\\ndiv_no_nan\\x12\\x08DivNoNan\\x1a\\x19div_no_nan/ReadVariableOp\\x1a\\x1bdiv_no_nan/ReadVariableOp_1*\\x07\\n\\x01T\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\nA\\n\\x08Identity\\x12\\x08Identity\\x1a\\ndiv_no_nan*\\x07\\n\\x01T\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\x8a\\x01\\n\\x1bdiv_no_nan_1/ReadVariableOp\\x12\\x0eReadVariableOp\\x1a\\x1eAssignAddVariableOp_2/resource\\x1a\\x16^AssignAddVariableOp_2*\\x0b\\n\\x05dtype\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\x8c\\x01\\n\\x1ddiv_no_nan_1/ReadVariableOp_1\\x12\\x0eReadVariableOp\\x1a\\x1eAssignAddVariableOp_3/resource\\x1a\\x16^AssignAddVariableOp_3*\\x0b\\n\\x05dtype\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\nu\\n\\x0cdiv_no_nan_1\\x12\\x08DivNoNan\\x1a\\x1bdiv_no_nan_1/ReadVariableOp\\x1a\\x1ddiv_no_nan_1/ReadVariableOp_1*\\x07\\n\\x01T\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\nE\\n\\nIdentity_1\\x12\\x08Identity\\x1a\\x0cdiv_no_nan_1*\\x07\\n\\x01T\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\nV\\n\\x07Const_1\\x12\\x05Const\\x1a\\x0b^Identity_1*\\x0b\\n\\x05dtype\\x12\\x020\\t*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00*\\x12\\n\\x05value\\x12\\tB\\x07\\x08\\t\\x12\\x00R\\x01\\x01\\n_\\n\\x1eAssignAddVariableOp_4/resource\\x12\\x0bPlaceholder*\\x0b\\n\\x05shape\\x12\\x02:\\x00*\\x0b\\n\\x05dtype\\x12\\x020\\x14*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\nb\\n\\x15AssignAddVariableOp_4\\x12\\x13AssignAddVariableOp\\x1a\\x1eAssignAddVariableOp_4/resource\\x1a\\x07Const_1*\\x0b\\n\\x05dtype\\x12\\x020\\t\\n\\x0c\\n\\x04NoOp\\x12\\x04NoOp\\n\\x0e\\n\\x06NoOp_1\\x12\\x04NoOp\\n\\x92\\x06\\n\\nIdentity_2\\x12\\x08Identity\\x1a\\nIdentity_1\\x1a\\x1e^Adam/Adam/AssignAddVariableOp\\x1a#^Adam/Adam/update/ResourceApplyAdam\\x1a%^Adam/Adam/update_1/ResourceApplyAdam\\x1a%^Adam/Adam/update_2/ResourceApplyAdam\\x1a%^Adam/Adam/update_3/ResourceApplyAdam\\x1a\\x19^Adam/Cast/ReadVariableOp\\x1a\\x1b^Adam/Cast_2/ReadVariableOp\\x1a\\x1b^Adam/Cast_3/ReadVariableOp\\x1a\\x14^Adam/ReadVariableOp\\x1a\\x14^AssignAddVariableOp\\x1a\\x16^AssignAddVariableOp_1\\x1a\\x16^AssignAddVariableOp_2\\x1a\\x16^AssignAddVariableOp_3\\x1a\\x16^AssignAddVariableOp_4\\x1a\\x10^IteratorGetNext\\x1a\\x1a^div_no_nan/ReadVariableOp\\x1a\\x1c^div_no_nan/ReadVariableOp_1\\x1a\\x1c^div_no_nan_1/ReadVariableOp\\x1a\\x1e^div_no_nan_1/ReadVariableOp_1\\x1a(^sequential/dense/BiasAdd/ReadVariableOp\\x1a\\'^sequential/dense/MatMul/ReadVariableOp\\x1a*^sequential/dense_1/BiasAdd/ReadVariableOp\\x1a)^sequential/dense_1/MatMul/ReadVariableOp*\\x07\\n\\x01T\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\\n\\x90\\x06\\n\\nIdentity_3\\x12\\x08Identity\\x1a\\x08Identity\\x1a\\x1e^Adam/Adam/AssignAddVariableOp\\x1a#^Adam/Adam/update/ResourceApplyAdam\\x1a%^Adam/Adam/update_1/ResourceApplyAdam\\x1a%^Adam/Adam/update_2/ResourceApplyAdam\\x1a%^Adam/Adam/update_3/ResourceApplyAdam\\x1a\\x19^Adam/Cast/ReadVariableOp\\x1a\\x1b^Adam/Cast_2/ReadVariableOp\\x1a\\x1b^Adam/Cast_3/ReadVariableOp\\x1a\\x14^Adam/ReadVariableOp\\x1a\\x14^AssignAddVariableOp\\x1a\\x16^AssignAddVariableOp_1\\x1a\\x16^AssignAddVariableOp_2\\x1a\\x16^AssignAddVariableOp_3\\x1a\\x16^AssignAddVariableOp_4\\x1a\\x10^IteratorGetNext\\x1a\\x1a^div_no_nan/ReadVariableOp\\x1a\\x1c^div_no_nan/ReadVariableOp_1\\x1a\\x1c^div_no_nan_1/ReadVariableOp\\x1a\\x1e^div_no_nan_1/ReadVariableOp_1\\x1a(^sequential/dense/BiasAdd/ReadVariableOp\\x1a\\'^sequential/dense/MatMul/ReadVariableOp\\x1a*^sequential/dense_1/BiasAdd/ReadVariableOp\\x1a)^sequential/dense_1/MatMul/ReadVariableOp*\\x07\\n\\x01T\\x12\\x020\\x01*\\x16\\n\\x0e_output_shapes\\x12\\x04\\n\\x02:\\x00\"\\x03\\x08\\xcc\\x05\\xd9\\x93w\\x8aA\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xa9\\xc2\\xab\\t\\x0e.$\\x9e\\x97\\x97\\xd8A\\x10\\x02*4\\n2\\n\\x07batch_2B\\x06\\x08\\x07\\x12\\x00B\\x00J\\x1f\\n\\x1d\\n\\x18graph_run_metadata_graph\\x12\\x011\\x99KS5\\x1e\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xd9\\xdc\\x122\\tenR\\x9e\\x97\\x97\\xd8A*\\x13\\n\\x11\\n\\nepoch_loss\\x15g\\xa2\\xc5>xB\\x19w\"\\x00\\x00\\x00\\x00\\x00\\x00\\x00x\\x11=\\xfd\\t!uR\\x9e\\x97\\x97\\xd8A*\\x17\\n\\x15\\n\\x0eepoch_accuracy\\x15I\\td?\\xfa\\xc0h\\x1f \\x00\\x00\\x00\\x00\\x00\\x00\\x00)\\xed\\xa9P\\t9\\xd2\\x7f\\x9e\\x97\\x97\\xd8A\\x10\\x01*\\x13\\n\\x11\\n\\nepoch_loss\\x15g >>:\\x05\\x07\\xcf$\\x00\\x00\\x00\\x00\\x00\\x00\\x00B+\\x80M\\t\\xc3\\xd7\\x7f\\x9e\\x97\\x97\\xd8A\\x10\\x01*\\x17\\n\\x15\\n\\x0eepoch_accuracy\\x15\\x81&r?\\xc2t\\xb55 \\x00\\x00\\x00\\x00\\x00\\x00\\x00)\\xed\\xa9P\\t\\xe8O\\xab\\x9e\\x97\\x97\\xd8A\\x10\\x02*\\x13\\n\\x11\\n\\nepoch_loss\\x15S\\x07\\x0c>\\xc9\\x92hG$\\x00\\x00\\x00\\x00\\x00\\x00\\x00B+\\x80M\\t\\x9bV\\xab\\x9e\\x97\\x97\\xd8A\\x10\\x02*\\x17\\n\\x15\\n\\x0eepoch_accuracy\\x15\\x1d\\xc9u?\\x8a\\xec/\\xf0 \\x00\\x00\\x00\\x00\\x00\\x00\\x00)\\xed\\xa9P\\t\\x85}\\xd5\\x9e\\x97\\x97\\xd8A\\x10\\x03*\\x13\\n\\x11\\n\\nepoch_loss\\x15\\xb4\\x8b\\xdf=)\"\\x1f\\xcf$\\x00\\x00\\x00\\x00\\x00\\x00\\x00B+\\x80M\\t\\x9d\\x82\\xd5\\x9e\\x97\\x97\\xd8A\\x10\\x03*\\x17\\n\\x15\\n\\x0eepoch_accuracy\\x15X\\xa5w?\\x9c>\\xa4T \\x00\\x00\\x00\\x00\\x00\\x00\\x00)\\xed\\xa9P\\t$b\\x02\\x9f\\x97\\x97\\xd8A\\x10\\x04*\\x13\\n\\x11\\n\\nepoch_loss\\x15\\x13\\x9e\\xb8=\\x8fO\\x9ew$\\x00\\x00\\x00\\x00\\x00\\x00\\x00B+\\x80M\\t\\xech\\x02\\x9f\\x97\\x97\\xd8A\\x10\\x04*\\x17\\n\\x15\\n\\x0eepoch_accuracy\\x15\\xfe\\xd4x?\\xf5N>\\xd5\\x94.'\n",
      "---------\n",
      "b'\\x80\\x05\\x95,\\x00\\x00\\x00\\x00\\x00\\x00\\x00C(\\x18\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xa3\\x7fK\"\\t\\x00\\x00\\x00\\x9e\\x97\\x97\\xd8A\\x1a\\rbrain.Event:2&w\\xff\\xfc\\x94.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/konstantinostsitsimpikos/tileroot/TileDB-ML/venv2/lib/python3.9/site-packages/tiledb/ctx.py:28: UserWarning: tiledb.default_ctx and scope_ctx will not function correctly due to bug in IPython contextvar support.  You must supply a Ctx object to each function for custom configuration options. Please consider upgrading to ipykernel >= 6!Please see https://github.com/TileDB-Inc/TileDB-Py/issues/667 for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unsupported item type '<class 'bytes'>'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-5-b82d3a2a5278>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mtiledb_model_1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTensorflowKerasTileDBModel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0muri\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'tiledb-keras-mnist-sequential-1'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m tiledb_model_1.save(include_optimizer=True,\n\u001B[0m\u001B[1;32m      4\u001B[0m                     \u001B[0mupdate\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m                     include_callbacks=cb)\n",
      "\u001B[0;32m~/tileroot/TileDB-ML/tiledb/ml/models/tensorflow_keras.py\u001B[0m in \u001B[0;36msave\u001B[0;34m(self, update, meta, include_optimizer, include_callbacks)\u001B[0m\n\u001B[1;32m     89\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_create_array\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     90\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 91\u001B[0;31m         self._write_array(\n\u001B[0m\u001B[1;32m     92\u001B[0m             \u001B[0minclude_optimizer\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minclude_optimizer\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     93\u001B[0m             \u001B[0mserialized_weights\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmodel_weights\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/tileroot/TileDB-ML/tiledb/ml/models/tensorflow_keras.py\u001B[0m in \u001B[0;36m_write_array\u001B[0;34m(self, include_optimizer, serialized_weights, serialized_optimizer_weights, meta)\u001B[0m\n\u001B[1;32m    326\u001B[0m                 ).encode(\"utf8\")\n\u001B[1;32m    327\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 328\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate_model_metadata\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtf_model_tiledb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmeta\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmeta\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    329\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    330\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_serialize_optimizer_weights\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minclude_optimizer\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mbool\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mbytes\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/tileroot/TileDB-ML/tiledb/ml/models/base.py\u001B[0m in \u001B[0;36mupdate_model_metadata\u001B[0;34m(self, array, meta)\u001B[0m\n\u001B[1;32m    111\u001B[0m                 )\n\u001B[1;32m    112\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmeta\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 113\u001B[0;31m                 \u001B[0marray\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmeta\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    114\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_file_properties\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    115\u001B[0m             \u001B[0marray\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmeta\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mtiledb/libmetadata.pyx\u001B[0m in \u001B[0;36mtiledb.libtiledb.Metadata.__setitem__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mtiledb/libmetadata.pyx\u001B[0m in \u001B[0;36mtiledb.libtiledb.put_metadata\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mtiledb/libmetadata.pyx\u001B[0m in \u001B[0;36mtiledb.libtiledb.pack_metadata_val\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: Unsupported item type '<class 'bytes'>'"
     ]
    }
   ],
   "source": [
    "tiledb_model_1 = TensorflowKerasTileDBModel(uri='tiledb-keras-mnist-sequential-1', model=model)\n",
    "\n",
    "tiledb_model_1.save(include_optimizer=True,\n",
    "                    update=False,\n",
    "                    include_callbacks=cb)\n",
    "\n",
    "fragments_info = tiledb.array_fragments('tiledb-keras-mnist-sequential-1')\n",
    "print(\"number of fragments: {}\".format(len(fragments_info)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above step will create a TileDB array in your working directory. For information about the structure of a dense\n",
    "TileDB array in terms of files on disk please take a look [here](https://docs.tiledb.com/main/concepts/data-format).\n",
    "Let's open our TileDB array model and check metadata. Metadata that are of type list, dict or tuple have been JSON\n",
    "serialized while saving, i.e., we need json.loads to deserialize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tiledb-keras-mnist-sequential-1/__meta',\n",
      " 'tiledb-keras-mnist-sequential-1/__1650274324660_1650274324660_93996bd6f91446af93cbf547f615caf1_11',\n",
      " 'tiledb-keras-mnist-sequential-1/__schema',\n",
      " 'tiledb-keras-mnist-sequential-1/__1650274324660_1650274324660_93996bd6f91446af93cbf547f615caf1_11.ok']\n",
      "\n",
      "Key: TILEDB_ML_MODEL_ML_FRAMEWORK, Value: TENSORFLOW KERAS\n",
      "Key: TILEDB_ML_MODEL_ML_FRAMEWORK_VERSION, Value: 2.5.0\n",
      "Key: TILEDB_ML_MODEL_PREVIEW, Value: Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Key: TILEDB_ML_MODEL_PYTHON_VERSION, Value: 3.9.5\n",
      "Key: TILEDB_ML_MODEL_STAGE, Value: STAGING\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnicodeDecodeError\u001B[0m                        Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-7-db917e0b3f73>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmodel_array_1\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmeta\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbytes\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m         \u001B[0mvalue\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mjson\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloads\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Key: {}, Value: {}\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/Cellar/python@3.9/3.9.5/Frameworks/Python.framework/Versions/3.9/lib/python3.9/json/__init__.py\u001B[0m in \u001B[0;36mloads\u001B[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[0m\n\u001B[1;32m    339\u001B[0m             raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n\u001B[1;32m    340\u001B[0m                             f'not {s.__class__.__name__}')\n\u001B[0;32m--> 341\u001B[0;31m         \u001B[0ms\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0ms\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdecode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdetect_encoding\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ms\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'surrogatepass'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    342\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    343\u001B[0m     if (cls is None and object_hook is None and\n",
      "\u001B[0;31mUnicodeDecodeError\u001B[0m: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "# Check array directory\n",
    "pprint(glob.glob('tiledb-keras-mnist-sequential-1/*'))\n",
    "\n",
    "# Open in write mode in order to add metadata\n",
    "print()\n",
    "model_array_1 = tiledb.open('tiledb-keras-mnist-sequential-1')\n",
    "for key, value in model_array_1.meta.items():\n",
    "    if isinstance(value, bytes):\n",
    "        value = json.loads(value)\n",
    "    print(\"Key: {}, Value: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, in array's metadata we have by default information about the backend we used for training, keras version,\n",
    "python version, model configuration and training configuration. We can load and check any of the aforementioned without\n",
    "having to load the entire model in memory. Moreover, we can add any kind of extra information about model accuracy, model\n",
    "version, deployment status etc, in the model's metadata either while saving the model, by passing a dictionary with any\n",
    "kind of information, or by opening the TileDB array and adding new keys. Both cases are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Open the array in write mode\n",
    "with tiledb.Array('tiledb-keras-mnist-sequential-1', \"w\") as A:\n",
    "    # Keep all history\n",
    "    A.meta['loss'] = json.dumps(model.history.history['loss'])\n",
    "    A.meta['accuracy'] = json.dumps(model.history.history['accuracy'])\n",
    "\n",
    "    # Or keep last epoch's loss and accuracy\n",
    "    A.meta['last_epoch_loss'] = json.dumps(model.history.history['loss'][-1])\n",
    "    A.meta['last_epoch_accuracy'] = json.dumps(model.history.history['accuracy'][-1])\n",
    "\n",
    "# Check that everything is there\n",
    "model_array_1 = tiledb.open('tiledb-keras-mnist-sequential-1')\n",
    "for key, value in model_array_1.meta.items():\n",
    "    if isinstance(value, bytes):\n",
    "        value = json.loads(value)\n",
    "    print(\"Key: {}, Value: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also save any kind of metadata while saving the model as a TileDB array, and avoid opening it multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.fit(x_train[:30000], y_train[:30000], epochs=5)\n",
    "\n",
    "tiledb_model_2 = TensorflowKerasTileDBModel(uri='tiledb-keras-mnist-sequential-2', model=model)\n",
    "\n",
    "tiledb_model_2.save(include_optimizer=True,\n",
    "                    update=False,\n",
    "                    meta={\"accuracy\": model.history.history['accuracy'],\n",
    "                          \"loss\": model.history.history['loss'],\n",
    "                          \"status\": 'experimental'})\n",
    "\n",
    "# Check array directory\n",
    "print()\n",
    "pprint(glob.glob('tiledb-keras-mnist-sequential-2/*'))\n",
    "\n",
    "# Check that everything is there\n",
    "print()\n",
    "model_array_2 = tiledb.open('tiledb-keras-mnist-sequential-2')\n",
    "for key, value in model_array_2.meta.items():\n",
    "    if isinstance(value, bytes):\n",
    "        value = json.loads(value)\n",
    "    print(\"Key: {}, Value: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For the case of Tensorflow Keras models, apart from model configuration (architecture) which is saved in the metadata\n",
    "section of the TileDB array, we save model's weights and optimizer's weights, as variable sized attributes (pickled),\n",
    "i.e., we can open the TileDB and get only the weights of a model or model's optimizer without bringing the whole model in\n",
    "memory. For example, we can load model's and optimizer's weights for models tiledb-keras-mnist-sequential-1 and\n",
    "tiledb-keras-mnist-sequential-2 as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# First open arrays\n",
    "model_array_1 = tiledb.open('tiledb-keras-mnist-sequential-1')[:]\n",
    "model_array_2 = tiledb.open('tiledb-keras-mnist-sequential-2')[:]\n",
    "\n",
    "# Load model weights\n",
    "model_1_weights = pickle.loads(model_array_1['model_weights'].item(0))\n",
    "model_2_weights = pickle.loads(model_array_2['model_weights'].item(0))\n",
    "\n",
    "# Load optimizer weights\n",
    "optimizer_1_weights = pickle.loads(model_array_1['optimizer_weights'].item(0))\n",
    "optimizer_2_weights = pickle.loads(model_array_2['optimizer_weights'].item(0))\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8,10)\n",
    "\n",
    "# Maybe plot a part of layer 1 weights for both NNs\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.suptitle('1st 50x50 weights of layer 1 for NN1 and NN2', size=16, y=0.72)\n",
    "ax1.matshow(model_1_weights[0][:50, :50])\n",
    "ax2.matshow(model_2_weights[0][:50, :50])\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.95)\n",
    "plt.show()\n",
    "\n",
    "# Maybe plot a part of optimizer weights for both NNs\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.suptitle('1st 50x50 optimizer weights for NN1 and NN2', size=16, y=0.72)\n",
    "ax1.matshow(optimizer_1_weights[1][:50, :50])\n",
    "ax2.matshow(optimizer_2_weights[1][:50, :50])\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(top=0.95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on, we can load the trained models for prediction or evaluation (we have to compile the model), as usual with\n",
    "Tensorflow Keras models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loaded_model_1 = tiledb_model_1.load()\n",
    "loaded_model_2 = tiledb_model_2.load()\n",
    "\n",
    "# Make some predictions\n",
    "print(loaded_model_1.predict(x_test))\n",
    "print(loaded_model_2.predict(x_test))\n",
    "\n",
    "# Evaluate models\n",
    "loaded_model_1 = tiledb_model_1.load(compile_model=True)\n",
    "loaded_model_2 = tiledb_model_2.load(compile_model=True)\n",
    "loaded_model_1.evaluate(x_test, y_test)\n",
    "loaded_model_2.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is really nice with saving models as TileDB array, is native versioning based on fragments as described\n",
    "[here](https://docs.tiledb.com/main/concepts/data-format#immutable-fragments). We can load a model, retrain it\n",
    "with new data and update the already existing TileDB model array with new model parameters and metadata. All information, old\n",
    "and new will be there and accessible. This is extremely useful when you retrain with new data or trying different architectures\n",
    "for the same problem, and you want to keep track of all your experiments without having to store different model instances. In our case,\n",
    "let's continue training model_1 with the rest of our dataset and for 5 more epochs. After training is done, you will\n",
    "notice the extra directories and files (fragments) added to tiledb-keras-mnist-sequential-1 TileDB array directory,\n",
    "which keep all versions of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loaded_model_1 = tiledb_model_1.load(compile_model=True)\n",
    "loaded_model_1.fit(x_train[30000:], y_train[30000:], epochs=5)\n",
    "\n",
    "# and update\n",
    "tiledb_model_1 = TensorflowKerasTileDBModel(uri='tiledb-keras-mnist-sequential-1', model=loaded_model_1)\n",
    "tiledb_model_1.save(include_optimizer=True,\n",
    "                    update=True,\n",
    "                    meta={\"accuracy\": model.history.history['accuracy'],\n",
    "                          \"loss\": model.history.history['loss'],\n",
    "                          \"version\": '0.0.1',\n",
    "                          \"status\": 'experimental'})\n",
    "\n",
    "# Check array directory\n",
    "print()\n",
    "pprint(glob.glob('tiledb-keras-mnist-sequential-1/*'))\n",
    "\n",
    "# tiledb.array_fragments() requires TileDB-Py version > 0.8.5\n",
    "fragments_info = tiledb.array_fragments('tiledb-keras-mnist-sequential-1')\n",
    "\n",
    "print()\n",
    "print(\"====== FRAGMENTS  INFO ======\")\n",
    "print(\"array uri: {}\".format(fragments_info.array_uri))\n",
    "print(\"number of fragments: {}\".format(len(fragments_info)))\n",
    "\n",
    "for fragment_num, fragment in enumerate(fragments_info, start=1):\n",
    "    print()\n",
    "    print(\"===== FRAGMENT NUMBER {} =====\".format(fragment.num))\n",
    "    print(\"fragment uri: {}\".format(fragment.uri))\n",
    "    print(\"timestamp range: {}\".format(fragment.timestamp_range))\n",
    "    print(\n",
    "        \"number of unconsolidated metadata: {}\".format(\n",
    "            fragment.unconsolidated_metadata_num\n",
    "        )\n",
    "    )\n",
    "    print(\"version: {}\".format(fragment.version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, a very interesting and useful, for machine learning models, TileDB feature that is described\n",
    "[here](https://docs.tiledb.com/main/concepts/data-format#groups) and [here](https://docs.tiledb.com/main/how-to/object-management#creating-tiledb-groups)\n",
    "are groups. Assuming we want to solve the MNIST problem, and we want to try several architectures. We can save each architecture\n",
    "as a separate TileDB array with native versioning each time it is re-trained, and then organise all models that solve the same problem (MNIST)\n",
    "as a TileDB array group with any kind of hierarchy. Let's firstly define a new model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_deeper_model():\n",
    "    # For the sake of simplicity we just add an extra dense layer to the previous architecture.\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=loss_fn,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Then train it and save it as a new TileDB array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = create_deeper_model()\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "tiledb_deeper_model = TensorflowKerasTileDBModel(uri='tiledb-keras-mnist-sequential-deeper', model=model)\n",
    "\n",
    "tiledb_deeper_model.save(include_optimizer=True,\n",
    "                         update=False,\n",
    "                         meta={\"accuracy\": model.history.history['accuracy'],\n",
    "                               \"loss\": model.history.history['loss'],\n",
    "                               \"status\": 'experimental'})\n",
    "\n",
    "# Check array directory\n",
    "print()\n",
    "pprint(glob.glob('tiledb-keras-mnist-sequential-deeper/*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we can create a TileDB group and organise (in hierarchies, e.g., sophisticated vs less sophisticated) all our\n",
    "MNIST models as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tiledb.group_create('MNIST_Group')\n",
    "os.system('mv tiledb-keras-mnist-sequential-1 MNIST_Group/')\n",
    "os.system('mv tiledb-keras-mnist-sequential-2 MNIST_Group/')\n",
    "os.system('mv tiledb-keras-mnist-sequential-deeper MNIST_Group/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Any time we can check and query all the available models, including their metadata, for a specific problem like MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tiledb.ls('MNIST_Group', lambda obj_path, obj_type: print(obj_path, obj_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Subclassing\n",
    "\n",
    "Apart from being able to store models, which have been created with Symbolic APIs\n",
    "(Sequential, Functional) someone can store models that are being designed based on\n",
    "Imperative API (aka. Model Subclassing).\n",
    "\n",
    "Let's first design a simple model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self, hidden_units):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.hidden_units = hidden_units\n",
    "        self.dense_layers = [keras.layers.Dense(u) for u in hidden_units]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.dense_layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"hidden_units\": self.hidden_units}\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Then we can create a trivial input dataset for testing the model. Remember that\n",
    "for custom models to be initialised they need to be called on data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = CustomModel([16, 16, 10])\n",
    "# Build the model by calling it\n",
    "input_arr = tf.random.uniform((1, 5))\n",
    "outputs = model(input_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We then can save the model as a TileDB array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tiledb_model_custom = TensorflowKerasTileDBModel(uri='tiledb-keras-custom-model', model=model)\n",
    "tiledb_model_custom.save(include_optimizer=True, update=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the subclassed model requires `custom_objects` to be passed as an argument\n",
    "and the `input_shape` of the model so it can be built. The output of two models are\n",
    "exactly the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loaded_custom = tiledb_model_custom.load(custom_objects={\"CustomModel\": CustomModel}, input_shape=(1, 5))\n",
    "outputs_loaded = loaded_custom(input_arr)\n",
    "outputs == outputs_loaded"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}